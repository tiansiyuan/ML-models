{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f5d0af2-52c5-46af-8679-0add8a92c841",
   "metadata": {},
   "source": [
    "# T5-base model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b73120-b067-42bb-aba9-abb749235975",
   "metadata": {},
   "source": [
    "## Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c59dd7c-7af7-405c-a9e0-dffbed5cd9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install as needed\n",
    "pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81181b24-1989-44ed-892a-be5284df43fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/venv/lib/python3.9/site-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5Model\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "model = T5Model.from_pretrained(\"t5-base\")\n",
    "\n",
    "input_ids = tokenizer(\n",
    "    \"Studies have been shown that owning a dog is good for you\", return_tensors=\"pt\"\n",
    ").input_ids  # Batch size 1\n",
    "decoder_input_ids = tokenizer(\"Studies show that\", return_tensors=\"pt\").input_ids  # Batch size 1\n",
    "\n",
    "# forward pass\n",
    "outputs = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids)\n",
    "last_hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00ca7f24-c5fe-4aa5-b0a9-9f05a55f1415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0005, -0.1320,  0.2328,  ...,  0.0699,  0.0568, -0.1638],\n",
       "         [-0.0052, -0.1856,  0.1215,  ..., -0.0225, -0.0012, -0.2632],\n",
       "         [ 0.0824, -0.3187,  0.0708,  ...,  0.0134,  0.0274, -0.3392],\n",
       "         [ 0.1529, -0.4006,  0.1589,  ...,  0.0711,  0.0720, -0.2287]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51628958-bee6-4753-8634-0d11acd8fffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 768])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a1610a-ee40-41de-a5b9-4353475e0e2b",
   "metadata": {},
   "source": [
    "## Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ba563bb-8345-426e-ad22-014e564b41af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelWithLMHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "243f385e-8ce9-40b6-9ff8-02346b690faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/venv/lib/python3.9/site-packages/transformers/models/auto/modeling_auto.py:1363: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer=AutoTokenizer.from_pretrained('T5-base')\n",
    "model=AutoModelWithLMHead.from_pretrained('T5-base', return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85ca0edf-4978-4eb5-9780-9710c2a6539f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = (\"Data science is an interdisciplinary field[10] focused on extracting knowledge from typically large data sets and applying the knowledge and insights from that data to solve problems in a wide range of application domains.[11] The field encompasses preparing data for analysis, formulating data science problems, analyzing data, developing data-driven solutions, and presenting findings to inform high-level decisions in a broad range of application domains. As such, it incorporates skills from computer science, statistics, information science, mathematics, data visualization, information visualization, data sonification, data integration, graphic design, complex systems, communication and business.[12][13] Statistician Nathan Yau, drawing on Ben Fry, also links data science to humanâ€“computer interaction: users should be able to intuitively control and explore data.[14][15] In 2015, the American Statistical Association identified database management, statistics and machine learning, and distributed and parallel systems as the three emerging foundational professional communities.[16]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "124bc7c1-d20a-4284-9778-1613ff09f006",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=tokenizer.encode(\"sumarize: \" +sequence,return_tensors='pt', max_length=512, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "005a5a82-023e-4c75-822d-288d889f9573",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.generate(inputs, min_length=80, max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ec24450-d059-44f7-8d2b-e02b7fdd8ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-19 09:42:59.840820: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-19 09:43:01.283097: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> data science is an interdisciplinary field focused on extracting knowledge from typically large data sets. it incorporates skills from computer science, statistics, information science, mathematics, data visualization, information visualization, data sonification, graphic design, complex systems, communication and business. the field encompasses preparing data for analysis, formulating data science problems, analyzing data, developing data-driven solutions.</s>\n"
     ]
    }
   ],
   "source": [
    "summary=tokenizer.decode(output[0])\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85631de8-f10d-4cde-bb7a-addd74ee3304",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
