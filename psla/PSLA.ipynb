{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90a72dda-5bc9-4552-bd06-4f6bf333c76d",
   "metadata": {},
   "source": [
    "# PSLA\n",
    "\n",
    "Improving Audio Tagging with Pretraining, Sampling, Labeling, and Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "859f4410-edb3-491f-b5c8-f32a81dfda48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'psla'...\n",
      "remote: Enumerating objects: 108, done.\u001b[K\n",
      "remote: Counting objects: 100% (108/108), done.\u001b[K\n",
      "remote: Compressing objects: 100% (75/75), done.\u001b[K\n",
      "remote: Total 108 (delta 35), reused 84 (delta 28), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (108/108), 7.26 MiB | 35.00 KiB/s, done.\n",
      "Resolving deltas: 100% (35/35), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone  https://github.com/YuanGongND/psla.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4bf0d2b-2c68-447d-b748-e36ba64b5a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HTTP_PROXY'] = 'http://proxy.vmware.com:3128'\n",
    "os.environ['HTTPS_PROXY'] = 'http://proxy.vmware.com:3128'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a114c9e0-0e3c-4481-8a72-d0fa0637af1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/psla\n"
     ]
    }
   ],
   "source": [
    "cd psla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e13f636-fe0d-432a-864f-3babab6d5c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining fairseq from git+https://github.com/pytorch/fairseq@bcc81f6d5291c3996c8b2472282458dead46343f#egg=fairseq (from -r requirements.txt (line 15))\n",
      "  Skipping because already up-to-date.\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting llvmlite==0.36.0 (from -r requirements.txt (line 1))\n",
      "  Using cached llvmlite-0.36.0-cp39-cp39-manylinux2010_x86_64.whl (25.3 MB)\n",
      "Collecting matplotlib==3.4.2 (from -r requirements.txt (line 2))\n",
      "  Using cached matplotlib-3.4.2-cp39-cp39-manylinux1_x86_64.whl (10.3 MB)\n",
      "Collecting numba==0.53.1 (from -r requirements.txt (line 3))\n",
      "  Using cached numba-0.53.1-cp39-cp39-manylinux2014_x86_64.whl (3.4 MB)\n",
      "Collecting numpy==1.20.3 (from -r requirements.txt (line 4))\n",
      "  Using cached numpy-1.20.3-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.4 MB)\n",
      "Collecting scikit-learn==0.24.2 (from -r requirements.txt (line 5))\n",
      "  Downloading scikit_learn-0.24.2-cp39-cp39-manylinux2010_x86_64.whl (23.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m50.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:10\u001b[0m\n",
      "\u001b[?25hCollecting scipy==1.6.3 (from -r requirements.txt (line 6))\n",
      "  Downloading scipy-1.6.3-cp39-cp39-manylinux1_x86_64.whl (27.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.3/27.3 MB\u001b[0m \u001b[31m67.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:12\u001b[0m\n",
      "\u001b[?25hCollecting sklearn==0.0 (from -r requirements.txt (line 7))\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h\u001b[31mERROR: Ignored the following versions that require a different python version: 0.52.0 Requires-Python >=3.6,<3.9; 0.52.0rc3 Requires-Python >=3.6,<3.9\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.6.0 (from versions: 1.7.1, 1.8.0, 1.8.1, 1.9.0, 1.9.1, 1.10.0, 1.10.1, 1.10.2, 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.6.0\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3eb51af-2f26-4b00-b0a0-acadef55d2e3",
   "metadata": {},
   "source": [
    "### FSD50K Recipe\n",
    "\n",
    "Get data and put into some where, modify fsd50k_path inegs/fsd50k/prep_fsd.py accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eed6a2ec-4034-4797-b615-ed6d0596803c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/psla/egs/fsd50k\n"
     ]
    }
   ],
   "source": [
    "cd egs/fsd50k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c04c20f9-f404-44a6-97c5-3aff493fc470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now converting all FSD50K audio to 16kHz, this may take dozens of minutes.\n",
      "Resampled 1000 samples.\n",
      "Resampled 2000 samples.\n",
      "Resampled 3000 samples.\n",
      "Resampled 4000 samples.\n",
      "Resampled 5000 samples.\n",
      "Resampled 6000 samples.\n",
      "Resampled 7000 samples.\n",
      "Resampled 8000 samples.\n",
      "Resampled 9000 samples.\n",
      "Resampled 10000 samples.\n",
      "Resampled 11000 samples.\n",
      "Resampled 12000 samples.\n",
      "Resampled 13000 samples.\n",
      "Resampled 14000 samples.\n",
      "Resampled 15000 samples.\n",
      "Resampled 16000 samples.\n",
      "Resampled 17000 samples.\n",
      "Resampled 18000 samples.\n",
      "Resampled 19000 samples.\n",
      "Resampled 20000 samples.\n",
      "Resampled 21000 samples.\n",
      "Resampled 22000 samples.\n",
      "Resampled 23000 samples.\n",
      "Resampled 24000 samples.\n",
      "Resampled 25000 samples.\n",
      "Resampled 26000 samples.\n",
      "Resampled 27000 samples.\n",
      "Resampled 28000 samples.\n",
      "Resampled 29000 samples.\n",
      "Resampled 30000 samples.\n",
      "Resampled 31000 samples.\n",
      "Resampled 32000 samples.\n",
      "Resampled 33000 samples.\n",
      "Resampled 34000 samples.\n",
      "Resampled 35000 samples.\n",
      "Resampled 36000 samples.\n",
      "Resampled 37000 samples.\n",
      "Resampled 38000 samples.\n",
      "Resampled 39000 samples.\n",
      "Resampled 40000 samples.\n",
      "Resampled 41000 samples.\n",
      "Resampled 42000 samples.\n",
      "Resampled 43000 samples.\n",
      "Resampled 44000 samples.\n",
      "Resampled 45000 samples.\n",
      "Resampled 46000 samples.\n",
      "Resampled 47000 samples.\n",
      "Resampled 48000 samples.\n",
      "Resampled 49000 samples.\n",
      "Resampled 50000 samples.\n",
      "Resampled 51000 samples.\n",
      "Resampling finished.\n",
      "--------------------------------------------\n",
      "Processed 36796 samples for the FSD50K training set.\n",
      "Processed 4170 samples for the FSD50K validation set.\n",
      "Processed 10231 samples for the FSD50K evaluation set.\n"
     ]
    }
   ],
   "source": [
    "!python prep_fsd.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36fad66-d97d-4bf4-8899-51e4931003c9",
   "metadata": {},
   "source": [
    "Download model prediction and place it in psla/src/label_enhancement/ and uncompress it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "63f09db3-c450-4ca8-aad6-27635db95a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/psla/src/label_enhancement\n"
     ]
    }
   ],
   "source": [
    "cd ~/psla/src/label_enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2fdf51d4-5086-4e21-992b-7bc77e67041f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 572 (0.6%) labels to original 101088 original labels\n",
      "Added 292 (0.3%) labels to original 101088 original labels\n",
      "Added 804 (0.8%) labels to original 101088 original labels\n",
      "Added 2114 (2.1%) labels to original 101088 original labels\n",
      "Added 3596 (3.6%) labels to original 101088 original labels\n"
     ]
    }
   ],
   "source": [
    "!python fix_type1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7ccc51-ad21-4272-ba77-6337acc3fc34",
   "metadata": {},
   "source": [
    "Fix path error for ontology.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aa84ab29-4e0f-447d-9564-3f02ba12e3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 17 (0.0%) labels to original 101088 original labels\n",
      "Added 10 (0.0%) labels to original 101088 original labels\n",
      "Added 51 (0.1%) labels to original 101088 original labels\n",
      "Added 196 (0.2%) labels to original 101088 original labels\n",
      "Added 373 (0.4%) labels to original 101088 original labels\n"
     ]
    }
   ],
   "source": [
    "!python fix_type2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7853cdc1-dcbb-4038-8c9b-2f6911f31969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Merge Type 1&2 Label Enhancement with mean Threshold\n",
      "Input Json file 1 has 101660 labels\n",
      "Input Json file 2 has 101105 labels\n",
      "Merged Json file has 101677 labels\n",
      "----------------Merge Type 1&2 Label Enhancement with median Threshold\n",
      "Input Json file 1 has 101380 labels\n",
      "Input Json file 2 has 101098 labels\n",
      "Merged Json file has 101390 labels\n",
      "----------------Merge Type 1&2 Label Enhancement with 25 Threshold\n",
      "Input Json file 1 has 101892 labels\n",
      "Input Json file 2 has 101139 labels\n",
      "Merged Json file has 101943 labels\n",
      "----------------Merge Type 1&2 Label Enhancement with 10 Threshold\n",
      "Input Json file 1 has 103202 labels\n",
      "Input Json file 2 has 101284 labels\n",
      "Merged Json file has 103395 labels\n",
      "----------------Merge Type 1&2 Label Enhancement with 5 Threshold\n",
      "Input Json file 1 has 104684 labels\n",
      "Input Json file 2 has 101461 labels\n",
      "Merged Json file has 105049 labels\n"
     ]
    }
   ],
   "source": [
    "!python merge_type_1_2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f3ebfe6-115f-4af9-9ad9-eebf0c305ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/psla/egs/fsd50k\n"
     ]
    }
   ],
   "source": [
    "cd ~/psla/egs/fsd50k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d18554d2-4791-40e4-b103-ce1e8e06c87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ source ../../venv-psla/bin/activate\n",
      "run.sh: line 14: ../../venv-psla/bin/activate: No such file or directory\n",
      "+ export TORCH_HOME=./\n",
      "+ TORCH_HOME=./\n",
      "+ att_head=4\n",
      "+ model=efficientnet\n",
      "+ psla=True\n",
      "+ eff_b=2\n",
      "+ batch_size=8\n",
      "+ '[' True == True ']'\n",
      "+ impretrain=True\n",
      "+ freqm=48\n",
      "+ timem=192\n",
      "+ mixup=0.5\n",
      "+ bal=True\n",
      "+ lr=5e-4\n",
      "+ p=mean\n",
      "+ '[' mean == none ']'\n",
      "+ trpath=./datafiles/fsd50k_tr_full_type1_2_mean.json\n",
      "+ epoch=40\n",
      "+ wa_start=21\n",
      "+ wa_end=40\n",
      "+ lrscheduler_start=10\n",
      "+ exp_dir=./exp/demo-efficientnet-2-5e-4-fsd50k-impretrain-True-fm48-tm192-mix0.5-bal-True-b8-lemean-2\n",
      "+ mkdir -p ./exp/demo-efficientnet-2-5e-4-fsd50k-impretrain-True-fm48-tm192-mix0.5-bal-True-b8-lemean-2\n",
      "+ CUDA_CACHE_DISABLE=1\n",
      "+ python ../../src/run.py --data-train ./datafiles/fsd50k_tr_full_type1_2_mean.json --data-val ./datafiles/fsd50k_val_full.json --data-eval ./datafiles/fsd50k_eval_full.json --exp-dir ./exp/demo-efficientnet-2-5e-4-fsd50k-impretrain-True-fm48-tm192-mix0.5-bal-True-b8-lemean-2 --n-print-steps 1000 --save_model True --num-workers 32 --label-csv ./class_labels_indices.csv --n_class 200 --n-epochs 40 --batch-size 8 --lr 5e-4 --model efficientnet --eff_b 2 --impretrain True --att_head 4 --freqm 48 --timem 192 --mixup 0.5 --bal True --lr_patience 2 --dataset_mean -4.6476 --dataset_std 4.5699 --target_length 3000 --noise False --metrics mAP --warmup True --loss BCE --lrscheduler_start 10 --lrscheduler_decay 0.5 --wa True --wa_start 21 --wa_end 40\n",
      "I am process 832, running on siyuan-26-0: starting (Sat Jul 15 07:45:21 2023)\n",
      "balanced sampler is being used\n",
      "---------------the train dataloader---------------\n",
      "now using following mask: 48 freq, 192 time\n",
      "now using mix-up with rate 0.500000\n",
      "now process audioset\n",
      "use dataset mean -4.648 and std 4.570 to normalize the input.\n",
      "number of classes is 200\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "---------------the evaluation dataloader---------------\n",
      "now using following mask: 0 freq, 0 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process audioset\n",
      "use dataset mean -4.648 and std 4.570 to normalize the input.\n",
      "number of classes is 200\n",
      "---------------the evaluation dataloader---------------\n",
      "now using following mask: 0 freq, 0 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process audioset\n",
      "use dataset mean -4.648 and std 4.570 to normalize the input.\n",
      "number of classes is 200\n",
      "Now Use ImageNet Pretrained EfficientNet-B2 Model.\n",
      "Loaded pretrained weights for efficientnet-b2\n",
      "Model with 4 attention heads\n",
      "\n",
      "Creating experiment directory: ./exp/demo-efficientnet-2-5e-4-fsd50k-impretrain-True-fm48-tm192-mix0.5-bal-True-b8-lemean-2\n",
      "running on cuda\n",
      "Total parameter number is : 9.955 million\n",
      "Total trainable parameter number is : 9.955 million\n",
      "now training with audioset, main metrics: mAP, loss function: BCELoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7f3c57df5070>\n",
      "The learning rate scheduler starts at 10 epoch with decay rate of 0.500 \n",
      "current #steps=0, #epochs=1\n",
      "start training...\n",
      "---------------\n",
      "2023-07-15 07:45:24.401840\n",
      "current #epochs=1, #steps=0\n",
      "warm-up learning rate is 0.000000\n",
      "warm-up learning rate is 0.000025\n",
      "warm-up learning rate is 0.000050\n",
      "warm-up learning rate is 0.000075\n",
      "warm-up learning rate is 0.000100\n",
      "warm-up learning rate is 0.000125\n",
      "warm-up learning rate is 0.000150\n",
      "warm-up learning rate is 0.000175\n",
      "warm-up learning rate is 0.000200\n",
      "warm-up learning rate is 0.000225\n",
      "warm-up learning rate is 0.000250\n",
      "warm-up learning rate is 0.000275\n",
      "warm-up learning rate is 0.000300\n",
      "warm-up learning rate is 0.000325\n",
      "warm-up learning rate is 0.000350\n",
      "warm-up learning rate is 0.000375\n",
      "warm-up learning rate is 0.000400\n",
      "warm-up learning rate is 0.000425\n",
      "warm-up learning rate is 0.000450\n",
      "warm-up learning rate is 0.000475\n",
      "warm-up learning rate is 0.000500\n",
      "Epoch: [1][1000/4600]\tPer Sample Total Time 0.02755\tPer Sample Data Time 0.00167\tPer Sample DNN Time 0.02588\tTrain Loss 0.1595\t\n",
      "Epoch: [1][2000/4600]\tPer Sample Total Time 0.02704\tPer Sample Data Time 0.00149\tPer Sample DNN Time 0.02555\tTrain Loss 0.1119\t\n",
      "Epoch: [1][3000/4600]\tPer Sample Total Time 0.02690\tPer Sample Data Time 0.00145\tPer Sample DNN Time 0.02545\tTrain Loss 0.0939\t\n",
      "Epoch: [1][4000/4600]\tPer Sample Total Time 0.02682\tPer Sample Data Time 0.00142\tPer Sample DNN Time 0.02539\tTrain Loss 0.0837\t\n",
      "start validation\n",
      "mAP: 0.273444\n",
      "AUC: 0.918701\n",
      "Avg Precision: 0.029138\n",
      "Avg Recall: 0.960839\n",
      "d_prime: 1.974787\n",
      "train_loss: 0.079427\n",
      "valid_loss: 0.046692\n",
      "validation finished\n",
      "Epoch-1 lr: 0.0005\n",
      "epoch 1 training time: 1033.820\n",
      "---------------\n",
      "2023-07-15 08:02:38.223181\n",
      "current #epochs=2, #steps=4600\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch: [2][400/4600]\tPer Sample Total Time 0.02795\tPer Sample Data Time 0.00238\tPer Sample DNN Time 0.02557\tTrain Loss 0.0499\t\n",
      "Epoch: [2][1400/4600]\tPer Sample Total Time 0.02682\tPer Sample Data Time 0.00152\tPer Sample DNN Time 0.02530\tTrain Loss 0.0487\t\n",
      "Epoch: [2][2400/4600]\tPer Sample Total Time 0.02664\tPer Sample Data Time 0.00139\tPer Sample DNN Time 0.02525\tTrain Loss 0.0477\t\n",
      "Epoch: [2][3400/4600]\tPer Sample Total Time 0.02657\tPer Sample Data Time 0.00134\tPer Sample DNN Time 0.02523\tTrain Loss 0.0469\t\n",
      "Epoch: [2][4400/4600]\tPer Sample Total Time 0.02652\tPer Sample Data Time 0.00130\tPer Sample DNN Time 0.02522\tTrain Loss 0.0461\t\n",
      "start validation\n",
      "mAP: 0.374124\n",
      "AUC: 0.934961\n",
      "Avg Precision: 0.029409\n",
      "Avg Recall: 0.969947\n",
      "d_prime: 2.140834\n",
      "train_loss: 0.045931\n",
      "valid_loss: 0.043348\n",
      "validation finished\n",
      "Epoch-2 lr: 0.0005\n",
      "epoch 2 training time: 1021.097\n",
      "---------------\n",
      "2023-07-15 08:19:39.320291\n",
      "current #epochs=3, #steps=9200\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch: [3][800/4600]\tPer Sample Total Time 0.02737\tPer Sample Data Time 0.00190\tPer Sample DNN Time 0.02547\tTrain Loss 0.0417\t\n",
      "Epoch: [3][1800/4600]\tPer Sample Total Time 0.02697\tPer Sample Data Time 0.00163\tPer Sample DNN Time 0.02534\tTrain Loss 0.0418\t\n",
      "Epoch: [3][2800/4600]\tPer Sample Total Time 0.02686\tPer Sample Data Time 0.00157\tPer Sample DNN Time 0.02530\tTrain Loss 0.0413\t\n",
      "Epoch: [3][3800/4600]\tPer Sample Total Time 0.02680\tPer Sample Data Time 0.00153\tPer Sample DNN Time 0.02528\tTrain Loss 0.0408\t\n",
      "start validation\n",
      "mAP: 0.415780\n",
      "AUC: 0.941291\n",
      "Avg Precision: 0.029192\n",
      "Avg Recall: 0.976746\n",
      "d_prime: 2.214242\n",
      "train_loss: 0.040454\n",
      "valid_loss: 0.043498\n",
      "validation finished\n",
      "Epoch-3 lr: 0.0005\n",
      "epoch 3 training time: 1031.043\n",
      "---------------\n",
      "2023-07-15 08:36:50.363284\n",
      "current #epochs=4, #steps=13800\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch: [4][200/4600]\tPer Sample Total Time 0.02947\tPer Sample Data Time 0.00320\tPer Sample DNN Time 0.02627\tTrain Loss 0.0398\t\n",
      "Epoch: [4][1200/4600]\tPer Sample Total Time 0.02718\tPer Sample Data Time 0.00173\tPer Sample DNN Time 0.02545\tTrain Loss 0.0400\t\n",
      "Epoch: [4][2200/4600]\tPer Sample Total Time 0.02696\tPer Sample Data Time 0.00161\tPer Sample DNN Time 0.02535\tTrain Loss 0.0391\t\n",
      "Epoch: [4][3200/4600]\tPer Sample Total Time 0.02688\tPer Sample Data Time 0.00157\tPer Sample DNN Time 0.02531\tTrain Loss 0.0391\t\n",
      "Epoch: [4][4200/4600]\tPer Sample Total Time 0.02684\tPer Sample Data Time 0.00155\tPer Sample DNN Time 0.02530\tTrain Loss 0.0387\t\n",
      "start validation\n",
      "mAP: 0.197424\n",
      "AUC: 0.821969\n",
      "Avg Precision: 0.026623\n",
      "Avg Recall: 0.873869\n",
      "d_prime: 1.305168\n",
      "train_loss: 0.038713\n",
      "valid_loss: 0.063092\n",
      "validation finished\n",
      "Epoch-4 lr: 0.0005\n",
      "epoch 4 training time: 1031.987\n",
      "---------------\n",
      "2023-07-15 08:54:02.350156\n",
      "current #epochs=5, #steps=18400\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch: [5][600/4600]\tPer Sample Total Time 0.02765\tPer Sample Data Time 0.00217\tPer Sample DNN Time 0.02548\tTrain Loss 0.0442\t\n",
      "Epoch: [5][1600/4600]\tPer Sample Total Time 0.02703\tPer Sample Data Time 0.00171\tPer Sample DNN Time 0.02532\tTrain Loss 0.0411\t\n",
      "Epoch: [5][2600/4600]\tPer Sample Total Time 0.02691\tPer Sample Data Time 0.00162\tPer Sample DNN Time 0.02529\tTrain Loss 0.0394\t\n",
      "Epoch: [5][3600/4600]\tPer Sample Total Time 0.02684\tPer Sample Data Time 0.00157\tPer Sample DNN Time 0.02527\tTrain Loss 0.0386\t\n",
      "start validation\n",
      "mAP: 0.489403\n",
      "AUC: 0.951645\n",
      "Avg Precision: 0.029681\n",
      "Avg Recall: 0.975655\n",
      "d_prime: 2.349039\n",
      "train_loss: 0.038063\n",
      "valid_loss: 0.035690\n",
      "validation finished\n",
      "Epoch-5 lr: 0.0005\n",
      "epoch 5 training time: 1031.530\n",
      "---------------\n",
      "2023-07-15 09:11:13.880116\n",
      "current #epochs=6, #steps=23000\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch: [6][0/4600]\tPer Sample Total Time 0.57212\tPer Sample Data Time 0.35966\tPer Sample DNN Time 0.21246\tTrain Loss 0.0328\t\n",
      "Epoch: [6][1000/4600]\tPer Sample Total Time 0.02723\tPer Sample Data Time 0.00173\tPer Sample DNN Time 0.02549\tTrain Loss 0.0354\t\n",
      "Epoch: [6][2000/4600]\tPer Sample Total Time 0.02700\tPer Sample Data Time 0.00163\tPer Sample DNN Time 0.02537\tTrain Loss 0.0350\t\n",
      "Epoch: [6][3000/4600]\tPer Sample Total Time 0.02691\tPer Sample Data Time 0.00159\tPer Sample DNN Time 0.02533\tTrain Loss 0.0352\t\n",
      "Epoch: [6][4000/4600]\tPer Sample Total Time 0.02687\tPer Sample Data Time 0.00157\tPer Sample DNN Time 0.02530\tTrain Loss 0.0352\t\n",
      "start validation\n",
      "mAP: 0.491549\n",
      "AUC: 0.956428\n",
      "Avg Precision: 0.029773\n",
      "Avg Recall: 0.983606\n",
      "d_prime: 2.419238\n",
      "train_loss: 0.035159\n",
      "valid_loss: 0.035965\n",
      "validation finished\n",
      "Epoch-6 lr: 0.0005\n",
      "epoch 6 training time: 1034.036\n",
      "---------------\n",
      "2023-07-15 09:28:27.915896\n",
      "current #epochs=7, #steps=27600\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch: [7][400/4600]\tPer Sample Total Time 0.02822\tPer Sample Data Time 0.00254\tPer Sample DNN Time 0.02568\tTrain Loss 0.0340\t\n",
      "Epoch: [7][1400/4600]\tPer Sample Total Time 0.02712\tPer Sample Data Time 0.00176\tPer Sample DNN Time 0.02536\tTrain Loss 0.0358\t\n",
      "Epoch: [7][2400/4600]\tPer Sample Total Time 0.02695\tPer Sample Data Time 0.00164\tPer Sample DNN Time 0.02531\tTrain Loss 0.0355\t\n",
      "Epoch: [7][3400/4600]\tPer Sample Total Time 0.02688\tPer Sample Data Time 0.00160\tPer Sample DNN Time 0.02528\tTrain Loss 0.0352\t\n",
      "Epoch: [7][4400/4600]\tPer Sample Total Time 0.02683\tPer Sample Data Time 0.00157\tPer Sample DNN Time 0.02527\tTrain Loss 0.0350\t\n",
      "start validation\n",
      "mAP: 0.507215\n",
      "AUC: 0.951877\n",
      "Avg Precision: 0.029602\n",
      "Avg Recall: 0.975742\n",
      "d_prime: 2.352310\n",
      "train_loss: 0.035008\n",
      "valid_loss: 0.035581\n",
      "validation finished\n",
      "Epoch-7 lr: 0.0005\n",
      "epoch 7 training time: 1032.852\n",
      "---------------\n",
      "2023-07-15 09:45:40.767892\n",
      "current #epochs=8, #steps=32200\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch: [8][800/4600]\tPer Sample Total Time 0.02742\tPer Sample Data Time 0.00199\tPer Sample DNN Time 0.02543\tTrain Loss 0.0345\t\n",
      "Epoch: [8][1800/4600]\tPer Sample Total Time 0.02696\tPer Sample Data Time 0.00164\tPer Sample DNN Time 0.02532\tTrain Loss 0.0352\t\n",
      "Epoch: [8][2800/4600]\tPer Sample Total Time 0.02685\tPer Sample Data Time 0.00156\tPer Sample DNN Time 0.02529\tTrain Loss 0.0350\t\n",
      "Epoch: [8][3800/4600]\tPer Sample Total Time 0.02678\tPer Sample Data Time 0.00151\tPer Sample DNN Time 0.02528\tTrain Loss 0.0349\t\n",
      "start validation\n",
      "mAP: 0.508024\n",
      "AUC: 0.954546\n",
      "Avg Precision: 0.029773\n",
      "Avg Recall: 0.979096\n",
      "d_prime: 2.390915\n",
      "train_loss: 0.034658\n",
      "valid_loss: 0.034232\n",
      "validation finished\n",
      "Epoch-8 lr: 0.0005\n",
      "epoch 8 training time: 1030.596\n",
      "---------------\n",
      "2023-07-15 10:02:51.363808\n",
      "current #epochs=9, #steps=36800\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch: [9][200/4600]\tPer Sample Total Time 0.02948\tPer Sample Data Time 0.00347\tPer Sample DNN Time 0.02601\tTrain Loss 0.0339\t\n",
      "Epoch: [9][1200/4600]\tPer Sample Total Time 0.02702\tPer Sample Data Time 0.00166\tPer Sample DNN Time 0.02536\tTrain Loss 0.0335\t\n",
      "Epoch: [9][2200/4600]\tPer Sample Total Time 0.02682\tPer Sample Data Time 0.00152\tPer Sample DNN Time 0.02530\tTrain Loss 0.0333\t\n",
      "Epoch: [9][3200/4600]\tPer Sample Total Time 0.02673\tPer Sample Data Time 0.00145\tPer Sample DNN Time 0.02528\tTrain Loss 0.0331\t\n",
      "Epoch: [9][4200/4600]\tPer Sample Total Time 0.02668\tPer Sample Data Time 0.00141\tPer Sample DNN Time 0.02526\tTrain Loss 0.0331\t\n",
      "start validation\n",
      "mAP: 0.518897\n",
      "AUC: 0.952828\n",
      "Avg Precision: 0.029642\n",
      "Avg Recall: 0.976205\n",
      "d_prime: 2.365854\n",
      "train_loss: 0.033120\n",
      "valid_loss: 0.034828\n",
      "validation finished\n",
      "Epoch-9 lr: 0.0005\n",
      "epoch 9 training time: 1026.731\n",
      "---------------\n",
      "2023-07-15 10:19:58.095386\n",
      "current #epochs=10, #steps=41400\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch: [10][600/4600]\tPer Sample Total Time 0.02750\tPer Sample Data Time 0.00192\tPer Sample DNN Time 0.02558\tTrain Loss 0.0333\t\n",
      "Epoch: [10][1600/4600]\tPer Sample Total Time 0.02688\tPer Sample Data Time 0.00153\tPer Sample DNN Time 0.02535\tTrain Loss 0.0336\t\n",
      "Epoch: [10][2600/4600]\tPer Sample Total Time 0.02673\tPer Sample Data Time 0.00145\tPer Sample DNN Time 0.02529\tTrain Loss 0.0332\t\n",
      "Epoch: [10][3600/4600]\tPer Sample Total Time 0.02668\tPer Sample Data Time 0.00141\tPer Sample DNN Time 0.02527\tTrain Loss 0.0330\t\n",
      "start validation\n",
      "mAP: 0.531739\n",
      "AUC: 0.952900\n",
      "Avg Precision: 0.029703\n",
      "Avg Recall: 0.977284\n",
      "d_prime: 2.366898\n",
      "train_loss: 0.032752\n",
      "valid_loss: 0.034225\n",
      "validation finished\n",
      "Epoch-10 lr: 0.00025\n",
      "epoch 10 training time: 1027.554\n",
      "---------------\n",
      "2023-07-15 10:37:05.650253\n",
      "current #epochs=11, #steps=46000\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch: [11][0/4600]\tPer Sample Total Time 0.53765\tPer Sample Data Time 0.40266\tPer Sample DNN Time 0.13499\tTrain Loss 0.0401\t\n",
      "Epoch: [11][1000/4600]\tPer Sample Total Time 0.02729\tPer Sample Data Time 0.00188\tPer Sample DNN Time 0.02541\tTrain Loss 0.0308\t\n",
      "Epoch: [11][2000/4600]\tPer Sample Total Time 0.02699\tPer Sample Data Time 0.00167\tPer Sample DNN Time 0.02532\tTrain Loss 0.0305\t\n",
      "Epoch: [11][3000/4600]\tPer Sample Total Time 0.02689\tPer Sample Data Time 0.00159\tPer Sample DNN Time 0.02529\tTrain Loss 0.0306\t\n",
      "Epoch: [11][4000/4600]\tPer Sample Total Time 0.02684\tPer Sample Data Time 0.00156\tPer Sample DNN Time 0.02528\tTrain Loss 0.0303\t\n",
      "start validation\n",
      "mAP: 0.551157\n",
      "AUC: 0.960000\n",
      "Avg Precision: 0.029777\n",
      "Avg Recall: 0.980801\n",
      "d_prime: 2.475840\n",
      "train_loss: 0.030110\n",
      "valid_loss: 0.033527\n",
      "validation finished\n",
      "Epoch-11 lr: 0.00025\n",
      "epoch 11 training time: 1033.156\n",
      "---------------\n",
      "2023-07-15 10:54:18.805710\n",
      "current #epochs=12, #steps=50600\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch: [12][400/4600]\tPer Sample Total Time 0.02828\tPer Sample Data Time 0.00251\tPer Sample DNN Time 0.02577\tTrain Loss 0.0293\t\n",
      "Epoch: [12][1400/4600]\tPer Sample Total Time 0.02712\tPer Sample Data Time 0.00173\tPer Sample DNN Time 0.02539\tTrain Loss 0.0290\t\n",
      "Epoch: [12][2400/4600]\tPer Sample Total Time 0.02693\tPer Sample Data Time 0.00161\tPer Sample DNN Time 0.02532\tTrain Loss 0.0291\t\n",
      "Epoch: [12][3400/4600]\tPer Sample Total Time 0.02684\tPer Sample Data Time 0.00155\tPer Sample DNN Time 0.02529\tTrain Loss 0.0295\t\n",
      "Epoch: [12][4400/4600]\tPer Sample Total Time 0.02680\tPer Sample Data Time 0.00153\tPer Sample DNN Time 0.02527\tTrain Loss 0.0295\t\n",
      "start validation\n",
      "mAP: 0.551746\n",
      "AUC: 0.957066\n",
      "Avg Precision: 0.029745\n",
      "Avg Recall: 0.978715\n",
      "d_prime: 2.429072\n",
      "train_loss: 0.029516\n",
      "valid_loss: 0.032812\n",
      "validation finished\n",
      "Epoch-12 lr: 0.00025\n",
      "epoch 12 training time: 1032.598\n",
      "---------------\n",
      "2023-07-15 11:11:31.404113\n",
      "current #epochs=13, #steps=55200\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch: [13][800/4600]\tPer Sample Total Time 0.02749\tPer Sample Data Time 0.00197\tPer Sample DNN Time 0.02552\tTrain Loss 0.0287\t\n",
      "Epoch: [13][1800/4600]\tPer Sample Total Time 0.02705\tPer Sample Data Time 0.00168\tPer Sample DNN Time 0.02538\tTrain Loss 0.0285\t\n",
      "Epoch: [13][2800/4600]\tPer Sample Total Time 0.02694\tPer Sample Data Time 0.00161\tPer Sample DNN Time 0.02532\tTrain Loss 0.0284\t\n",
      "Epoch: [13][3800/4600]\tPer Sample Total Time 0.02687\tPer Sample Data Time 0.00157\tPer Sample DNN Time 0.02530\tTrain Loss 0.0284\t\n",
      "start validation\n",
      "mAP: 0.554369\n",
      "AUC: 0.957592\n",
      "Avg Precision: 0.029766\n",
      "Avg Recall: 0.980165\n",
      "d_prime: 2.437250\n",
      "train_loss: 0.028416\n",
      "valid_loss: 0.032820\n",
      "validation finished\n",
      "Epoch-13 lr: 0.00025\n",
      "epoch 13 training time: 1033.840\n",
      "---------------\n",
      "2023-07-15 11:28:45.244517\n",
      "current #epochs=14, #steps=59800\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch: [14][200/4600]\tPer Sample Total Time 0.02981\tPer Sample Data Time 0.00407\tPer Sample DNN Time 0.02574\tTrain Loss 0.0288\t\n",
      "Epoch: [14][1200/4600]\tPer Sample Total Time 0.02719\tPer Sample Data Time 0.00186\tPer Sample DNN Time 0.02532\tTrain Loss 0.0286\t\n",
      "Epoch: [14][2200/4600]\tPer Sample Total Time 0.02694\tPer Sample Data Time 0.00166\tPer Sample DNN Time 0.02528\tTrain Loss 0.0285\t\n",
      "Epoch: [14][3200/4600]\tPer Sample Total Time 0.02685\tPer Sample Data Time 0.00159\tPer Sample DNN Time 0.02526\tTrain Loss 0.0284\t\n",
      "Epoch: [14][4200/4600]\tPer Sample Total Time 0.02680\tPer Sample Data Time 0.00155\tPer Sample DNN Time 0.02525\tTrain Loss 0.0293\t\n",
      "start validation\n",
      "mAP: 0.542907\n",
      "AUC: 0.957745\n",
      "Avg Precision: 0.029777\n",
      "Avg Recall: 0.981093\n",
      "d_prime: 2.439659\n",
      "train_loss: 0.029383\n",
      "valid_loss: 0.033072\n",
      "validation finished\n",
      "Epoch-14 lr: 0.00025\n",
      "epoch 14 training time: 1029.581\n",
      "---------------\n",
      "2023-07-15 11:45:54.825785\n",
      "current #epochs=15, #steps=64400\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch: [15][600/4600]\tPer Sample Total Time 0.02784\tPer Sample Data Time 0.00211\tPer Sample DNN Time 0.02574\tTrain Loss 0.0290\t\n",
      "Epoch: [15][1600/4600]\tPer Sample Total Time 0.02717\tPer Sample Data Time 0.00172\tPer Sample DNN Time 0.02545\tTrain Loss 0.0283\t\n",
      "Epoch: [15][2600/4600]\tPer Sample Total Time 0.02702\tPer Sample Data Time 0.00165\tPer Sample DNN Time 0.02537\tTrain Loss 0.0281\t\n",
      "Epoch: [15][3600/4600]\tPer Sample Total Time 0.02694\tPer Sample Data Time 0.00161\tPer Sample DNN Time 0.02534\tTrain Loss 0.0282\t\n",
      "start validation\n",
      "mAP: 0.555305\n",
      "AUC: 0.958612\n",
      "Avg Precision: 0.029810\n",
      "Avg Recall: 0.982600\n",
      "d_prime: 2.453380\n",
      "train_loss: 0.028157\n",
      "valid_loss: 0.032958\n",
      "validation finished\n",
      "Epoch-15 lr: 0.000125\n",
      "epoch 15 training time: 1035.675\n",
      "---------------\n",
      "2023-07-15 12:03:10.500828\n",
      "current #epochs=16, #steps=69000\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch: [16][0/4600]\tPer Sample Total Time 0.55586\tPer Sample Data Time 0.38353\tPer Sample DNN Time 0.17233\tTrain Loss 0.0259\t\n",
      "Epoch: [16][1000/4600]\tPer Sample Total Time 0.02728\tPer Sample Data Time 0.00181\tPer Sample DNN Time 0.02548\tTrain Loss 0.0279\t\n",
      "Epoch: [16][2000/4600]\tPer Sample Total Time 0.02698\tPer Sample Data Time 0.00163\tPer Sample DNN Time 0.02535\tTrain Loss 0.0272\t\n",
      "Epoch: [16][3000/4600]\tPer Sample Total Time 0.02688\tPer Sample Data Time 0.00157\tPer Sample DNN Time 0.02531\tTrain Loss 0.0271\t\n",
      "Epoch: [16][4000/4600]\tPer Sample Total Time 0.02682\tPer Sample Data Time 0.00153\tPer Sample DNN Time 0.02529\tTrain Loss 0.0270\t\n",
      "start validation\n",
      "mAP: 0.562850\n",
      "AUC: 0.956097\n",
      "Avg Precision: 0.029767\n",
      "Avg Recall: 0.977318\n",
      "d_prime: 2.414181\n",
      "train_loss: 0.026931\n",
      "valid_loss: 0.032681\n",
      "validation finished\n",
      "Epoch-16 lr: 0.000125\n",
      "epoch 16 training time: 1032.602\n",
      "---------------\n",
      "2023-07-15 12:20:23.102634\n",
      "current #epochs=17, #steps=73600\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch: [17][400/4600]\tPer Sample Total Time 0.02819\tPer Sample Data Time 0.00245\tPer Sample DNN Time 0.02574\tTrain Loss 0.0265\t\n",
      "Epoch: [17][1400/4600]\tPer Sample Total Time 0.02721\tPer Sample Data Time 0.00178\tPer Sample DNN Time 0.02544\tTrain Loss 0.0266\t\n",
      "Epoch: [17][2400/4600]\tPer Sample Total Time 0.02704\tPer Sample Data Time 0.00168\tPer Sample DNN Time 0.02536\tTrain Loss 0.0266\t\n",
      "Epoch: [17][3400/4600]\tPer Sample Total Time 0.02695\tPer Sample Data Time 0.00163\tPer Sample DNN Time 0.02533\tTrain Loss 0.0266\t\n",
      "Epoch: [17][4400/4600]\tPer Sample Total Time 0.02691\tPer Sample Data Time 0.00160\tPer Sample DNN Time 0.02531\tTrain Loss 0.0265\t\n",
      "start validation\n",
      "mAP: 0.570303\n",
      "AUC: 0.958437\n",
      "Avg Precision: 0.029828\n",
      "Avg Recall: 0.981374\n",
      "d_prime: 2.450595\n",
      "train_loss: 0.026492\n",
      "valid_loss: 0.032165\n",
      "validation finished\n",
      "Epoch-17 lr: 0.000125\n",
      "epoch 17 training time: 1035.624\n",
      "---------------\n",
      "2023-07-15 12:37:38.726930\n",
      "current #epochs=18, #steps=78200\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch: [18][800/4600]\tPer Sample Total Time 0.02758\tPer Sample Data Time 0.00193\tPer Sample DNN Time 0.02565\tTrain Loss 0.0261\t\n",
      "Epoch: [18][1800/4600]\tPer Sample Total Time 0.02701\tPer Sample Data Time 0.00158\tPer Sample DNN Time 0.02543\tTrain Loss 0.0261\t\n",
      "Epoch: [18][2800/4600]\tPer Sample Total Time 0.02686\tPer Sample Data Time 0.00150\tPer Sample DNN Time 0.02536\tTrain Loss 0.0260\t\n",
      "Epoch: [18][3800/4600]\tPer Sample Total Time 0.02683\tPer Sample Data Time 0.00150\tPer Sample DNN Time 0.02533\tTrain Loss 0.0261\t\n",
      "start validation\n",
      "mAP: 0.571674\n",
      "AUC: 0.958294\n",
      "Avg Precision: 0.029807\n",
      "Avg Recall: 0.981768\n",
      "d_prime: 2.448316\n",
      "train_loss: 0.026118\n",
      "valid_loss: 0.032174\n",
      "validation finished\n",
      "Epoch-18 lr: 0.000125\n",
      "epoch 18 training time: 1034.379\n",
      "---------------\n",
      "2023-07-15 12:54:53.106059\n",
      "current #epochs=19, #steps=82800\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch: [19][200/4600]\tPer Sample Total Time 0.02968\tPer Sample Data Time 0.00405\tPer Sample DNN Time 0.02564\tTrain Loss 0.0267\t\n",
      "Epoch: [19][1200/4600]\tPer Sample Total Time 0.02717\tPer Sample Data Time 0.00187\tPer Sample DNN Time 0.02531\tTrain Loss 0.0258\t\n",
      "Epoch: [19][2200/4600]\tPer Sample Total Time 0.02696\tPer Sample Data Time 0.00168\tPer Sample DNN Time 0.02528\tTrain Loss 0.0260\t\n",
      "Epoch: [19][3200/4600]\tPer Sample Total Time 0.02686\tPer Sample Data Time 0.00160\tPer Sample DNN Time 0.02526\tTrain Loss 0.0259\t\n",
      "Epoch: [19][4200/4600]\tPer Sample Total Time 0.02682\tPer Sample Data Time 0.00156\tPer Sample DNN Time 0.02526\tTrain Loss 0.0259\t\n",
      "start validation\n",
      "mAP: 0.571185\n",
      "AUC: 0.958184\n",
      "Avg Precision: 0.029789\n",
      "Avg Recall: 0.978525\n",
      "d_prime: 2.446571\n",
      "train_loss: 0.025933\n",
      "valid_loss: 0.032154\n",
      "validation finished\n",
      "Epoch-19 lr: 0.000125\n",
      "epoch 19 training time: 1031.890\n",
      "---------------\n",
      "2023-07-15 13:12:04.995524\n",
      "current #epochs=20, #steps=87400\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch: [20][600/4600]\tPer Sample Total Time 0.02786\tPer Sample Data Time 0.00222\tPer Sample DNN Time 0.02564\tTrain Loss 0.0256\t\n",
      "Epoch: [20][1600/4600]\tPer Sample Total Time 0.02712\tPer Sample Data Time 0.00173\tPer Sample DNN Time 0.02539\tTrain Loss 0.0257\t\n",
      "Epoch: [20][2600/4600]\tPer Sample Total Time 0.02696\tPer Sample Data Time 0.00163\tPer Sample DNN Time 0.02533\tTrain Loss 0.0256\t\n",
      "Epoch: [20][3600/4600]\tPer Sample Total Time 0.02687\tPer Sample Data Time 0.00157\tPer Sample DNN Time 0.02530\tTrain Loss 0.0258\t\n",
      "start validation\n",
      "mAP: 0.571686\n",
      "AUC: 0.957521\n",
      "Avg Precision: 0.029766\n",
      "Avg Recall: 0.978931\n",
      "d_prime: 2.436147\n",
      "train_loss: 0.025747\n",
      "valid_loss: 0.031845\n",
      "validation finished\n",
      "Epoch-20 lr: 6.25e-05\n",
      "epoch 20 training time: 1032.961\n",
      "---------------\n",
      "2023-07-15 13:29:17.956326\n",
      "current #epochs=21, #steps=92000\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch: [21][0/4600]\tPer Sample Total Time 0.66348\tPer Sample Data Time 0.36404\tPer Sample DNN Time 0.29944\tTrain Loss 0.0333\t\n",
      "Epoch: [21][1000/4600]\tPer Sample Total Time 0.02721\tPer Sample Data Time 0.00166\tPer Sample DNN Time 0.02555\tTrain Loss 0.0252\t\n",
      "Epoch: [21][2000/4600]\tPer Sample Total Time 0.02684\tPer Sample Data Time 0.00146\tPer Sample DNN Time 0.02538\tTrain Loss 0.0251\t\n",
      "Epoch: [21][3000/4600]\tPer Sample Total Time 0.02675\tPer Sample Data Time 0.00142\tPer Sample DNN Time 0.02533\tTrain Loss 0.0251\t\n",
      "Epoch: [21][4000/4600]\tPer Sample Total Time 0.02669\tPer Sample Data Time 0.00139\tPer Sample DNN Time 0.02530\tTrain Loss 0.0250\t\n",
      "start validation\n",
      "mAP: 0.575430\n",
      "AUC: 0.958209\n",
      "Avg Precision: 0.029793\n",
      "Avg Recall: 0.980165\n",
      "d_prime: 2.446966\n",
      "train_loss: 0.025037\n",
      "valid_loss: 0.032076\n",
      "validation finished\n",
      "Epoch-21 lr: 6.25e-05\n",
      "epoch 21 training time: 1026.739\n",
      "---------------\n",
      "2023-07-15 13:46:24.695349\n",
      "current #epochs=22, #steps=96600\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch: [22][400/4600]\tPer Sample Total Time 0.02840\tPer Sample Data Time 0.00280\tPer Sample DNN Time 0.02560\tTrain Loss 0.0248\t\n",
      "Epoch: [22][1400/4600]\tPer Sample Total Time 0.02719\tPer Sample Data Time 0.00183\tPer Sample DNN Time 0.02535\tTrain Loss 0.0246\t\n",
      "Epoch: [22][2400/4600]\tPer Sample Total Time 0.02699\tPer Sample Data Time 0.00168\tPer Sample DNN Time 0.02531\tTrain Loss 0.0248\t\n",
      "Epoch: [22][3400/4600]\tPer Sample Total Time 0.02690\tPer Sample Data Time 0.00161\tPer Sample DNN Time 0.02529\tTrain Loss 0.0248\t\n",
      "Epoch: [22][4400/4600]\tPer Sample Total Time 0.02685\tPer Sample Data Time 0.00158\tPer Sample DNN Time 0.02528\tTrain Loss 0.0249\t\n",
      "start validation\n",
      "mAP: 0.578021\n",
      "AUC: 0.959128\n",
      "Avg Precision: 0.029776\n",
      "Avg Recall: 0.978104\n",
      "d_prime: 2.461662\n",
      "train_loss: 0.024845\n",
      "valid_loss: 0.032058\n",
      "validation finished\n",
      "Epoch-22 lr: 6.25e-05\n",
      "epoch 22 training time: 1034.267\n",
      "---------------\n",
      "2023-07-15 14:03:38.962076\n",
      "current #epochs=23, #steps=101200\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch: [23][800/4600]\tPer Sample Total Time 0.02736\tPer Sample Data Time 0.00197\tPer Sample DNN Time 0.02539\tTrain Loss 0.0245\t\n",
      "Epoch: [23][1800/4600]\tPer Sample Total Time 0.02691\tPer Sample Data Time 0.00160\tPer Sample DNN Time 0.02531\tTrain Loss 0.0244\t\n",
      "Epoch: [23][2800/4600]\tPer Sample Total Time 0.02678\tPer Sample Data Time 0.00150\tPer Sample DNN Time 0.02528\tTrain Loss 0.0247\t\n",
      "Epoch: [23][3800/4600]\tPer Sample Total Time 0.02671\tPer Sample Data Time 0.00145\tPer Sample DNN Time 0.02526\tTrain Loss 0.0247\t\n",
      "start validation\n",
      "mAP: 0.581174\n",
      "AUC: 0.959914\n",
      "Avg Precision: 0.029803\n",
      "Avg Recall: 0.980639\n",
      "d_prime: 2.474442\n",
      "train_loss: 0.024635\n",
      "valid_loss: 0.031727\n",
      "validation finished\n",
      "Epoch-23 lr: 6.25e-05\n",
      "epoch 23 training time: 1027.138\n",
      "---------------\n",
      "2023-07-15 14:20:46.100185\n",
      "current #epochs=24, #steps=105800\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch: [24][200/4600]\tPer Sample Total Time 0.03024\tPer Sample Data Time 0.00316\tPer Sample DNN Time 0.02708\tTrain Loss 0.0242\t\n",
      "Epoch: [24][1200/4600]\tPer Sample Total Time 0.02732\tPer Sample Data Time 0.00175\tPer Sample DNN Time 0.02557\tTrain Loss 0.0244\t\n",
      "Epoch: [24][2200/4600]\tPer Sample Total Time 0.02706\tPer Sample Data Time 0.00164\tPer Sample DNN Time 0.02543\tTrain Loss 0.0243\t\n",
      "Epoch: [24][3200/4600]\tPer Sample Total Time 0.02696\tPer Sample Data Time 0.00159\tPer Sample DNN Time 0.02537\tTrain Loss 0.0243\t\n",
      "Epoch: [24][4200/4600]\tPer Sample Total Time 0.02691\tPer Sample Data Time 0.00156\tPer Sample DNN Time 0.02535\tTrain Loss 0.0244\t\n",
      "start validation\n",
      "mAP: 0.579677\n",
      "AUC: 0.957148\n",
      "Avg Precision: 0.029755\n",
      "Avg Recall: 0.976774\n",
      "d_prime: 2.430333\n",
      "train_loss: 0.024405\n",
      "valid_loss: 0.031699\n",
      "validation finished\n",
      "Epoch-24 lr: 6.25e-05\n",
      "epoch 24 training time: 1034.838\n",
      "---------------\n",
      "2023-07-15 14:38:00.937821\n",
      "current #epochs=25, #steps=110400\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch: [25][600/4600]\tPer Sample Total Time 0.02781\tPer Sample Data Time 0.00250\tPer Sample DNN Time 0.02531\tTrain Loss 0.0244\t\n",
      "Epoch: [25][1600/4600]\tPer Sample Total Time 0.02707\tPer Sample Data Time 0.00179\tPer Sample DNN Time 0.02528\tTrain Loss 0.0245\t\n",
      "Epoch: [25][2600/4600]\tPer Sample Total Time 0.02687\tPer Sample Data Time 0.00160\tPer Sample DNN Time 0.02526\tTrain Loss 0.0244\t\n",
      "Epoch: [25][3600/4600]\tPer Sample Total Time 0.02676\tPer Sample Data Time 0.00151\tPer Sample DNN Time 0.02525\tTrain Loss 0.0243\t\n",
      "start validation\n",
      "mAP: 0.580069\n",
      "AUC: 0.958947\n",
      "Avg Precision: 0.029794\n",
      "Avg Recall: 0.978662\n",
      "d_prime: 2.458745\n",
      "train_loss: 0.024244\n",
      "valid_loss: 0.032536\n",
      "validation finished\n",
      "Epoch-25 lr: 3.125e-05\n",
      "epoch 25 training time: 1028.479\n",
      "---------------\n",
      "2023-07-15 14:55:09.417461\n",
      "current #epochs=26, #steps=115000\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch: [26][0/4600]\tPer Sample Total Time 0.64376\tPer Sample Data Time 0.49437\tPer Sample DNN Time 0.14940\tTrain Loss 0.0413\t\n",
      "Epoch: [26][1000/4600]\tPer Sample Total Time 0.02718\tPer Sample Data Time 0.00183\tPer Sample DNN Time 0.02535\tTrain Loss 0.0238\t\n",
      "Epoch: [26][2000/4600]\tPer Sample Total Time 0.02685\tPer Sample Data Time 0.00157\tPer Sample DNN Time 0.02529\tTrain Loss 0.0240\t\n",
      "Epoch: [26][3000/4600]\tPer Sample Total Time 0.02675\tPer Sample Data Time 0.00149\tPer Sample DNN Time 0.02527\tTrain Loss 0.0240\t\n",
      "Epoch: [26][4000/4600]\tPer Sample Total Time 0.02669\tPer Sample Data Time 0.00144\tPer Sample DNN Time 0.02525\tTrain Loss 0.0241\t\n",
      "start validation\n",
      "mAP: 0.584227\n",
      "AUC: 0.959752\n",
      "Avg Precision: 0.029817\n",
      "Avg Recall: 0.978757\n",
      "d_prime: 2.471787\n",
      "train_loss: 0.024096\n",
      "valid_loss: 0.031947\n",
      "validation finished\n",
      "Epoch-26 lr: 3.125e-05\n",
      "epoch 26 training time: 1028.103\n",
      "---------------\n",
      "2023-07-15 15:12:17.520382\n",
      "current #epochs=27, #steps=119600\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch: [27][400/4600]\tPer Sample Total Time 0.02827\tPer Sample Data Time 0.00249\tPer Sample DNN Time 0.02578\tTrain Loss 0.0236\t\n",
      "Epoch: [27][1400/4600]\tPer Sample Total Time 0.02703\tPer Sample Data Time 0.00163\tPer Sample DNN Time 0.02539\tTrain Loss 0.0238\t\n",
      "Epoch: [27][2400/4600]\tPer Sample Total Time 0.02682\tPer Sample Data Time 0.00150\tPer Sample DNN Time 0.02532\tTrain Loss 0.0239\t\n",
      "Epoch: [27][3400/4600]\tPer Sample Total Time 0.02673\tPer Sample Data Time 0.00144\tPer Sample DNN Time 0.02529\tTrain Loss 0.0239\t\n",
      "Epoch: [27][4400/4600]\tPer Sample Total Time 0.02668\tPer Sample Data Time 0.00140\tPer Sample DNN Time 0.02528\tTrain Loss 0.0238\t\n",
      "start validation\n",
      "mAP: 0.584186\n",
      "AUC: 0.957401\n",
      "Avg Precision: 0.029768\n",
      "Avg Recall: 0.978469\n",
      "d_prime: 2.434273\n",
      "train_loss: 0.023752\n",
      "valid_loss: 0.031865\n",
      "validation finished\n",
      "Epoch-27 lr: 3.125e-05\n",
      "epoch 27 training time: 1025.960\n",
      "---------------\n",
      "2023-07-15 15:29:23.480181\n",
      "current #epochs=28, #steps=124200\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch: [28][800/4600]\tPer Sample Total Time 0.02740\tPer Sample Data Time 0.00202\tPer Sample DNN Time 0.02538\tTrain Loss 0.0236\t\n",
      "Epoch: [28][1800/4600]\tPer Sample Total Time 0.02696\tPer Sample Data Time 0.00166\tPer Sample DNN Time 0.02531\tTrain Loss 0.0236\t\n",
      "Epoch: [28][2800/4600]\tPer Sample Total Time 0.02686\tPer Sample Data Time 0.00157\tPer Sample DNN Time 0.02529\tTrain Loss 0.0235\t\n",
      "Epoch: [28][3800/4600]\tPer Sample Total Time 0.02682\tPer Sample Data Time 0.00152\tPer Sample DNN Time 0.02529\tTrain Loss 0.0236\t\n",
      "start validation\n",
      "mAP: 0.582684\n",
      "AUC: 0.953787\n",
      "Avg Precision: 0.029657\n",
      "Avg Recall: 0.972315\n",
      "d_prime: 2.379750\n",
      "train_loss: 0.023548\n",
      "valid_loss: 0.032657\n",
      "validation finished\n",
      "Epoch-28 lr: 3.125e-05\n",
      "epoch 28 training time: 1031.397\n",
      "---------------\n",
      "2023-07-15 15:46:34.877390\n",
      "current #epochs=29, #steps=128800\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch: [29][200/4600]\tPer Sample Total Time 0.02992\tPer Sample Data Time 0.00360\tPer Sample DNN Time 0.02632\tTrain Loss 0.0238\t\n",
      "Epoch: [29][1200/4600]\tPer Sample Total Time 0.02704\tPer Sample Data Time 0.00162\tPer Sample DNN Time 0.02541\tTrain Loss 0.0236\t\n",
      "Epoch: [29][2200/4600]\tPer Sample Total Time 0.02680\tPer Sample Data Time 0.00147\tPer Sample DNN Time 0.02533\tTrain Loss 0.0237\t\n",
      "Epoch: [29][3200/4600]\tPer Sample Total Time 0.02670\tPer Sample Data Time 0.00141\tPer Sample DNN Time 0.02529\tTrain Loss 0.0236\t\n",
      "Epoch: [29][4200/4600]\tPer Sample Total Time 0.02665\tPer Sample Data Time 0.00138\tPer Sample DNN Time 0.02528\tTrain Loss 0.0236\t\n",
      "start validation\n",
      "mAP: 0.583079\n",
      "AUC: 0.958282\n",
      "Avg Precision: 0.029775\n",
      "Avg Recall: 0.978782\n",
      "d_prime: 2.448136\n",
      "train_loss: 0.023620\n",
      "valid_loss: 0.032020\n",
      "validation finished\n",
      "Epoch-29 lr: 3.125e-05\n",
      "epoch 29 training time: 1023.943\n",
      "---------------\n",
      "2023-07-15 16:03:38.821437\n",
      "current #epochs=30, #steps=133400\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch: [30][600/4600]\tPer Sample Total Time 0.02765\tPer Sample Data Time 0.00202\tPer Sample DNN Time 0.02563\tTrain Loss 0.0237\t\n",
      "Epoch: [30][1600/4600]\tPer Sample Total Time 0.02698\tPer Sample Data Time 0.00159\tPer Sample DNN Time 0.02539\tTrain Loss 0.0235\t\n",
      "Epoch: [30][2600/4600]\tPer Sample Total Time 0.02683\tPer Sample Data Time 0.00149\tPer Sample DNN Time 0.02534\tTrain Loss 0.0234\t\n",
      "Epoch: [30][3600/4600]\tPer Sample Total Time 0.02677\tPer Sample Data Time 0.00146\tPer Sample DNN Time 0.02531\tTrain Loss 0.0235\t\n",
      "start validation\n",
      "mAP: 0.581120\n",
      "AUC: 0.956582\n",
      "Avg Precision: 0.029759\n",
      "Avg Recall: 0.978161\n",
      "d_prime: 2.421594\n",
      "train_loss: 0.023478\n",
      "valid_loss: 0.032806\n",
      "validation finished\n",
      "Epoch-30 lr: 1.5625e-05\n",
      "epoch 30 training time: 1028.673\n",
      "---------------\n",
      "2023-07-15 16:20:47.494477\n",
      "current #epochs=31, #steps=138000\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch: [31][0/4600]\tPer Sample Total Time 0.58299\tPer Sample Data Time 0.45917\tPer Sample DNN Time 0.12382\tTrain Loss 0.0196\t\n",
      "Epoch: [31][1000/4600]\tPer Sample Total Time 0.02717\tPer Sample Data Time 0.00179\tPer Sample DNN Time 0.02539\tTrain Loss 0.0239\t\n",
      "Epoch: [31][2000/4600]\tPer Sample Total Time 0.02687\tPer Sample Data Time 0.00156\tPer Sample DNN Time 0.02531\tTrain Loss 0.0234\t\n",
      "Epoch: [31][3000/4600]\tPer Sample Total Time 0.02676\tPer Sample Data Time 0.00148\tPer Sample DNN Time 0.02528\tTrain Loss 0.0236\t\n",
      "Epoch: [31][4000/4600]\tPer Sample Total Time 0.02671\tPer Sample Data Time 0.00144\tPer Sample DNN Time 0.02527\tTrain Loss 0.0235\t\n",
      "start validation\n",
      "mAP: 0.587490\n",
      "AUC: 0.958913\n",
      "Avg Precision: 0.029793\n",
      "Avg Recall: 0.978753\n",
      "d_prime: 2.458200\n",
      "train_loss: 0.023470\n",
      "valid_loss: 0.032135\n",
      "validation finished\n",
      "Epoch-31 lr: 1.5625e-05\n",
      "epoch 31 training time: 1028.084\n",
      "---------------\n",
      "2023-07-15 16:37:55.579718\n",
      "current #epochs=32, #steps=142600\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch: [32][400/4600]\tPer Sample Total Time 0.02819\tPer Sample Data Time 0.00241\tPer Sample DNN Time 0.02578\tTrain Loss 0.0229\t\n",
      "Epoch: [32][1400/4600]\tPer Sample Total Time 0.02705\tPer Sample Data Time 0.00165\tPer Sample DNN Time 0.02540\tTrain Loss 0.0233\t\n",
      "Epoch: [32][2400/4600]\tPer Sample Total Time 0.02685\tPer Sample Data Time 0.00151\tPer Sample DNN Time 0.02533\tTrain Loss 0.0234\t\n",
      "Epoch: [32][3400/4600]\tPer Sample Total Time 0.02675\tPer Sample Data Time 0.00145\tPer Sample DNN Time 0.02530\tTrain Loss 0.0232\t\n",
      "Epoch: [32][4400/4600]\tPer Sample Total Time 0.02670\tPer Sample Data Time 0.00142\tPer Sample DNN Time 0.02528\tTrain Loss 0.0233\t\n",
      "start validation\n",
      "mAP: 0.584093\n",
      "AUC: 0.958248\n",
      "Avg Precision: 0.029801\n",
      "Avg Recall: 0.977883\n",
      "d_prime: 2.447595\n",
      "train_loss: 0.023300\n",
      "valid_loss: 0.032398\n",
      "validation finished\n",
      "Epoch-32 lr: 1.5625e-05\n",
      "epoch 32 training time: 1026.870\n",
      "---------------\n",
      "2023-07-15 16:55:02.449574\n",
      "current #epochs=33, #steps=147200\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch: [33][800/4600]\tPer Sample Total Time 0.02718\tPer Sample Data Time 0.00180\tPer Sample DNN Time 0.02539\tTrain Loss 0.0232\t\n",
      "Epoch: [33][1800/4600]\tPer Sample Total Time 0.02679\tPer Sample Data Time 0.00149\tPer Sample DNN Time 0.02530\tTrain Loss 0.0229\t\n",
      "Epoch: [33][2800/4600]\tPer Sample Total Time 0.02667\tPer Sample Data Time 0.00140\tPer Sample DNN Time 0.02527\tTrain Loss 0.0230\t\n",
      "Epoch: [33][3800/4600]\tPer Sample Total Time 0.02662\tPer Sample Data Time 0.00137\tPer Sample DNN Time 0.02525\tTrain Loss 0.0230\t\n",
      "start validation\n",
      "mAP: 0.585358\n",
      "AUC: 0.957950\n",
      "Avg Precision: 0.029803\n",
      "Avg Recall: 0.979451\n",
      "d_prime: 2.442878\n",
      "train_loss: 0.023061\n",
      "valid_loss: 0.032164\n",
      "validation finished\n",
      "Epoch-33 lr: 1.5625e-05\n",
      "epoch 33 training time: 1021.842\n",
      "---------------\n",
      "2023-07-15 17:12:04.291357\n",
      "current #epochs=34, #steps=151800\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch: [34][200/4600]\tPer Sample Total Time 0.02976\tPer Sample Data Time 0.00356\tPer Sample DNN Time 0.02620\tTrain Loss 0.0225\t\n",
      "Epoch: [34][1200/4600]\tPer Sample Total Time 0.02715\tPer Sample Data Time 0.00173\tPer Sample DNN Time 0.02542\tTrain Loss 0.0228\t\n",
      "Epoch: [34][2200/4600]\tPer Sample Total Time 0.02690\tPer Sample Data Time 0.00156\tPer Sample DNN Time 0.02534\tTrain Loss 0.0229\t\n",
      "Epoch: [34][3200/4600]\tPer Sample Total Time 0.02680\tPer Sample Data Time 0.00149\tPer Sample DNN Time 0.02531\tTrain Loss 0.0231\t\n",
      "Epoch: [34][4200/4600]\tPer Sample Total Time 0.02674\tPer Sample Data Time 0.00145\tPer Sample DNN Time 0.02529\tTrain Loss 0.0231\t\n",
      "start validation\n",
      "mAP: 0.584389\n",
      "AUC: 0.957872\n",
      "Avg Precision: 0.029777\n",
      "Avg Recall: 0.977461\n",
      "d_prime: 2.441644\n",
      "train_loss: 0.023123\n",
      "valid_loss: 0.032258\n",
      "validation finished\n",
      "Epoch-34 lr: 1.5625e-05\n",
      "epoch 34 training time: 1028.850\n",
      "---------------\n",
      "2023-07-15 17:29:13.141621\n",
      "current #epochs=35, #steps=156400\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch: [35][600/4600]\tPer Sample Total Time 0.02754\tPer Sample Data Time 0.00193\tPer Sample DNN Time 0.02560\tTrain Loss 0.0223\t\n",
      "Epoch: [35][1600/4600]\tPer Sample Total Time 0.02691\tPer Sample Data Time 0.00154\tPer Sample DNN Time 0.02537\tTrain Loss 0.0227\t\n",
      "Epoch: [35][2600/4600]\tPer Sample Total Time 0.02677\tPer Sample Data Time 0.00146\tPer Sample DNN Time 0.02531\tTrain Loss 0.0229\t\n",
      "Epoch: [35][3600/4600]\tPer Sample Total Time 0.02669\tPer Sample Data Time 0.00141\tPer Sample DNN Time 0.02528\tTrain Loss 0.0231\t\n",
      "start validation\n",
      "mAP: 0.582979\n",
      "AUC: 0.958190\n",
      "Avg Precision: 0.029830\n",
      "Avg Recall: 0.979925\n",
      "d_prime: 2.446664\n",
      "train_loss: 0.023068\n",
      "valid_loss: 0.032187\n",
      "validation finished\n",
      "Epoch-35 lr: 7.8125e-06\n",
      "epoch 35 training time: 1026.218\n",
      "---------------\n",
      "2023-07-15 17:46:19.359216\n",
      "current #epochs=36, #steps=161000\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch: [36][0/4600]\tPer Sample Total Time 0.59948\tPer Sample Data Time 0.47604\tPer Sample DNN Time 0.12344\tTrain Loss 0.0220\t\n",
      "Epoch: [36][1000/4600]\tPer Sample Total Time 0.02710\tPer Sample Data Time 0.00171\tPer Sample DNN Time 0.02539\tTrain Loss 0.0233\t\n",
      "Epoch: [36][2000/4600]\tPer Sample Total Time 0.02676\tPer Sample Data Time 0.00146\tPer Sample DNN Time 0.02530\tTrain Loss 0.0233\t\n",
      "Epoch: [36][3000/4600]\tPer Sample Total Time 0.02666\tPer Sample Data Time 0.00139\tPer Sample DNN Time 0.02527\tTrain Loss 0.0232\t\n",
      "Epoch: [36][4000/4600]\tPer Sample Total Time 0.02662\tPer Sample Data Time 0.00136\tPer Sample DNN Time 0.02526\tTrain Loss 0.0231\t\n",
      "start validation\n",
      "mAP: 0.584064\n",
      "AUC: 0.958213\n",
      "Avg Precision: 0.029805\n",
      "Avg Recall: 0.978815\n",
      "d_prime: 2.447034\n",
      "train_loss: 0.023011\n",
      "valid_loss: 0.032107\n",
      "validation finished\n",
      "Epoch-36 lr: 7.8125e-06\n",
      "epoch 36 training time: 1022.844\n",
      "---------------\n",
      "2023-07-15 18:03:22.203313\n",
      "current #epochs=37, #steps=165600\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch: [37][400/4600]\tPer Sample Total Time 0.02815\tPer Sample Data Time 0.00250\tPer Sample DNN Time 0.02565\tTrain Loss 0.0229\t\n",
      "Epoch: [37][1400/4600]\tPer Sample Total Time 0.02700\tPer Sample Data Time 0.00164\tPer Sample DNN Time 0.02537\tTrain Loss 0.0229\t\n",
      "Epoch: [37][2400/4600]\tPer Sample Total Time 0.02681\tPer Sample Data Time 0.00150\tPer Sample DNN Time 0.02531\tTrain Loss 0.0229\t\n",
      "Epoch: [37][3400/4600]\tPer Sample Total Time 0.02673\tPer Sample Data Time 0.00144\tPer Sample DNN Time 0.02529\tTrain Loss 0.0230\t\n",
      "Epoch: [37][4400/4600]\tPer Sample Total Time 0.02669\tPer Sample Data Time 0.00142\tPer Sample DNN Time 0.02528\tTrain Loss 0.0231\t\n",
      "start validation\n",
      "mAP: 0.585905\n",
      "AUC: 0.958370\n",
      "Avg Precision: 0.029798\n",
      "Avg Recall: 0.977287\n",
      "d_prime: 2.449529\n",
      "train_loss: 0.023091\n",
      "valid_loss: 0.032178\n",
      "validation finished\n",
      "Epoch-37 lr: 7.8125e-06\n",
      "epoch 37 training time: 1029.390\n",
      "---------------\n",
      "2023-07-15 18:20:31.593767\n",
      "current #epochs=38, #steps=170200\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch: [38][800/4600]\tPer Sample Total Time 0.02735\tPer Sample Data Time 0.00181\tPer Sample DNN Time 0.02555\tTrain Loss 0.0233\t\n",
      "Epoch: [38][1800/4600]\tPer Sample Total Time 0.02686\tPer Sample Data Time 0.00150\tPer Sample DNN Time 0.02536\tTrain Loss 0.0232\t\n",
      "Epoch: [38][2800/4600]\tPer Sample Total Time 0.02671\tPer Sample Data Time 0.00141\tPer Sample DNN Time 0.02530\tTrain Loss 0.0232\t\n",
      "Epoch: [38][3800/4600]\tPer Sample Total Time 0.02665\tPer Sample Data Time 0.00137\tPer Sample DNN Time 0.02528\tTrain Loss 0.0230\t\n",
      "start validation\n",
      "mAP: 0.585204\n",
      "AUC: 0.958629\n",
      "Avg Precision: 0.029801\n",
      "Avg Recall: 0.978608\n",
      "d_prime: 2.453654\n",
      "train_loss: 0.023059\n",
      "valid_loss: 0.032066\n",
      "validation finished\n",
      "Epoch-38 lr: 7.8125e-06\n",
      "epoch 38 training time: 1025.257\n",
      "---------------\n",
      "2023-07-15 18:37:36.851251\n",
      "current #epochs=39, #steps=174800\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch: [39][200/4600]\tPer Sample Total Time 0.02981\tPer Sample Data Time 0.00329\tPer Sample DNN Time 0.02652\tTrain Loss 0.0231\t\n",
      "Epoch: [39][1200/4600]\tPer Sample Total Time 0.02705\tPer Sample Data Time 0.00159\tPer Sample DNN Time 0.02545\tTrain Loss 0.0230\t\n",
      "Epoch: [39][2200/4600]\tPer Sample Total Time 0.02679\tPer Sample Data Time 0.00145\tPer Sample DNN Time 0.02535\tTrain Loss 0.0230\t\n",
      "Epoch: [39][3200/4600]\tPer Sample Total Time 0.02671\tPer Sample Data Time 0.00140\tPer Sample DNN Time 0.02531\tTrain Loss 0.0229\t\n",
      "Epoch: [39][4200/4600]\tPer Sample Total Time 0.02665\tPer Sample Data Time 0.00137\tPer Sample DNN Time 0.02529\tTrain Loss 0.0230\t\n",
      "start validation\n",
      "mAP: 0.586928\n",
      "AUC: 0.958582\n",
      "Avg Precision: 0.029793\n",
      "Avg Recall: 0.977593\n",
      "d_prime: 2.452908\n",
      "train_loss: 0.022998\n",
      "valid_loss: 0.031789\n",
      "validation finished\n",
      "Epoch-39 lr: 7.8125e-06\n",
      "epoch 39 training time: 1024.508\n",
      "---------------\n",
      "2023-07-15 18:54:41.359256\n",
      "current #epochs=40, #steps=179400\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch: [40][600/4600]\tPer Sample Total Time 0.02759\tPer Sample Data Time 0.00212\tPer Sample DNN Time 0.02546\tTrain Loss 0.0229\t\n",
      "Epoch: [40][1600/4600]\tPer Sample Total Time 0.02688\tPer Sample Data Time 0.00157\tPer Sample DNN Time 0.02531\tTrain Loss 0.0228\t\n",
      "Epoch: [40][2600/4600]\tPer Sample Total Time 0.02674\tPer Sample Data Time 0.00147\tPer Sample DNN Time 0.02527\tTrain Loss 0.0230\t\n",
      "Epoch: [40][3600/4600]\tPer Sample Total Time 0.02669\tPer Sample Data Time 0.00143\tPer Sample DNN Time 0.02526\tTrain Loss 0.0230\t\n",
      "start validation\n",
      "mAP: 0.587901\n",
      "AUC: 0.959341\n",
      "Avg Precision: 0.029808\n",
      "Avg Recall: 0.978151\n",
      "d_prime: 2.465100\n",
      "train_loss: 0.022963\n",
      "valid_loss: 0.031795\n",
      "validation finished\n",
      "Epoch-40 lr: 3.90625e-06\n",
      "epoch 40 training time: 1026.731\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "---------------Training Finished---------------\n",
      "---------------Result Summary---------------\n",
      "---------------evaluate best single model on the validation set---------------\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "mAP: 0.587901\n",
      "AUC: 0.959341\n",
      "---------------evaluate best single model on the evaluation set---------------\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "mAP: 0.557435\n",
      "AUC: 0.942977\n",
      "---------------evaluate weight average model on the validation set---------------\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "mAP: 0.587512\n",
      "AUC: 0.959057\n",
      "---------------evaluate weight averages model on the evaluation set---------------\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "mAP: 0.558742\n",
      "AUC: 0.943054\n",
      "---------------evaluate ensemble model on the validation set---------------\n",
      "mAP: 0.599903\n",
      "AUC: 0.969304\n",
      "---------------evaluate ensemble model on the evaluation set---------------\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "mAP: 0.570932\n",
      "AUC: 0.953463\n"
     ]
    }
   ],
   "source": [
    "!bash run.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c178a6e3-d90a-4018-944e-42dc0fe402d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting efficientnet_pytorch\n",
      "  Using cached efficientnet_pytorch-0.7.1-py3-none-any.whl\n",
      "Requirement already satisfied: torch in /home/venv/lib/python3.9/site-packages (from efficientnet_pytorch) (2.0.0+cu117)\n",
      "Requirement already satisfied: filelock in /home/venv/lib/python3.9/site-packages (from torch->efficientnet_pytorch) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in /home/venv/lib/python3.9/site-packages (from torch->efficientnet_pytorch) (4.5.0)\n",
      "Requirement already satisfied: sympy in /home/venv/lib/python3.9/site-packages (from torch->efficientnet_pytorch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/venv/lib/python3.9/site-packages (from torch->efficientnet_pytorch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/venv/lib/python3.9/site-packages (from torch->efficientnet_pytorch) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/venv/lib/python3.9/site-packages (from torch->efficientnet_pytorch) (2.0.0)\n",
      "Requirement already satisfied: cmake in /home/venv/lib/python3.9/site-packages (from triton==2.0.0->torch->efficientnet_pytorch) (3.26.3)\n",
      "Requirement already satisfied: lit in /home/venv/lib/python3.9/site-packages (from triton==2.0.0->torch->efficientnet_pytorch) (16.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/venv/lib/python3.9/site-packages (from jinja2->torch->efficientnet_pytorch) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/venv/lib/python3.9/site-packages (from sympy->torch->efficientnet_pytorch) (1.3.0)\n",
      "Installing collected packages: efficientnet_pytorch\n",
      "Successfully installed efficientnet_pytorch-0.7.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install efficientnet_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "163a2e35-3410-44ff-ba0e-17ccc2e442fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Allocations           |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8ba176f-403a-4d11-aef6-22f2627048fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b975b32-d630-4125-a4be-5e9fcd4ef5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60d2306f-9fba-479b-94fe-feec9de82e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7daf7069-894b-4d82-bd78-942db3afd6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/venv/lib/python3.9/site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/venv/lib/python3.9/site-packages (from scikit-learn) (1.10.1)\n",
      "Collecting joblib>=1.1.1 (from scikit-learn)\n",
      "  Using cached joblib-1.3.1-py3-none-any.whl (301 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.3.1 scikit-learn-1.3.0 threadpoolctl-3.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797dc39a-7b39-45a7-a3b0-490e7512bd18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86deb22-6081-40be-9151-89ec86ae1e89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
