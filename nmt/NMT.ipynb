{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a5794fd-8591-48b2-b22a-d9be35ecab1c",
   "metadata": {},
   "source": [
    "# Transformer (NMT)\n",
    "\n",
    "The information and code is from https://pytorch.org/hub/pytorch_fairseq_translation/.\n",
    "\n",
    "### Model Description\n",
    "\n",
    "The Transformer, introduced in the paper Attention Is All You Need, is a powerful sequence-to-sequence modeling architecture capable of producing state-of-the-art neural machine translation (NMT) systems.\n",
    "\n",
    "### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8404f7a9-3fc8-4fbb-8ca1-d366f31a73ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bitarray\n",
      "  Using cached bitarray-2.7.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (270 kB)\n",
      "Collecting fastBPE\n",
      "  Using cached fastBPE-0.1.0.tar.gz (35 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting hydra-core\n",
      "  Using cached hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
      "Collecting omegaconf\n",
      "  Using cached omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Requirement already satisfied: regex in /home/venv/lib/python3.9/site-packages (2023.6.3)\n",
      "Requirement already satisfied: requests in /home/venv/lib/python3.9/site-packages (2.30.0)\n",
      "Collecting sacremoses\n",
      "  Using cached sacremoses-0.0.53.tar.gz (880 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting subword_nmt\n",
      "  Using cached subword_nmt-0.3.8-py3-none-any.whl (27 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m89.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:04\u001b[0m\n",
      "\u001b[?25hCollecting sacrebleu\n",
      "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m83.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting antlr4-python3-runtime==4.9.* (from hydra-core)\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m108.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/venv/lib/python3.9/site-packages (from hydra-core) (23.1)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in /home/venv/lib/python3.9/site-packages (from omegaconf) (6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/venv/lib/python3.9/site-packages (from requests) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/venv/lib/python3.9/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/venv/lib/python3.9/site-packages (from requests) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/venv/lib/python3.9/site-packages (from requests) (2023.5.7)\n",
      "Requirement already satisfied: six in /home/venv/lib/python3.9/site-packages (from sacremoses) (1.16.0)\n",
      "Requirement already satisfied: click in /home/venv/lib/python3.9/site-packages (from sacremoses) (8.1.3)\n",
      "Collecting joblib (from sacremoses)\n",
      "  Downloading joblib-1.3.1-py3-none-any.whl (301 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m106.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/venv/lib/python3.9/site-packages (from sacremoses) (4.65.0)\n",
      "Collecting mock (from subword_nmt)\n",
      "  Downloading mock-5.0.2-py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/venv/lib/python3.9/site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/venv/lib/python3.9/site-packages (from scikit-learn) (1.10.1)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting portalocker (from sacrebleu)\n",
      "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /home/venv/lib/python3.9/site-packages (from sacrebleu) (0.9.0)\n",
      "Collecting colorama (from sacrebleu)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Collecting lxml (from sacrebleu)\n",
      "  Downloading lxml-4.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (7.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m78.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0mm\n",
      "\u001b[?25hBuilding wheels for collected packages: fastBPE, antlr4-python3-runtime, sacremoses\n",
      "  Building wheel for fastBPE (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fastBPE: filename=fastBPE-0.1.0-cp39-cp39-linux_x86_64.whl size=762505 sha256=4eca0bb5a096ebe0bc66d606935104218739bb6c2744aa580e19d4e28e4b17f6\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/e1/10/20/0691b69b472ff8530a7e608674d5bd1cbc772f4d6071c8accf\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=0270b1d25932d17b792f667e2b90616898aff398159697046ac7ebb60a8b004b\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/23/cf/80/f3efa822e6ab23277902ee9165fe772eeb1dfb8014f359020a\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=520c68c962a5edc927dc69b40b01dad0b512de2177a901a674132a98e0a98f4d\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/12/1c/3d/46cf06718d63a32ff798a89594b61e7f345ab6b36d909ce033\n",
      "Successfully built fastBPE antlr4-python3-runtime sacremoses\n",
      "Installing collected packages: fastBPE, bitarray, antlr4-python3-runtime, threadpoolctl, portalocker, omegaconf, mock, lxml, joblib, colorama, subword_nmt, scikit-learn, sacremoses, sacrebleu, hydra-core\n",
      "Successfully installed antlr4-python3-runtime-4.9.3 bitarray-2.7.6 colorama-0.4.6 fastBPE-0.1.0 hydra-core-1.3.2 joblib-1.3.1 lxml-4.9.2 mock-5.0.2 omegaconf-2.3.0 portalocker-2.7.0 sacrebleu-2.3.1 sacremoses-0.0.53 scikit-learn-1.3.0 subword_nmt-0.3.8 threadpoolctl-3.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bitarray fastBPE hydra-core omegaconf regex requests sacremoses subword_nmt scikit-learn sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82846fa7-6dea-4352-b1a3-89056f495fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HTTP_PROXY'] = 'http://proxy.vmware.com:3128'\n",
    "os.environ['HTTPS_PROXY'] = 'http://proxy.vmware.com:3128'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d42165-bfb6-4b2f-a305-4c1f255a82a6",
   "metadata": {},
   "source": [
    "### English-to-French Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2156a279-626a-431a-8d86-404d1b1653d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/pytorch/fairseq/zipball/main\" to /home/jovyan/.cache/torch/hub/main.zip\n",
      "2023-06-30 09:33:05.380475: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-30 09:33:06.193495: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX\n",
      "INFO:root:running build_ext\n",
      "/home/venv/lib/python3.9/site-packages/torch/utils/cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
      "  warnings.warn(msg.format('we could not find ninja.'))\n",
      "INFO:root:cythoning fairseq/data/data_utils_fast.pyx to fairseq/data/data_utils_fast.cpp\n",
      "INFO:root:cythoning fairseq/data/token_block_utils_fast.pyx to fairseq/data/token_block_utils_fast.cpp\n",
      "INFO:root:building 'fairseq.libbleu' extension\n",
      "INFO:root:creating build\n",
      "INFO:root:creating build/temp.linux-x86_64-cpython-39\n",
      "INFO:root:creating build/temp.linux-x86_64-cpython-39/fairseq\n",
      "INFO:root:creating build/temp.linux-x86_64-cpython-39/fairseq/clib\n",
      "INFO:root:creating build/temp.linux-x86_64-cpython-39/fairseq/clib/libbleu\n",
      "INFO:root:x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/home/venv/include -I/usr/include/python3.9 -c fairseq/clib/libbleu/libbleu.cpp -o build/temp.linux-x86_64-cpython-39/fairseq/clib/libbleu/libbleu.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=libbleu -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "INFO:root:x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/home/venv/include -I/usr/include/python3.9 -c fairseq/clib/libbleu/module.cpp -o build/temp.linux-x86_64-cpython-39/fairseq/clib/libbleu/module.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=libbleu -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "INFO:root:creating build/lib.linux-x86_64-cpython-39\n",
      "INFO:root:creating build/lib.linux-x86_64-cpython-39/fairseq\n",
      "INFO:root:x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-39/fairseq/clib/libbleu/libbleu.o build/temp.linux-x86_64-cpython-39/fairseq/clib/libbleu/module.o -L/usr/lib/x86_64-linux-gnu -o build/lib.linux-x86_64-cpython-39/fairseq/libbleu.cpython-39-x86_64-linux-gnu.so\n",
      "INFO:root:building 'fairseq.data.data_utils_fast' extension\n",
      "INFO:root:creating build/temp.linux-x86_64-cpython-39/fairseq/data\n",
      "INFO:root:x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/home/venv/lib/python3.9/site-packages/numpy/core/include -I/home/venv/lib/python3.9/site-packages/numpy/core/include -I/home/venv/include -I/usr/include/python3.9 -c fairseq/data/data_utils_fast.cpp -o build/temp.linux-x86_64-cpython-39/fairseq/data/data_utils_fast.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=data_utils_fast -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "In file included from /home/venv/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h:1948,\n",
      "                 from /home/venv/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h:12,\n",
      "                 from /home/venv/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h:5,\n",
      "                 from fairseq/data/data_utils_fast.cpp:760:\n",
      "/home/venv/lib/python3.9/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2: warning: #warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [-Wcpp]\n",
      "   17 | #warning \"Using deprecated NumPy API, disable it with \" \\\n",
      "      |  ^~~~~~~\n",
      "INFO:root:creating build/lib.linux-x86_64-cpython-39/fairseq/data\n",
      "INFO:root:x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-39/fairseq/data/data_utils_fast.o -L/usr/lib/x86_64-linux-gnu -o build/lib.linux-x86_64-cpython-39/fairseq/data/data_utils_fast.cpython-39-x86_64-linux-gnu.so\n",
      "INFO:root:building 'fairseq.data.token_block_utils_fast' extension\n",
      "INFO:root:x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/home/venv/lib/python3.9/site-packages/numpy/core/include -I/home/venv/lib/python3.9/site-packages/numpy/core/include -I/home/venv/include -I/usr/include/python3.9 -c fairseq/data/token_block_utils_fast.cpp -o build/temp.linux-x86_64-cpython-39/fairseq/data/token_block_utils_fast.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=token_block_utils_fast -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "In file included from /home/venv/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h:1948,\n",
      "                 from /home/venv/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h:12,\n",
      "                 from /home/venv/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h:5,\n",
      "                 from fairseq/data/token_block_utils_fast.cpp:761:\n",
      "/home/venv/lib/python3.9/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2: warning: #warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [-Wcpp]\n",
      "   17 | #warning \"Using deprecated NumPy API, disable it with \" \\\n",
      "      |  ^~~~~~~\n",
      "fairseq/data/token_block_utils_fast.cpp: In function ‘PyArrayObject* __pyx_f_7fairseq_4data_22token_block_utils_fast__get_slice_indices_fast(PyArrayObject*, PyObject*, int, int, int)’:\n",
      "fairseq/data/token_block_utils_fast.cpp:3469:36: warning: comparison of integer expressions of different signedness: ‘__pyx_t_7fairseq_4data_22token_block_utils_fast_DTYPE_t’ {aka ‘long int’} and ‘size_t’ {aka ‘long unsigned int’} [-Wsign-compare]\n",
      " 3469 |       __pyx_t_4 = ((__pyx_v_sz_idx < __pyx_t_10) != 0);\n",
      "      |                     ~~~~~~~~~~~~~~~^~~~~~~~~~~~\n",
      "fairseq/data/token_block_utils_fast.cpp:3664:36: warning: comparison of integer expressions of different signedness: ‘__pyx_t_7fairseq_4data_22token_block_utils_fast_DTYPE_t’ {aka ‘long int’} and ‘size_t’ {aka ‘long unsigned int’} [-Wsign-compare]\n",
      " 3664 |       __pyx_t_3 = ((__pyx_v_sz_idx < __pyx_t_10) != 0);\n",
      "      |                     ~~~~~~~~~~~~~~~^~~~~~~~~~~~\n",
      "INFO:root:x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-39/fairseq/data/token_block_utils_fast.o -L/usr/lib/x86_64-linux-gnu -o build/lib.linux-x86_64-cpython-39/fairseq/data/token_block_utils_fast.cpython-39-x86_64-linux-gnu.so\n",
      "INFO:root:building 'fairseq.libbase' extension\n",
      "INFO:root:creating build/temp.linux-x86_64-cpython-39/fairseq/clib/libbase\n",
      "INFO:root:x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/home/venv/lib/python3.9/site-packages/torch/include -I/home/venv/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/home/venv/lib/python3.9/site-packages/torch/include/TH -I/home/venv/lib/python3.9/site-packages/torch/include/THC -I/home/venv/include -I/usr/include/python3.9 -c fairseq/clib/libbase/balanced_assignment.cpp -o build/temp.linux-x86_64-cpython-39/fairseq/clib/libbase/balanced_assignment.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=libbase -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "INFO:root:x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-39/fairseq/clib/libbase/balanced_assignment.o -L/home/venv/lib/python3.9/site-packages/torch/lib -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-cpython-39/fairseq/libbase.cpython-39-x86_64-linux-gnu.so\n",
      "INFO:root:building 'fairseq.libnat' extension\n",
      "INFO:root:creating build/temp.linux-x86_64-cpython-39/fairseq/clib/libnat\n",
      "INFO:root:x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/home/venv/lib/python3.9/site-packages/torch/include -I/home/venv/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/home/venv/lib/python3.9/site-packages/torch/include/TH -I/home/venv/lib/python3.9/site-packages/torch/include/THC -I/home/venv/include -I/usr/include/python3.9 -c fairseq/clib/libnat/edit_dist.cpp -o build/temp.linux-x86_64-cpython-39/fairseq/clib/libnat/edit_dist.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=libnat -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "INFO:root:x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-39/fairseq/clib/libnat/edit_dist.o -L/home/venv/lib/python3.9/site-packages/torch/lib -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-cpython-39/fairseq/libnat.cpython-39-x86_64-linux-gnu.so\n",
      "INFO:root:building 'alignment_train_cpu_binding' extension\n",
      "INFO:root:creating build/temp.linux-x86_64-cpython-39/examples\n",
      "INFO:root:creating build/temp.linux-x86_64-cpython-39/examples/operators\n",
      "INFO:root:x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/home/venv/lib/python3.9/site-packages/torch/include -I/home/venv/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/home/venv/lib/python3.9/site-packages/torch/include/TH -I/home/venv/lib/python3.9/site-packages/torch/include/THC -I/home/venv/include -I/usr/include/python3.9 -c examples/operators/alignment_train_cpu.cpp -o build/temp.linux-x86_64-cpython-39/examples/operators/alignment_train_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=alignment_train_cpu_binding -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "INFO:root:x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-39/examples/operators/alignment_train_cpu.o -L/home/venv/lib/python3.9/site-packages/torch/lib -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-cpython-39/alignment_train_cpu_binding.cpython-39-x86_64-linux-gnu.so\n",
      "INFO:root:copying build/lib.linux-x86_64-cpython-39/fairseq/libbleu.cpython-39-x86_64-linux-gnu.so -> fairseq\n",
      "INFO:root:copying build/lib.linux-x86_64-cpython-39/fairseq/data/data_utils_fast.cpython-39-x86_64-linux-gnu.so -> fairseq/data\n",
      "INFO:root:copying build/lib.linux-x86_64-cpython-39/fairseq/data/token_block_utils_fast.cpython-39-x86_64-linux-gnu.so -> fairseq/data\n",
      "INFO:root:copying build/lib.linux-x86_64-cpython-39/fairseq/libbase.cpython-39-x86_64-linux-gnu.so -> fairseq\n",
      "INFO:root:copying build/lib.linux-x86_64-cpython-39/fairseq/libnat.cpython-39-x86_64-linux-gnu.so -> fairseq\n",
      "INFO:root:copying build/lib.linux-x86_64-cpython-39/alignment_train_cpu_binding.cpython-39-x86_64-linux-gnu.so -> \n",
      "INFO:fairseq.file_utils:https://dl.fbaipublicfiles.com/fairseq/models/wmt14.en-fr.joined-dict.transformer.tar.bz2 not found in cache, downloading to /home/model-server/tmp/tmp9anag304\n",
      "100%|██████████| 2316140317/2316140317 [04:08<00:00, 9309416.69B/s] \n",
      "INFO:fairseq.file_utils:copying /home/model-server/tmp/tmp9anag304 to cache at /home/jovyan/.cache/torch/pytorch_fairseq/53f403ba27ab138b06c1a8d78f5bb4f1722567ac3d3b3e41f821ec2cae2974da.7ef8ab763efda16d3c82dd8b5a574bdfe524e078bac7b444ea1a9c5d355b55ae\n",
      "INFO:fairseq.file_utils:creating metadata file for /home/jovyan/.cache/torch/pytorch_fairseq/53f403ba27ab138b06c1a8d78f5bb4f1722567ac3d3b3e41f821ec2cae2974da.7ef8ab763efda16d3c82dd8b5a574bdfe524e078bac7b444ea1a9c5d355b55ae\n",
      "INFO:fairseq.file_utils:removing temp file /home/model-server/tmp/tmp9anag304\n",
      "INFO:fairseq.file_utils:loading archive file https://dl.fbaipublicfiles.com/fairseq/models/wmt14.en-fr.joined-dict.transformer.tar.bz2 from cache at /home/jovyan/.cache/torch/pytorch_fairseq/53f403ba27ab138b06c1a8d78f5bb4f1722567ac3d3b3e41f821ec2cae2974da.7ef8ab763efda16d3c82dd8b5a574bdfe524e078bac7b444ea1a9c5d355b55ae\n",
      "INFO:fairseq.file_utils:extracting archive file /home/jovyan/.cache/torch/pytorch_fairseq/53f403ba27ab138b06c1a8d78f5bb4f1722567ac3d3b3e41f821ec2cae2974da.7ef8ab763efda16d3c82dd8b5a574bdfe524e078bac7b444ea1a9c5d355b55ae to temp dir /home/model-server/tmp/tmp05pdul8x\n",
      "/home/venv/lib/python3.9/site-packages/hydra/experimental/initialize.py:43: UserWarning: hydra.experimental.initialize() is no longer experimental. Use hydra.initialize()\n",
      "  deprecation_warning(message=message)\n",
      "/home/venv/lib/python3.9/site-packages/hydra/experimental/initialize.py:45: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  self.delegate = real_initialize(\n",
      "/home/venv/lib/python3.9/site-packages/hydra/experimental/compose.py:25: UserWarning: hydra.experimental.compose() is no longer experimental. Use hydra.compose()\n",
      "  deprecation_warning(message=message)\n",
      "/home/venv/lib/python3.9/site-packages/hydra/core/default_element.py:124: UserWarning: In 'config': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/jovyan/.cache/torch/hub/pytorch_fairseq_main/fairseq/checkpoint_utils.py:432: UserWarning: \n",
      "'config' is validated against ConfigStore schema with the same name.\n",
      "This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.\n",
      "  state = load_checkpoint_to_cpu(filename, arg_overrides)\n",
      "/home/venv/lib/python3.9/site-packages/hydra/compose.py:56: UserWarning: \n",
      "The strict flag in the compose API is deprecated.\n",
      "See https://hydra.cc/docs/1.2/upgrades/0.11_to_1.0/strict_mode_flag_deprecated for more info.\n",
      "\n",
      "  deprecation_warning(\n",
      "/home/venv/lib/python3.9/site-packages/hydra/experimental/initialize.py:43: UserWarning: hydra.experimental.initialize() is no longer experimental. Use hydra.initialize()\n",
      "  deprecation_warning(message=message)\n",
      "/home/venv/lib/python3.9/site-packages/hydra/experimental/initialize.py:45: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  self.delegate = real_initialize(\n",
      "/home/jovyan/.cache/torch/hub/pytorch_fairseq_main/fairseq/models/fairseq_model.py:272: UserWarning: \n",
      "'config' is validated against ConfigStore schema with the same name.\n",
      "This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.\n",
      "  x = hub_utils.from_pretrained(\n",
      "INFO:fairseq.tasks.translation:[en] dictionary: 44512 types\n",
      "INFO:fairseq.tasks.translation:[fr] dictionary: 44512 types\n",
      "INFO:fairseq.models.fairseq_model:{'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 2, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 128, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://learnfair0253:58342', 'distributed_port': 58342, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 5120, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 5120, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 80000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0007], 'stop_min_lr': 1e-09, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': '/checkpoint02/myleott/2018-05-19/wmt14_en_fr.fp16_allreduce.fp16.maxupd80000.transformer_vaswani_wmt_en_de_big.shareemb.adam.beta0.9,0.98.initlr1e-07.warmup4000.lr0.0007.clip0.0.drop0.1.wd0.0.ls0.1.maxtok5120.seed2.ngpu128', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 128}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=10, log_format='json', seed=2, data='/home/jovyan/.cache/torch/pytorch_fairseq/53f403ba27ab138b06c1a8d78f5bb4f1722567ac3d3b3e41f821ec2cae2974da.7ef8ab763efda16d3c82dd8b5a574bdfe524e078bac7b444ea1a9c5d355b55ae', source_lang='en', target_lang='fr', max_source_positions=1024, max_target_positions=1024, skip_invalid_size_inputs_valid_test=False, max_tokens=5120, max_sentences=None, train_subset='train', valid_subset='valid', max_sentences_valid=None, sample_without_replacement=0, distributed_world_size=128, distributed_rank=0, distributed_backend='nccl', distributed_init_method='tcp://learnfair0253:58342', distributed_port=58342, device_id=0, arch='transformer_vaswani_wmt_en_de_big', criterion='label_smoothed_cross_entropy', max_epoch=0, max_update=80000, clip_norm=0.0, sentence_avg=False, update_freq=[1.0], fp16=True, optimizer='adam', lr=[0.0007], momentum=0.99, weight_decay=0.0, lr_scheduler='inverse_sqrt', lr_shrink=0.1, save_dir='/checkpoint02/myleott/2018-05-19/wmt14_en_fr.fp16_allreduce.fp16.maxupd80000.transformer_vaswani_wmt_en_de_big.shareemb.adam.beta0.9,0.98.initlr1e-07.warmup4000.lr0.0007.clip0.0.drop0.1.wd0.0.ls0.1.maxtok5120.seed2.ngpu128', restore_file='checkpoint_last.pt', save_interval=1, no_save=False, no_epoch_checkpoints=False, validate_interval=1, dropout=0.1, attention_dropout=0.0, relu_dropout=0.0, encoder_normalize_before=False, encoder_learned_pos=False, decoder_learned_pos=False, decoder_normalize_before=False, share_decoder_input_output_embed=True, share_all_embeddings=True, label_smoothing=0.1, adam_betas='(0.9, 0.98)', adam_eps=1e-08, warmup_updates=4000, warmup_init_lr=1e-07, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_layers=6, encoder_attention_heads=16, decoder_embed_dim=1024, decoder_ffn_embed_dim=4096, decoder_layers=6, decoder_attention_heads=16, tokenizer='moses', bpe='subword_nmt', bpe_codes='/home/jovyan/.cache/torch/pytorch_fairseq/53f403ba27ab138b06c1a8d78f5bb4f1722567ac3d3b3e41f821ec2cae2974da.7ef8ab763efda16d3c82dd8b5a574bdfe524e078bac7b444ea1a9c5d355b55ae/bpecodes', task='translation', stop_min_lr=1e-09, _name='transformer_vaswani_wmt_en_de_big', encoder_embed_path=None, decoder_embed_path=None, activation_dropout=0.0, activation_fn='relu', adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, merge_src_tgt_embed=False, no_token_positional_embeddings=False, adaptive_input=False, no_cross_attention=False, cross_self_attention=False, decoder_output_dim=1024, decoder_input_dim=1024, no_scale_embedding=False, layernorm_embedding=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, encoder_layerdrop=0, decoder_layerdrop=0, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0), 'task': {'_name': 'translation', 'data': '/home/jovyan/.cache/torch/pytorch_fairseq/53f403ba27ab138b06c1a8d78f5bb4f1722567ac3d3b3e41f821ec2cae2974da.7ef8ab763efda16d3c82dd8b5a574bdfe524e078bac7b444ea1a9c5d355b55ae', 'source_lang': 'en', 'target_lang': 'fr', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [0.0007]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0007]}, 'scoring': None, 'bpe': {'_name': 'subword_nmt', 'bpe_codes': '/home/jovyan/.cache/torch/pytorch_fairseq/53f403ba27ab138b06c1a8d78f5bb4f1722567ac3d3b3e41f821ec2cae2974da.7ef8ab763efda16d3c82dd8b5a574bdfe524e078bac7b444ea1a9c5d355b55ae/bpecodes', 'bpe_separator': '@@'}, 'tokenizer': {'_name': 'moses', 'source_lang': 'en', 'target_lang': 'fr', 'moses_no_dash_splits': False, 'moses_no_escape': False}, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}\n",
      "INFO:fairseq.tasks.fairseq_task:can_reuse_epoch_itr = False\n",
      "INFO:fairseq.tasks.fairseq_task:reuse_dataloader = True\n",
      "INFO:fairseq.tasks.fairseq_task:rebuild_batches = False\n",
      "INFO:fairseq.tasks.fairseq_task:creating new batches for epoch 1\n",
      "INFO:fairseq.tasks.fairseq_task:can_reuse_epoch_itr = False\n",
      "INFO:fairseq.tasks.fairseq_task:reuse_dataloader = True\n",
      "INFO:fairseq.tasks.fairseq_task:rebuild_batches = False\n",
      "INFO:fairseq.tasks.fairseq_task:creating new batches for epoch 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Load an En-Fr Transformer model trained on WMT'14 data :\n",
    "en2fr = torch.hub.load('pytorch/fairseq', 'transformer.wmt14.en-fr', tokenizer='moses', bpe='subword_nmt')\n",
    "\n",
    "# Use the GPU (optional):\n",
    "en2fr.cuda()\n",
    "\n",
    "# Translate with beam search:\n",
    "fr = en2fr.translate('Hello world!', beam=5)\n",
    "assert fr == 'Bonjour à tous !'\n",
    "\n",
    "# Manually tokenize:\n",
    "en_toks = en2fr.tokenize('Hello world!')\n",
    "assert en_toks == 'Hello world !'\n",
    "\n",
    "# Manually apply BPE:\n",
    "en_bpe = en2fr.apply_bpe(en_toks)\n",
    "assert en_bpe == 'H@@ ello world !'\n",
    "\n",
    "# Manually binarize:\n",
    "en_bin = en2fr.binarize(en_bpe)\n",
    "assert en_bin.tolist() == [329, 14044, 682, 812, 2]\n",
    "\n",
    "# Generate five translations with top-k sampling:\n",
    "fr_bin = en2fr.generate(en_bin, beam=5, sampling=True, sampling_topk=20)\n",
    "assert len(fr_bin) == 5\n",
    "\n",
    "# Convert one of the samples to a string and detokenize\n",
    "fr_sample = fr_bin[0]['tokens']\n",
    "fr_bpe = en2fr.string(fr_sample)\n",
    "fr_toks = en2fr.remove_bpe(fr_bpe)\n",
    "fr = en2fr.detokenize(fr_toks)\n",
    "assert fr == en2fr.decode(fr_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8a0f083-50b1-4708-879d-5b9ba224aa71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour à tous !\n"
     ]
    }
   ],
   "source": [
    "print(fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fd6260-488d-47cc-9f0c-3949e83037ab",
   "metadata": {},
   "source": [
    "### English-to-German Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6648ce07-fb3b-483e-a3ee-a76ce657fd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jovyan/.cache/torch/hub/pytorch_fairseq_main\n",
      "INFO:fairseq.file_utils:https://dl.fbaipublicfiles.com/fairseq/models/wmt19.en-de.joined-dict.single_model.tar.gz not found in cache, downloading to /home/model-server/tmp/tmpg2nwswgq\n",
      "100%|██████████| 2988854245/2988854245 [02:37<00:00, 18933814.19B/s]\n",
      "INFO:fairseq.file_utils:copying /home/model-server/tmp/tmpg2nwswgq to cache at /home/jovyan/.cache/torch/pytorch_fairseq/81a0be5cbbf1c106320ef94681844d4594031c94c16b0475be11faa5a5120c48.63b093d59e7e0814ff799bb965ed4cbde30200b8c93a44bf8c1e5e98f5c54db3\n",
      "INFO:fairseq.file_utils:creating metadata file for /home/jovyan/.cache/torch/pytorch_fairseq/81a0be5cbbf1c106320ef94681844d4594031c94c16b0475be11faa5a5120c48.63b093d59e7e0814ff799bb965ed4cbde30200b8c93a44bf8c1e5e98f5c54db3\n",
      "INFO:fairseq.file_utils:removing temp file /home/model-server/tmp/tmpg2nwswgq\n",
      "INFO:fairseq.file_utils:loading archive file https://dl.fbaipublicfiles.com/fairseq/models/wmt19.en-de.joined-dict.single_model.tar.gz from cache at /home/jovyan/.cache/torch/pytorch_fairseq/81a0be5cbbf1c106320ef94681844d4594031c94c16b0475be11faa5a5120c48.63b093d59e7e0814ff799bb965ed4cbde30200b8c93a44bf8c1e5e98f5c54db3\n",
      "INFO:fairseq.file_utils:extracting archive file /home/jovyan/.cache/torch/pytorch_fairseq/81a0be5cbbf1c106320ef94681844d4594031c94c16b0475be11faa5a5120c48.63b093d59e7e0814ff799bb965ed4cbde30200b8c93a44bf8c1e5e98f5c54db3 to temp dir /home/model-server/tmp/tmpi3q513xo\n",
      "INFO:fairseq.tasks.translation:[en] dictionary: 42024 types\n",
      "INFO:fairseq.tasks.translation:[de] dictionary: 42024 types\n",
      "INFO:fairseq.models.fairseq_model:{'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': 'simple', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 2, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:17406', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 3584, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 3584, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 201800, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0007], 'stop_min_lr': 1e-09, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': '/checkpoint/edunov/20190403/wmt19en2de.btsample5.ffn8192.transformer_wmt_en_de_big_bsz3584_lr0.0007_dr0.2_size_updates200000_seed20_lbsm0.1_size_sa1_upsample2//finetune1', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 200, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=True, log_interval=100, log_format='simple', tensorboard_logdir='', seed=2, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir=None, task='translation', num_workers=0, skip_invalid_size_inputs_valid_test=False, max_tokens=3584, max_sentences=None, train_subset='train', valid_subset='valid', max_sentences_valid=None, distributed_world_size=2, distributed_rank=0, distributed_backend='nccl', distributed_init_method='tcp://localhost:17406', distributed_port=-1, device_id=0, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, arch='transformer_wmt_en_de_big', criterion='label_smoothed_cross_entropy', max_epoch=0, max_update=201800, clip_norm=0.0, sentence_avg=False, update_freq=[1], optimizer='adam', lr=[0.0007], momentum=0.99, weight_decay=0.0, lr_scheduler='inverse_sqrt', lr_shrink=0.1, save_dir='/checkpoint/edunov/20190403/wmt19en2de.btsample5.ffn8192.transformer_wmt_en_de_big_bsz3584_lr0.0007_dr0.2_size_updates200000_seed20_lbsm0.1_size_sa1_upsample2//finetune1', restore_file='checkpoint_last.pt', reset_optimizer=False, reset_lr_scheduler=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=200, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, validate_interval=1, no_token_positional_embeddings=False, label_smoothing=0.1, adam_betas='(0.9, 0.98)', adam_eps=1e-08, warmup_updates=4000, warmup_init_lr=1e-07, data='/home/jovyan/.cache/torch/pytorch_fairseq/81a0be5cbbf1c106320ef94681844d4594031c94c16b0475be11faa5a5120c48.63b093d59e7e0814ff799bb965ed4cbde30200b8c93a44bf8c1e5e98f5c54db3', extra_data='', source_lang='en', target_lang='de', lazy_load=False, raw_text=False, left_pad_source=True, left_pad_target=False, max_source_positions=1024, max_target_positions=1024, upsample_primary=1, share_all_embeddings=True, dropout=0.2, encoder_ffn_embed_dim=8192, attention_dropout=0.1, encoder_embed_dim=1024, encoder_attention_heads=16, encoder_normalize_before=False, decoder_embed_dim=1024, decoder_ffn_embed_dim=4096, decoder_attention_heads=16, encoder_embed_path=None, encoder_layers=6, encoder_learned_pos=False, decoder_embed_path=None, decoder_layers=6, decoder_normalize_before=False, decoder_learned_pos=False, relu_dropout=0.0, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, share_decoder_input_output_embed=True, adaptive_input=False, decoder_output_dim=1024, decoder_input_dim=1024, tokenizer='moses', bpe='fastbpe', bpe_codes='/home/jovyan/.cache/torch/pytorch_fairseq/81a0be5cbbf1c106320ef94681844d4594031c94c16b0475be11faa5a5120c48.63b093d59e7e0814ff799bb965ed4cbde30200b8c93a44bf8c1e5e98f5c54db3/bpecodes', stop_min_lr=1e-09, _name='transformer_wmt_en_de_big', activation_dropout=0.0, activation_fn='relu', merge_src_tgt_embed=False, no_cross_attention=False, cross_self_attention=False, no_scale_embedding=False, layernorm_embedding=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, encoder_layerdrop=0, decoder_layerdrop=0, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0), 'task': {'_name': 'translation', 'data': '/home/jovyan/.cache/torch/pytorch_fairseq/81a0be5cbbf1c106320ef94681844d4594031c94c16b0475be11faa5a5120c48.63b093d59e7e0814ff799bb965ed4cbde30200b8c93a44bf8c1e5e98f5c54db3', 'source_lang': 'en', 'target_lang': 'de', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': 1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [0.0007]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0007]}, 'scoring': None, 'bpe': {'_name': 'fastbpe', 'bpe_codes': '/home/jovyan/.cache/torch/pytorch_fairseq/81a0be5cbbf1c106320ef94681844d4594031c94c16b0475be11faa5a5120c48.63b093d59e7e0814ff799bb965ed4cbde30200b8c93a44bf8c1e5e98f5c54db3/bpecodes'}, 'tokenizer': {'_name': 'moses', 'source_lang': 'en', 'target_lang': 'de', 'moses_no_dash_splits': False, 'moses_no_escape': False}, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}\n",
      "Loading codes from /home/jovyan/.cache/torch/pytorch_fairseq/81a0be5cbbf1c106320ef94681844d4594031c94c16b0475be11faa5a5120c48.63b093d59e7e0814ff799bb965ed4cbde30200b8c93a44bf8c1e5e98f5c54db3/bpecodes ...\n",
      "Read 30000 codes from the codes file.\n",
      "INFO:fairseq.tasks.fairseq_task:can_reuse_epoch_itr = False\n",
      "INFO:fairseq.tasks.fairseq_task:reuse_dataloader = True\n",
      "INFO:fairseq.tasks.fairseq_task:rebuild_batches = False\n",
      "INFO:fairseq.tasks.fairseq_task:creating new batches for epoch 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Load an En-De Transformer model trained on WMT'19 data:\n",
    "en2de = torch.hub.load('pytorch/fairseq', 'transformer.wmt19.en-de.single_model', tokenizer='moses', bpe='fastbpe')\n",
    "\n",
    "# Access the underlying TransformerModel\n",
    "assert isinstance(en2de.models[0], torch.nn.Module)\n",
    "\n",
    "# Translate from En-De\n",
    "de = en2de.translate('PyTorch Hub is a pre-trained model repository designed to facilitate research reproducibility.')\n",
    "assert de == 'PyTorch Hub ist ein vorgefertigtes Modell-Repository, das die Reproduzierbarkeit der Forschung erleichtern soll.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bec7b242-1ff4-434a-8e39-170f8d0e0aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Hub ist ein vorgefertigtes Modell-Repository, das die Reproduzierbarkeit der Forschung erleichtern soll.\n"
     ]
    }
   ],
   "source": [
    "print(de)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41792b60-fa11-49ac-9b0d-b814b487af12",
   "metadata": {},
   "source": [
    "### A round-trip translation to create a paraphrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ffc5aa1-cbd0-4b23-b521-b71da0eeccd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jovyan/.cache/torch/hub/pytorch_fairseq_main\n",
      "INFO:fairseq.file_utils:loading archive file https://dl.fbaipublicfiles.com/fairseq/models/wmt19.en-de.joined-dict.single_model.tar.gz from cache at /home/jovyan/.cache/torch/pytorch_fairseq/81a0be5cbbf1c106320ef94681844d4594031c94c16b0475be11faa5a5120c48.63b093d59e7e0814ff799bb965ed4cbde30200b8c93a44bf8c1e5e98f5c54db3\n",
      "INFO:fairseq.tasks.translation:[en] dictionary: 42024 types\n",
      "INFO:fairseq.tasks.translation:[de] dictionary: 42024 types\n",
      "INFO:fairseq.models.fairseq_model:{'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': 'simple', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 2, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:17406', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 3584, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 3584, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 201800, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0007], 'stop_min_lr': 1e-09, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': '/checkpoint/edunov/20190403/wmt19en2de.btsample5.ffn8192.transformer_wmt_en_de_big_bsz3584_lr0.0007_dr0.2_size_updates200000_seed20_lbsm0.1_size_sa1_upsample2//finetune1', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 200, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=True, log_interval=100, log_format='simple', tensorboard_logdir='', seed=2, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir=None, task='translation', num_workers=0, skip_invalid_size_inputs_valid_test=False, max_tokens=3584, max_sentences=None, train_subset='train', valid_subset='valid', max_sentences_valid=None, distributed_world_size=2, distributed_rank=0, distributed_backend='nccl', distributed_init_method='tcp://localhost:17406', distributed_port=-1, device_id=0, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, arch='transformer_wmt_en_de_big', criterion='label_smoothed_cross_entropy', max_epoch=0, max_update=201800, clip_norm=0.0, sentence_avg=False, update_freq=[1], optimizer='adam', lr=[0.0007], momentum=0.99, weight_decay=0.0, lr_scheduler='inverse_sqrt', lr_shrink=0.1, save_dir='/checkpoint/edunov/20190403/wmt19en2de.btsample5.ffn8192.transformer_wmt_en_de_big_bsz3584_lr0.0007_dr0.2_size_updates200000_seed20_lbsm0.1_size_sa1_upsample2//finetune1', restore_file='checkpoint_last.pt', reset_optimizer=False, reset_lr_scheduler=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=200, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, validate_interval=1, no_token_positional_embeddings=False, label_smoothing=0.1, adam_betas='(0.9, 0.98)', adam_eps=1e-08, warmup_updates=4000, warmup_init_lr=1e-07, data='/home/jovyan/.cache/torch/pytorch_fairseq/81a0be5cbbf1c106320ef94681844d4594031c94c16b0475be11faa5a5120c48.63b093d59e7e0814ff799bb965ed4cbde30200b8c93a44bf8c1e5e98f5c54db3', extra_data='', source_lang='en', target_lang='de', lazy_load=False, raw_text=False, left_pad_source=True, left_pad_target=False, max_source_positions=1024, max_target_positions=1024, upsample_primary=1, share_all_embeddings=True, dropout=0.2, encoder_ffn_embed_dim=8192, attention_dropout=0.1, encoder_embed_dim=1024, encoder_attention_heads=16, encoder_normalize_before=False, decoder_embed_dim=1024, decoder_ffn_embed_dim=4096, decoder_attention_heads=16, encoder_embed_path=None, encoder_layers=6, encoder_learned_pos=False, decoder_embed_path=None, decoder_layers=6, decoder_normalize_before=False, decoder_learned_pos=False, relu_dropout=0.0, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, share_decoder_input_output_embed=True, adaptive_input=False, decoder_output_dim=1024, decoder_input_dim=1024, tokenizer='moses', bpe='fastbpe', bpe_codes='/home/jovyan/.cache/torch/pytorch_fairseq/81a0be5cbbf1c106320ef94681844d4594031c94c16b0475be11faa5a5120c48.63b093d59e7e0814ff799bb965ed4cbde30200b8c93a44bf8c1e5e98f5c54db3/bpecodes', stop_min_lr=1e-09, _name='transformer_wmt_en_de_big', activation_dropout=0.0, activation_fn='relu', merge_src_tgt_embed=False, no_cross_attention=False, cross_self_attention=False, no_scale_embedding=False, layernorm_embedding=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, encoder_layerdrop=0, decoder_layerdrop=0, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0), 'task': {'_name': 'translation', 'data': '/home/jovyan/.cache/torch/pytorch_fairseq/81a0be5cbbf1c106320ef94681844d4594031c94c16b0475be11faa5a5120c48.63b093d59e7e0814ff799bb965ed4cbde30200b8c93a44bf8c1e5e98f5c54db3', 'source_lang': 'en', 'target_lang': 'de', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': 1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [0.0007]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0007]}, 'scoring': None, 'bpe': {'_name': 'fastbpe', 'bpe_codes': '/home/jovyan/.cache/torch/pytorch_fairseq/81a0be5cbbf1c106320ef94681844d4594031c94c16b0475be11faa5a5120c48.63b093d59e7e0814ff799bb965ed4cbde30200b8c93a44bf8c1e5e98f5c54db3/bpecodes'}, 'tokenizer': {'_name': 'moses', 'source_lang': 'en', 'target_lang': 'de', 'moses_no_dash_splits': False, 'moses_no_escape': False}, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}\n",
      "Loading codes from /home/jovyan/.cache/torch/pytorch_fairseq/81a0be5cbbf1c106320ef94681844d4594031c94c16b0475be11faa5a5120c48.63b093d59e7e0814ff799bb965ed4cbde30200b8c93a44bf8c1e5e98f5c54db3/bpecodes ...\n",
      "Read 30000 codes from the codes file.\n",
      "Using cache found in /home/jovyan/.cache/torch/hub/pytorch_fairseq_main\n",
      "INFO:fairseq.file_utils:https://dl.fbaipublicfiles.com/fairseq/models/wmt19.de-en.joined-dict.single_model.tar.gz not found in cache, downloading to /home/model-server/tmp/tmpvuc60xxi\n",
      "100%|██████████| 2992273886/2992273886 [05:41<00:00, 8759565.09B/s] \n",
      "INFO:fairseq.file_utils:copying /home/model-server/tmp/tmpvuc60xxi to cache at /home/jovyan/.cache/torch/pytorch_fairseq/f42bb1b72d293668a5c50d9589fd2f3cc27322e390b1ef4cf3fdcf625c0d2fd7.bf6e22453272c2cba218a5ccecd045f73e926c34c1d66c47c9b31233343820a9\n",
      "INFO:fairseq.file_utils:creating metadata file for /home/jovyan/.cache/torch/pytorch_fairseq/f42bb1b72d293668a5c50d9589fd2f3cc27322e390b1ef4cf3fdcf625c0d2fd7.bf6e22453272c2cba218a5ccecd045f73e926c34c1d66c47c9b31233343820a9\n",
      "INFO:fairseq.file_utils:removing temp file /home/model-server/tmp/tmpvuc60xxi\n",
      "INFO:fairseq.file_utils:loading archive file https://dl.fbaipublicfiles.com/fairseq/models/wmt19.de-en.joined-dict.single_model.tar.gz from cache at /home/jovyan/.cache/torch/pytorch_fairseq/f42bb1b72d293668a5c50d9589fd2f3cc27322e390b1ef4cf3fdcf625c0d2fd7.bf6e22453272c2cba218a5ccecd045f73e926c34c1d66c47c9b31233343820a9\n",
      "INFO:fairseq.file_utils:extracting archive file /home/jovyan/.cache/torch/pytorch_fairseq/f42bb1b72d293668a5c50d9589fd2f3cc27322e390b1ef4cf3fdcf625c0d2fd7.bf6e22453272c2cba218a5ccecd045f73e926c34c1d66c47c9b31233343820a9 to temp dir /home/model-server/tmp/tmp715lebuy\n",
      "INFO:fairseq.tasks.translation:[de] dictionary: 42024 types\n",
      "INFO:fairseq.tasks.translation:[en] dictionary: 42024 types\n",
      "INFO:fairseq.models.fairseq_model:{'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': 'simple', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 2, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:12536', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 3584, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 3584, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 200200, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0007], 'stop_min_lr': 1e-09, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': '/checkpoint/edunov/20190403/wmt19de2en.btsample5.ffn8192.transformer_wmt_en_de_big_bsz3584_lr0.0007_dr0.2_size_updates200000_seed21_lbsm0.1_size_sa1_upsample4//finetune1', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 200, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=True, log_interval=100, log_format='simple', tensorboard_logdir='', seed=2, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir=None, task='translation', num_workers=0, skip_invalid_size_inputs_valid_test=False, max_tokens=3584, max_sentences=None, train_subset='train', valid_subset='valid', max_sentences_valid=None, distributed_world_size=2, distributed_rank=0, distributed_backend='nccl', distributed_init_method='tcp://localhost:12536', distributed_port=-1, device_id=0, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, arch='transformer_wmt_en_de_big', criterion='label_smoothed_cross_entropy', max_epoch=0, max_update=200200, clip_norm=0.0, sentence_avg=False, update_freq=[1], optimizer='adam', lr=[0.0007], momentum=0.99, weight_decay=0.0, lr_scheduler='inverse_sqrt', lr_shrink=0.1, save_dir='/checkpoint/edunov/20190403/wmt19de2en.btsample5.ffn8192.transformer_wmt_en_de_big_bsz3584_lr0.0007_dr0.2_size_updates200000_seed21_lbsm0.1_size_sa1_upsample4//finetune1', restore_file='checkpoint_last.pt', reset_optimizer=False, reset_lr_scheduler=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=200, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, validate_interval=1, no_token_positional_embeddings=False, label_smoothing=0.1, adam_betas='(0.9, 0.98)', adam_eps=1e-08, warmup_updates=4000, warmup_init_lr=1e-07, data='/home/jovyan/.cache/torch/pytorch_fairseq/f42bb1b72d293668a5c50d9589fd2f3cc27322e390b1ef4cf3fdcf625c0d2fd7.bf6e22453272c2cba218a5ccecd045f73e926c34c1d66c47c9b31233343820a9', extra_data='', source_lang='de', target_lang='en', lazy_load=False, raw_text=False, left_pad_source=True, left_pad_target=False, max_source_positions=1024, max_target_positions=1024, upsample_primary=1, share_all_embeddings=True, dropout=0.2, encoder_ffn_embed_dim=8192, attention_dropout=0.1, encoder_embed_dim=1024, encoder_attention_heads=16, encoder_normalize_before=False, decoder_embed_dim=1024, decoder_ffn_embed_dim=4096, decoder_attention_heads=16, encoder_embed_path=None, encoder_layers=6, encoder_learned_pos=False, decoder_embed_path=None, decoder_layers=6, decoder_normalize_before=False, decoder_learned_pos=False, relu_dropout=0.0, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, share_decoder_input_output_embed=True, adaptive_input=False, decoder_output_dim=1024, decoder_input_dim=1024, tokenizer='moses', bpe='fastbpe', bpe_codes='/home/jovyan/.cache/torch/pytorch_fairseq/f42bb1b72d293668a5c50d9589fd2f3cc27322e390b1ef4cf3fdcf625c0d2fd7.bf6e22453272c2cba218a5ccecd045f73e926c34c1d66c47c9b31233343820a9/bpecodes', stop_min_lr=1e-09, _name='transformer_wmt_en_de_big', activation_dropout=0.0, activation_fn='relu', merge_src_tgt_embed=False, no_cross_attention=False, cross_self_attention=False, no_scale_embedding=False, layernorm_embedding=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, encoder_layerdrop=0, decoder_layerdrop=0, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0), 'task': {'_name': 'translation', 'data': '/home/jovyan/.cache/torch/pytorch_fairseq/f42bb1b72d293668a5c50d9589fd2f3cc27322e390b1ef4cf3fdcf625c0d2fd7.bf6e22453272c2cba218a5ccecd045f73e926c34c1d66c47c9b31233343820a9', 'source_lang': 'de', 'target_lang': 'en', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': 1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [0.0007]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0007]}, 'scoring': None, 'bpe': {'_name': 'fastbpe', 'bpe_codes': '/home/jovyan/.cache/torch/pytorch_fairseq/f42bb1b72d293668a5c50d9589fd2f3cc27322e390b1ef4cf3fdcf625c0d2fd7.bf6e22453272c2cba218a5ccecd045f73e926c34c1d66c47c9b31233343820a9/bpecodes'}, 'tokenizer': {'_name': 'moses', 'source_lang': 'de', 'target_lang': 'en', 'moses_no_dash_splits': False, 'moses_no_escape': False}, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}\n",
      "Loading codes from /home/jovyan/.cache/torch/pytorch_fairseq/f42bb1b72d293668a5c50d9589fd2f3cc27322e390b1ef4cf3fdcf625c0d2fd7.bf6e22453272c2cba218a5ccecd045f73e926c34c1d66c47c9b31233343820a9/bpecodes ...\n",
      "Read 30000 codes from the codes file.\n",
      "INFO:fairseq.tasks.fairseq_task:can_reuse_epoch_itr = False\n",
      "INFO:fairseq.tasks.fairseq_task:reuse_dataloader = True\n",
      "INFO:fairseq.tasks.fairseq_task:rebuild_batches = False\n",
      "INFO:fairseq.tasks.fairseq_task:creating new batches for epoch 1\n",
      "INFO:fairseq.tasks.fairseq_task:can_reuse_epoch_itr = False\n",
      "INFO:fairseq.tasks.fairseq_task:reuse_dataloader = True\n",
      "INFO:fairseq.tasks.fairseq_task:rebuild_batches = False\n",
      "INFO:fairseq.tasks.fairseq_task:creating new batches for epoch 1\n",
      "Using cache found in /home/jovyan/.cache/torch/hub/pytorch_fairseq_main\n",
      "INFO:fairseq.file_utils:https://dl.fbaipublicfiles.com/fairseq/models/wmt19.en-ru.single_model.tar.gz not found in cache, downloading to /home/model-server/tmp/tmpxx75dibz\n",
      "100%|██████████| 3037373614/3037373614 [04:01<00:00, 12567071.35B/s]\n",
      "INFO:fairseq.file_utils:copying /home/model-server/tmp/tmpxx75dibz to cache at /home/jovyan/.cache/torch/pytorch_fairseq/57b24ff1a88d5f14807352c9d8e17949d46ae3d0a06c1be3667929101011cdc0.8699fa0753ba14331352cc26ceb7aa46fba856bad52dd40fc97d3834418bf6f1\n",
      "INFO:fairseq.file_utils:creating metadata file for /home/jovyan/.cache/torch/pytorch_fairseq/57b24ff1a88d5f14807352c9d8e17949d46ae3d0a06c1be3667929101011cdc0.8699fa0753ba14331352cc26ceb7aa46fba856bad52dd40fc97d3834418bf6f1\n",
      "INFO:fairseq.file_utils:removing temp file /home/model-server/tmp/tmpxx75dibz\n",
      "INFO:fairseq.file_utils:loading archive file https://dl.fbaipublicfiles.com/fairseq/models/wmt19.en-ru.single_model.tar.gz from cache at /home/jovyan/.cache/torch/pytorch_fairseq/57b24ff1a88d5f14807352c9d8e17949d46ae3d0a06c1be3667929101011cdc0.8699fa0753ba14331352cc26ceb7aa46fba856bad52dd40fc97d3834418bf6f1\n",
      "INFO:fairseq.file_utils:extracting archive file /home/jovyan/.cache/torch/pytorch_fairseq/57b24ff1a88d5f14807352c9d8e17949d46ae3d0a06c1be3667929101011cdc0.8699fa0753ba14331352cc26ceb7aa46fba856bad52dd40fc97d3834418bf6f1 to temp dir /home/model-server/tmp/tmpdsu41ppk\n",
      "INFO:fairseq.tasks.translation:[en] dictionary: 31640 types\n",
      "INFO:fairseq.tasks.translation:[ru] dictionary: 31232 types\n",
      "INFO:fairseq.models.fairseq_model:{'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': 'simple', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 2, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11535', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 3584, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 3584, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 201700, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0007], 'stop_min_lr': 1e-09, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': '/checkpoint/edunov/20190403/wmt19en2ru.btsample5.ffn8192.transformer_wmt_en_de_big_bsz3584_lr0.0007_dr0.2_size_updates200000_seed12_lbsm0.1_size_sa0_upsample2//finetune1/', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 200, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=True, log_interval=100, log_format='simple', tensorboard_logdir='', seed=2, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir=None, task='translation', num_workers=0, skip_invalid_size_inputs_valid_test=False, max_tokens=3584, max_sentences=None, train_subset='train', valid_subset='valid', max_sentences_valid=None, distributed_world_size=2, distributed_rank=0, distributed_backend='nccl', distributed_init_method='tcp://localhost:11535', distributed_port=-1, device_id=0, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, arch='transformer_wmt_en_de_big', criterion='label_smoothed_cross_entropy', max_epoch=0, max_update=201700, clip_norm=0.0, sentence_avg=False, update_freq=[1], optimizer='adam', lr=[0.0007], momentum=0.99, weight_decay=0.0, lr_scheduler='inverse_sqrt', lr_shrink=0.1, save_dir='/checkpoint/edunov/20190403/wmt19en2ru.btsample5.ffn8192.transformer_wmt_en_de_big_bsz3584_lr0.0007_dr0.2_size_updates200000_seed12_lbsm0.1_size_sa0_upsample2//finetune1/', restore_file='checkpoint_last.pt', reset_optimizer=False, reset_lr_scheduler=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=200, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, validate_interval=1, no_token_positional_embeddings=False, label_smoothing=0.1, adam_betas='(0.9, 0.98)', adam_eps=1e-08, warmup_updates=4000, warmup_init_lr=1e-07, data='/home/jovyan/.cache/torch/pytorch_fairseq/57b24ff1a88d5f14807352c9d8e17949d46ae3d0a06c1be3667929101011cdc0.8699fa0753ba14331352cc26ceb7aa46fba856bad52dd40fc97d3834418bf6f1', extra_data='', source_lang='en', target_lang='ru', lazy_load=False, raw_text=False, left_pad_source=True, left_pad_target=False, max_source_positions=1024, max_target_positions=1024, upsample_primary=1, share_decoder_input_output_embed=True, dropout=0.2, encoder_ffn_embed_dim=8192, attention_dropout=0.1, encoder_embed_dim=1024, encoder_attention_heads=16, encoder_normalize_before=False, decoder_embed_dim=1024, decoder_ffn_embed_dim=4096, decoder_attention_heads=16, encoder_embed_path=None, encoder_layers=6, encoder_learned_pos=False, decoder_embed_path=None, decoder_layers=6, decoder_normalize_before=False, decoder_learned_pos=False, relu_dropout=0.0, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, share_all_embeddings=False, adaptive_input=False, decoder_output_dim=1024, decoder_input_dim=1024, tokenizer='moses', bpe='fastbpe', bpe_codes='/home/jovyan/.cache/torch/pytorch_fairseq/57b24ff1a88d5f14807352c9d8e17949d46ae3d0a06c1be3667929101011cdc0.8699fa0753ba14331352cc26ceb7aa46fba856bad52dd40fc97d3834418bf6f1/bpecodes', stop_min_lr=1e-09, _name='transformer_wmt_en_de_big', activation_dropout=0.0, activation_fn='relu', merge_src_tgt_embed=False, no_cross_attention=False, cross_self_attention=False, no_scale_embedding=False, layernorm_embedding=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, encoder_layerdrop=0, decoder_layerdrop=0, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, min_params_to_wrap=100000000), 'task': {'_name': 'translation', 'data': '/home/jovyan/.cache/torch/pytorch_fairseq/57b24ff1a88d5f14807352c9d8e17949d46ae3d0a06c1be3667929101011cdc0.8699fa0753ba14331352cc26ceb7aa46fba856bad52dd40fc97d3834418bf6f1', 'source_lang': 'en', 'target_lang': 'ru', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': 1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [0.0007]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0007]}, 'scoring': None, 'bpe': {'_name': 'fastbpe', 'bpe_codes': '/home/jovyan/.cache/torch/pytorch_fairseq/57b24ff1a88d5f14807352c9d8e17949d46ae3d0a06c1be3667929101011cdc0.8699fa0753ba14331352cc26ceb7aa46fba856bad52dd40fc97d3834418bf6f1/bpecodes'}, 'tokenizer': {'_name': 'moses', 'source_lang': 'en', 'target_lang': 'ru', 'moses_no_dash_splits': False, 'moses_no_escape': False}, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}\n",
      "Loading codes from /home/jovyan/.cache/torch/pytorch_fairseq/57b24ff1a88d5f14807352c9d8e17949d46ae3d0a06c1be3667929101011cdc0.8699fa0753ba14331352cc26ceb7aa46fba856bad52dd40fc97d3834418bf6f1/bpecodes ...\n",
      "Read 30000 codes from the codes file.\n",
      "Using cache found in /home/jovyan/.cache/torch/hub/pytorch_fairseq_main\n",
      "INFO:fairseq.file_utils:https://dl.fbaipublicfiles.com/fairseq/models/wmt19.ru-en.single_model.tar.gz not found in cache, downloading to /home/model-server/tmp/tmpa36eyskg\n",
      "100%|██████████| 3041223502/3041223502 [02:37<00:00, 19264955.03B/s]\n",
      "INFO:fairseq.file_utils:copying /home/model-server/tmp/tmpa36eyskg to cache at /home/jovyan/.cache/torch/pytorch_fairseq/f857729c1dcbbade3bbe70f7f58ede13e939a7b8278eb9015602e73be09e5cb4.ecb440f9c8cec1f28ee5023cdeab76f67eede4fc1ac0f2c70eeb2e65a25ad783\n",
      "INFO:fairseq.file_utils:creating metadata file for /home/jovyan/.cache/torch/pytorch_fairseq/f857729c1dcbbade3bbe70f7f58ede13e939a7b8278eb9015602e73be09e5cb4.ecb440f9c8cec1f28ee5023cdeab76f67eede4fc1ac0f2c70eeb2e65a25ad783\n",
      "INFO:fairseq.file_utils:removing temp file /home/model-server/tmp/tmpa36eyskg\n",
      "INFO:fairseq.file_utils:loading archive file https://dl.fbaipublicfiles.com/fairseq/models/wmt19.ru-en.single_model.tar.gz from cache at /home/jovyan/.cache/torch/pytorch_fairseq/f857729c1dcbbade3bbe70f7f58ede13e939a7b8278eb9015602e73be09e5cb4.ecb440f9c8cec1f28ee5023cdeab76f67eede4fc1ac0f2c70eeb2e65a25ad783\n",
      "INFO:fairseq.file_utils:extracting archive file /home/jovyan/.cache/torch/pytorch_fairseq/f857729c1dcbbade3bbe70f7f58ede13e939a7b8278eb9015602e73be09e5cb4.ecb440f9c8cec1f28ee5023cdeab76f67eede4fc1ac0f2c70eeb2e65a25ad783 to temp dir /home/model-server/tmp/tmp0sg33m82\n",
      "INFO:fairseq.tasks.translation:[ru] dictionary: 31232 types\n",
      "INFO:fairseq.tasks.translation:[en] dictionary: 31640 types\n",
      "INFO:fairseq.models.fairseq_model:{'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': 'simple', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 2, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:15993', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 3584, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 3584, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 201700, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0007], 'stop_min_lr': 1e-09, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': '/checkpoint/edunov/20190403/wmt19ru2en.btsample5.ffn8192.transformer_wmt_en_de_big_bsz3584_lr0.0007_dr0.2_size_updates200000_seed2_lbsm0.1_size_sa0_upsample2/finetune/', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 200, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=True, log_interval=100, log_format='simple', tensorboard_logdir='', seed=2, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir=None, task='translation', num_workers=0, skip_invalid_size_inputs_valid_test=False, max_tokens=3584, max_sentences=None, train_subset='train', valid_subset='valid', max_sentences_valid=None, distributed_world_size=2, distributed_rank=0, distributed_backend='nccl', distributed_init_method='tcp://localhost:15993', distributed_port=-1, device_id=0, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, arch='transformer_wmt_en_de_big', criterion='label_smoothed_cross_entropy', max_epoch=0, max_update=201700, clip_norm=0.0, sentence_avg=False, update_freq=[1], optimizer='adam', lr=[0.0007], momentum=0.99, weight_decay=0.0, lr_scheduler='inverse_sqrt', lr_shrink=0.1, save_dir='/checkpoint/edunov/20190403/wmt19ru2en.btsample5.ffn8192.transformer_wmt_en_de_big_bsz3584_lr0.0007_dr0.2_size_updates200000_seed2_lbsm0.1_size_sa0_upsample2/finetune/', restore_file='checkpoint_last.pt', reset_optimizer=False, reset_lr_scheduler=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=200, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, validate_interval=1, no_token_positional_embeddings=False, label_smoothing=0.1, adam_betas='(0.9, 0.98)', adam_eps=1e-08, warmup_updates=4000, warmup_init_lr=1e-07, data='/home/jovyan/.cache/torch/pytorch_fairseq/f857729c1dcbbade3bbe70f7f58ede13e939a7b8278eb9015602e73be09e5cb4.ecb440f9c8cec1f28ee5023cdeab76f67eede4fc1ac0f2c70eeb2e65a25ad783', extra_data='', source_lang='ru', target_lang='en', lazy_load=False, raw_text=False, left_pad_source=True, left_pad_target=False, max_source_positions=1024, max_target_positions=1024, upsample_primary=4, share_decoder_input_output_embed=True, dropout=0.2, encoder_ffn_embed_dim=8192, attention_dropout=0.1, encoder_embed_dim=1024, encoder_attention_heads=16, encoder_normalize_before=False, decoder_embed_dim=1024, decoder_ffn_embed_dim=4096, decoder_attention_heads=16, encoder_embed_path=None, encoder_layers=6, encoder_learned_pos=False, decoder_embed_path=None, decoder_layers=6, decoder_normalize_before=False, decoder_learned_pos=False, relu_dropout=0.0, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, share_all_embeddings=False, adaptive_input=False, decoder_output_dim=1024, decoder_input_dim=1024, tokenizer='moses', bpe='fastbpe', bpe_codes='/home/jovyan/.cache/torch/pytorch_fairseq/f857729c1dcbbade3bbe70f7f58ede13e939a7b8278eb9015602e73be09e5cb4.ecb440f9c8cec1f28ee5023cdeab76f67eede4fc1ac0f2c70eeb2e65a25ad783/bpecodes', stop_min_lr=1e-09, _name='transformer_wmt_en_de_big', activation_dropout=0.0, activation_fn='relu', merge_src_tgt_embed=False, no_cross_attention=False, cross_self_attention=False, no_scale_embedding=False, layernorm_embedding=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, encoder_layerdrop=0, decoder_layerdrop=0, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, min_params_to_wrap=100000000), 'task': {'_name': 'translation', 'data': '/home/jovyan/.cache/torch/pytorch_fairseq/f857729c1dcbbade3bbe70f7f58ede13e939a7b8278eb9015602e73be09e5cb4.ecb440f9c8cec1f28ee5023cdeab76f67eede4fc1ac0f2c70eeb2e65a25ad783', 'source_lang': 'ru', 'target_lang': 'en', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': 4, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [0.0007]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0007]}, 'scoring': None, 'bpe': {'_name': 'fastbpe', 'bpe_codes': '/home/jovyan/.cache/torch/pytorch_fairseq/f857729c1dcbbade3bbe70f7f58ede13e939a7b8278eb9015602e73be09e5cb4.ecb440f9c8cec1f28ee5023cdeab76f67eede4fc1ac0f2c70eeb2e65a25ad783/bpecodes'}, 'tokenizer': {'_name': 'moses', 'source_lang': 'ru', 'target_lang': 'en', 'moses_no_dash_splits': False, 'moses_no_escape': False}, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}\n",
      "Loading codes from /home/jovyan/.cache/torch/pytorch_fairseq/f857729c1dcbbade3bbe70f7f58ede13e939a7b8278eb9015602e73be09e5cb4.ecb440f9c8cec1f28ee5023cdeab76f67eede4fc1ac0f2c70eeb2e65a25ad783/bpecodes ...\n",
      "Read 24000 codes from the codes file.\n",
      "INFO:fairseq.tasks.fairseq_task:can_reuse_epoch_itr = False\n",
      "INFO:fairseq.tasks.fairseq_task:reuse_dataloader = True\n",
      "INFO:fairseq.tasks.fairseq_task:rebuild_batches = False\n",
      "INFO:fairseq.tasks.fairseq_task:creating new batches for epoch 1\n",
      "INFO:fairseq.tasks.fairseq_task:can_reuse_epoch_itr = False\n",
      "INFO:fairseq.tasks.fairseq_task:reuse_dataloader = True\n",
      "INFO:fairseq.tasks.fairseq_task:rebuild_batches = False\n",
      "INFO:fairseq.tasks.fairseq_task:creating new batches for epoch 1\n"
     ]
    }
   ],
   "source": [
    "# Round-trip translations between English and German:\n",
    "en2de = torch.hub.load('pytorch/fairseq', 'transformer.wmt19.en-de.single_model', tokenizer='moses', bpe='fastbpe')\n",
    "de2en = torch.hub.load('pytorch/fairseq', 'transformer.wmt19.de-en.single_model', tokenizer='moses', bpe='fastbpe')\n",
    "\n",
    "paraphrase = de2en.translate(en2de.translate('PyTorch Hub is an awesome interface!'))\n",
    "assert paraphrase == 'PyTorch Hub is a fantastic interface!'\n",
    "\n",
    "# Compare the results with English-Russian round-trip translation:\n",
    "en2ru = torch.hub.load('pytorch/fairseq', 'transformer.wmt19.en-ru.single_model', tokenizer='moses', bpe='fastbpe')\n",
    "ru2en = torch.hub.load('pytorch/fairseq', 'transformer.wmt19.ru-en.single_model', tokenizer='moses', bpe='fastbpe')\n",
    "\n",
    "paraphrase = ru2en.translate(en2ru.translate('PyTorch Hub is an awesome interface!'))\n",
    "assert paraphrase == 'PyTorch is a great interface!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7bcffcc-6fdf-4785-8b97-801735ebd050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch is a great interface!\n"
     ]
    }
   ],
   "source": [
    "print(paraphrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3250c552-bcb1-46e7-89d4-8705adae3a76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
