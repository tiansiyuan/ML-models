{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ff204b0-bed4-4636-93e2-640da4484aed",
   "metadata": {},
   "source": [
    "# OpenNMT\n",
    "\n",
    "The instructions and code are taken from [Neural Machine Translation (NMT) tutorial with OpenNMT-py](https://github.com/ymoslem/OpenNMT-Tutorial) by combining\n",
    "the two Jupyter notebooks together with a little bit tweaking.\n",
    "\n",
    "### Data Gathering and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e265f69-c509-4e0b-ad90-a2311634d312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/nmt\n",
      "Cloning into 'MT-Preparation'...\n",
      "remote: Enumerating objects: 239, done.\u001b[K\n",
      "remote: Counting objects: 100% (239/239), done.\u001b[K\n",
      "remote: Compressing objects: 100% (133/133), done.\u001b[K\n",
      "remote: Total 239 (delta 119), reused 186 (delta 94), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (239/239), 61.56 KiB | 685.00 KiB/s, done.\n",
      "Resolving deltas: 100% (119/119), done.\n"
     ]
    }
   ],
   "source": [
    "# Create a directory and clone the Github MT-Preparation repository\n",
    "!mkdir -p nmt\n",
    "%cd nmt\n",
    "!rm -rf *\n",
    "!git clone https://github.com/ymoslem/MT-Preparation.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ab8d2de-0962-45df-b418-7c50cc03b0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from -r MT-Preparation/requirements.txt (line 1)) (1.25.2)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from -r MT-Preparation/requirements.txt (line 2)) (2.0.3)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.9/site-packages (from -r MT-Preparation/requirements.txt (line 3)) (0.1.99)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.9/site-packages (from pandas->-r MT-Preparation/requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas->-r MT-Preparation/requirements.txt (line 2)) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.9/site-packages (from pandas->-r MT-Preparation/requirements.txt (line 2)) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->-r MT-Preparation/requirements.txt (line 2)) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Install the requirements\n",
    "!pip3 install -r MT-Preparation/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69efd4cc-8d33-4420-bc1e-9cb08155410e",
   "metadata": {},
   "source": [
    "### Datasets\n",
    "\n",
    "Example datasets:\n",
    "\n",
    "    EN-AR: https://object.pouta.csc.fi/OPUS-UN/v20090831/moses/ar-en.txt.zip\n",
    "    EN-ES: https://object.pouta.csc.fi/OPUS-UN/v20090831/moses/en-es.txt.zip\n",
    "    EN-FR: https://object.pouta.csc.fi/OPUS-UN/v20090831/moses/en-fr.txt.zip\n",
    "    EN-RU: https://object.pouta.csc.fi/OPUS-UN/v20090831/moses/en-ru.txt.zip\n",
    "    EN-ZH: https://object.pouta.csc.fi/OPUS-UN/v20090831/moses/en-zh.txt.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f0292bf-e949-4911-93e9-55c51a1823c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-08-22 03:26:23--  https://object.pouta.csc.fi/OPUS-UN/v20090831/moses/en-fr.txt.zip\n",
      "Resolving object.pouta.csc.fi (object.pouta.csc.fi)... 86.50.254.18, 86.50.254.19\n",
      "Connecting to object.pouta.csc.fi (object.pouta.csc.fi)|86.50.254.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10014972 (9.6M) [application/zip]\n",
      "Saving to: ‘en-fr.txt.zip’\n",
      "\n",
      "en-fr.txt.zip       100%[===================>]   9.55M   312KB/s    in 90s     \n",
      "\n",
      "2023-08-22 03:28:00 (109 KB/s) - ‘en-fr.txt.zip’ saved [10014972/10014972]\n",
      "\n",
      "Archive:  en-fr.txt.zip\n",
      "  inflating: UN.en-fr.en             \n",
      "  inflating: UN.en-fr.fr             \n",
      "  inflating: README                  \n"
     ]
    }
   ],
   "source": [
    "# Download and unzip a dataset\n",
    "!wget https://object.pouta.csc.fi/OPUS-UN/v20090831/moses/en-fr.txt.zip\n",
    "!unzip en-fr.txt.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e63c6544-815e-41c1-8de5-844072e65793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape (rows, columns): (74067, 2)\n",
      "--- Rows with Empty Cells Deleted\t--> Rows: 74067\n",
      "--- Duplicates Deleted\t\t\t--> Rows: 60662\n",
      "--- Source-Copied Rows Deleted\t\t--> Rows: 60476\n",
      "--- Too Long Source/Target Deleted\t--> Rows: 59719\n",
      "--- HTML Removed\t\t\t--> Rows: 59719\n",
      "--- Rows will remain in true-cased\t--> Rows: 59719\n",
      "--- Rows with Empty Cells Deleted\t--> Rows: 59719\n",
      "--- Rows Shuffled\t\t\t--> Rows: 59719\n",
      "--- Source Saved: UN.en-fr.fr-filtered.fr\n",
      "--- Target Saved: UN.en-fr.en-filtered.en\n"
     ]
    }
   ],
   "source": [
    "# Filter the dataset\n",
    "# Arguments: source file, target file, source language, target language\n",
    "!python3 MT-Preparation/filtering/filter.py UN.en-fr.fr UN.en-fr.en fr en"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37120b69-ab98-41f1-a8bc-8655ffc3de1c",
   "metadata": {},
   "source": [
    "### Tokenization / Sub-wording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37efb603-ec90-4c84-bd91-4133643dd82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-train_bpe.py\t1-train_unigram.py  2-subword.py  3-desubword.py\n"
     ]
    }
   ],
   "source": [
    "!ls MT-Preparation/subwording/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ac2fee0-2ba0-481d-a405-e9de11c4428c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=UN.en-fr.fr-filtered.fr --model_prefix=source --vocab_size=50000 --hard_vocab_limit=false --split_digits=true\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: UN.en-fr.fr-filtered.fr\n",
      "  input_format: \n",
      "  model_prefix: source\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 50000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 1\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 0\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(351) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(183) LOG(INFO) Loading corpus: UN.en-fr.fr-filtered.fr\n",
      "trainer_interface.cc(407) LOG(INFO) Loaded all 59719 sentences\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(428) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(537) LOG(INFO) all chars count=19614832\n",
      "trainer_interface.cc(548) LOG(INFO) Done: 99.9546% characters are covered.\n",
      "trainer_interface.cc(558) LOG(INFO) Alphabet size=82\n",
      "trainer_interface.cc(559) LOG(INFO) Final character coverage=0.999546\n",
      "trainer_interface.cc(591) LOG(INFO) Done! preprocessed 59719 sentences.\n",
      "unigram_model_trainer.cc(222) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(226) LOG(INFO) Extracting frequent sub strings... node_num=13631066\n",
      "unigram_model_trainer.cc(274) LOG(INFO) Initialized 61805 seed sentencepieces\n",
      "trainer_interface.cc(597) LOG(INFO) Tokenizing input sentences with whitespace: 59719\n",
      "trainer_interface.cc(608) LOG(INFO) Done! 48938\n",
      "unigram_model_trainer.cc(564) LOG(INFO) Using 48938 sentences for EM training\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=23065 obj=12.0957 num_tokens=205556 num_tokens/piece=8.91203\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=16778 obj=8.81693 num_tokens=205778 num_tokens/piece=12.2648\n",
      "trainer_interface.cc(686) LOG(INFO) Saving model: source.model\n",
      "trainer_interface.cc(698) LOG(INFO) Saving vocabs: source.vocab\n",
      "Done, training a SentencepPiece model for the Source finished successfully!\n",
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=UN.en-fr.en-filtered.en --model_prefix=target --vocab_size=50000 --hard_vocab_limit=false --split_digits=true\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: UN.en-fr.en-filtered.en\n",
      "  input_format: \n",
      "  model_prefix: target\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 50000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 1\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 0\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(351) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(183) LOG(INFO) Loading corpus: UN.en-fr.en-filtered.en\n",
      "trainer_interface.cc(407) LOG(INFO) Loaded all 59719 sentences\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(428) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(537) LOG(INFO) all chars count=17772658\n",
      "trainer_interface.cc(548) LOG(INFO) Done: 99.9623% characters are covered.\n",
      "trainer_interface.cc(558) LOG(INFO) Alphabet size=70\n",
      "trainer_interface.cc(559) LOG(INFO) Final character coverage=0.999623\n",
      "trainer_interface.cc(591) LOG(INFO) Done! preprocessed 59719 sentences.\n",
      "unigram_model_trainer.cc(222) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(226) LOG(INFO) Extracting frequent sub strings... node_num=11814606\n",
      "unigram_model_trainer.cc(274) LOG(INFO) Initialized 46525 seed sentencepieces\n",
      "trainer_interface.cc(597) LOG(INFO) Tokenizing input sentences with whitespace: 59719\n",
      "trainer_interface.cc(608) LOG(INFO) Done! 44916\n",
      "unigram_model_trainer.cc(564) LOG(INFO) Using 44916 sentences for EM training\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=19499 obj=11.8498 num_tokens=207239 num_tokens/piece=10.6282\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=13744 obj=8.60033 num_tokens=207645 num_tokens/piece=15.108\n",
      "trainer_interface.cc(686) LOG(INFO) Saving model: target.model\n",
      "trainer_interface.cc(698) LOG(INFO) Saving vocabs: target.vocab\n",
      "Done, training a SentencepPiece model for the Target finished successfully!\n"
     ]
    }
   ],
   "source": [
    "# Train a SentencePiece model for subword tokenization\n",
    "!python3 MT-Preparation/subwording/1-train_unigram.py UN.en-fr.fr-filtered.fr UN.en-fr.en-filtered.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "468dfde6-c844-4b48-aee5-04f276b9ad2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en-fr.txt.zip\tsource.model  target.vocab\t       UN.en-fr.fr\n",
      "MT-Preparation\tsource.vocab  UN.en-fr.en\t       UN.en-fr.fr-filtered.fr\n",
      "README\t\ttarget.model  UN.en-fr.en-filtered.en\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6cec949-86ac-49bf-acf5-e79541f3827b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Model: source.model\n",
      "Target Model: target.model\n",
      "Source Dataset: UN.en-fr.fr-filtered.fr\n",
      "Target Dataset: UN.en-fr.en-filtered.en\n",
      "Done subwording the source file! Output: UN.en-fr.fr-filtered.fr.subword\n",
      "Done subwording the target file! Output: UN.en-fr.en-filtered.en.subword\n"
     ]
    }
   ],
   "source": [
    "# Subword the dataset\n",
    "!python3 MT-Preparation/subwording/2-subword.py source.model target.model UN.en-fr.fr-filtered.fr UN.en-fr.en-filtered.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6be1ca0-617e-443e-9dd2-5dbd0af787e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Les États Parties encouragent les activités de formation et d'assistance technique de nature à faciliter l'extradition et l'entraide judiciaire. Ces activités de formation et d'assistance technique peuvent inclure une formation linguistique, des détachements et des échanges entre les personnels des autorités centrales ou des organismes ayant des responsabilités dans les domaines visés.\n",
      "10. Souligne qu'il est important de faciliter l'adhésion de tous les pays en développement, en particulier les pays les moins avancés, ainsi que des pays en transition, qui demandent à faire partie de l'Organisation mondiale du commerce, en ayant à l'esprit le paragraphe 21 de la résolution 55/182 et les développements ultérieurs ;\n",
      "6. Souligne également que, lorsque l'on considère les liens entre la mondialisation et le développement durable, il faut en particulier s'attacher à identifier et à appliquer des politiques et des pratiques qui se renforcent mutuellement et qui encouragent la croissance économique, le développement social et la protection de l'environnement, et que cela requiert des efforts aux niveaux national et international ;\n",
      "-----\n",
      "3. States Parties shall promote training and technical assistance that will facilitate extradition and mutual legal assistance. Such training and technical assistance may include language training, secondments and exchanges between personnel in central authorities or agencies with relevant responsibilities.\n",
      "10. Stresses the importance of facilitating the accession of all developing countries, particularly the least developed countries, as well as countries with economies in transition, that apply for membership in the World Trade Organization, bearing in mind paragraph 21 of resolution 55/182 and subsequent developments;\n",
      "6. Underlines the fact that, in addressing the linkages between globalization and sustainable development, particular focus should be placed on identifying and implementing mutually reinforcing policies and practices that promote sustained economic growth, social development and environmental protection and that this requires efforts at both the national and international levels;\n"
     ]
    }
   ],
   "source": [
    "# First 3 lines before subwording\n",
    "!head -n 3 UN.en-fr.fr-filtered.fr && echo \"-----\" && head -n 3 UN.en-fr.en-filtered.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "063cadef-4e42-40b7-9b1a-d4bc6f1b5efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁ 3 . ▁Les ▁États ▁Parties ▁encouragent ▁les ▁activités ▁de ▁formation ▁et ▁d ' assistance ▁technique ▁de ▁nature ▁à ▁faciliter ▁l ' extradition ▁et ▁l ' entraide ▁judiciaire . ▁Ces ▁activités ▁de ▁formation ▁et ▁d ' assistance ▁technique ▁peuvent ▁inclure ▁une ▁formation ▁linguistique , ▁des ▁détachement s ▁et ▁des ▁échanges ▁entre ▁les ▁personnels ▁des ▁autorités ▁centrale s ▁ou ▁des ▁organismes ▁ayant ▁des ▁responsabilités ▁d ans ▁les ▁domaines ▁visés .\n",
      "▁ 1 0 . ▁Souligne ▁qu ' il ▁est ▁important ▁de ▁faciliter ▁l ' adhésion ▁de ▁tous ▁les ▁pays ▁en ▁développement , ▁en ▁particulier ▁les ▁pays ▁les ▁moins ▁avancés , ▁ainsi ▁que ▁des ▁pays ▁en ▁transition , ▁qui ▁demandent ▁à ▁faire ▁partie ▁de ▁l ' Organisation ▁mondiale ▁du ▁commerce , ▁en ▁ayant ▁à ▁l ' esprit ▁le ▁paragraphe ▁ 2 1 ▁de ▁la ▁résolution ▁ 5 5 / 1 8 2 ▁et ▁les ▁développement s ▁ultérieurs ▁;\n",
      "▁ 6 . ▁Souligne ▁également ▁que , ▁lorsque ▁l ' on ▁considère ▁les ▁liens ▁entre ▁la ▁mondialisation ▁et ▁le ▁développement ▁durable , ▁il ▁faut ▁en ▁particulier ▁s ' attacher ▁à ▁identifier ▁et ▁à ▁appliquer ▁des ▁politiques ▁et ▁des ▁pratiques ▁qui ▁se ▁renforcent ▁mutuellement ▁et ▁qui ▁encouragent ▁la ▁croissance ▁économique , ▁le ▁développement ▁social ▁et ▁la ▁protection ▁de ▁l ' environnement , ▁et ▁que ▁cela ▁requiert ▁des ▁efforts ▁aux ▁niveaux ▁national ▁et ▁international ▁;\n",
      "---\n",
      "▁ 3 . ▁States ▁Parties ▁shall ▁promote ▁training ▁and ▁technical ▁assistance ▁that ▁will ▁facilitate ▁extradition ▁and ▁mutual ▁legal ▁assistance . ▁S uch ▁training ▁and ▁technical ▁assistance ▁may ▁include ▁language ▁training , ▁second ments ▁and ▁exchanges ▁between ▁personnel ▁in ▁central ▁authorities ▁or ▁agencies ▁with ▁relevant ▁ responsibilities .\n",
      "▁ 1 0 . ▁Stresses ▁the ▁importance ▁of ▁facilitating ▁the ▁accession ▁of ▁all ▁developing ▁countries , ▁particularly ▁the ▁least ▁developed ▁countries , ▁as ▁well ▁as ▁countries ▁with ▁economies ▁in ▁transition , ▁that ▁apply ▁for ▁membership ▁in ▁the ▁World ▁Trade ▁Organization , ▁ bearing ▁in ▁mind ▁paragraph ▁ 2 1 ▁of ▁resolution ▁ 5 5 / 1 8 2 ▁and ▁subsequent ▁developments ;\n",
      "▁ 6 . ▁Underlines ▁the ▁fact ▁that , ▁in ▁addressing ▁the ▁linkages ▁between ▁globalization ▁and ▁sustainable ▁development , ▁particular ▁focus ▁should ▁be ▁placed ▁on ▁identifying ▁and ▁implementing ▁mutually ▁reinforcing ▁policies ▁and ▁practices ▁that ▁promote ▁sustained ▁economic ▁growth , ▁social ▁development ▁and ▁environmental ▁protection ▁and ▁that ▁this ▁requires ▁efforts ▁at ▁both ▁the ▁national ▁and ▁international ▁levels ;\n"
     ]
    }
   ],
   "source": [
    "# First 3 lines after subwording\n",
    "!head -n 3 UN.en-fr.fr-filtered.fr.subword && echo \"---\" && head -n 3 UN.en-fr.en-filtered.en.subword"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ee20fa-dd69-4cbf-a191-72048e07dae0",
   "metadata": {},
   "source": [
    "### Data Splitting\n",
    "\n",
    "We usually split our dataset into 3 portions:\n",
    "\n",
    "    1. training dataset - used for training the model;\n",
    "    2. development dataset - used to run regular validations during the training to help improve the model parameters; and\n",
    "    3. testing dataset - a holdout dataset used after the model finishes training to finally evaluate the model on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "160280d6-54a8-4516-b0b2-06984a5691c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape: (59719, 2)\n",
      "--- Empty Cells Deleted --> Rows: 59719\n",
      "--- Wrote Files\n",
      "Done!\n",
      "Output files\n",
      "UN.en-fr.fr-filtered.fr.subword.train\n",
      "UN.en-fr.en-filtered.en.subword.train\n",
      "UN.en-fr.fr-filtered.fr.subword.dev\n",
      "UN.en-fr.en-filtered.en.subword.dev\n",
      "UN.en-fr.fr-filtered.fr.subword.test\n",
      "UN.en-fr.en-filtered.en.subword.test\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training set, development set, and test set\n",
    "# Development and test sets should be between 1000 and 5000 segments (here we chose 2000)\n",
    "!python3 MT-Preparation/train_dev_split/train_dev_test_split.py 2000 2000 UN.en-fr.fr-filtered.fr.subword UN.en-fr.en-filtered.en.subword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5acd0dcd-df2d-4700-8fbf-784bcefa6ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    2000 UN.en-fr.en-filtered.en.subword.dev\n",
      "    2000 UN.en-fr.en-filtered.en.subword.test\n",
      "   55719 UN.en-fr.en-filtered.en.subword.train\n",
      "    2000 UN.en-fr.fr-filtered.fr.subword.dev\n",
      "    2000 UN.en-fr.fr-filtered.fr.subword.test\n",
      "   55719 UN.en-fr.fr-filtered.fr.subword.train\n",
      "  119438 total\n"
     ]
    }
   ],
   "source": [
    "# Line count for the subworded train, dev, test datatest\n",
    "!wc -l *.subword.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc8bbdc6-4bcc-4866-959f-602de1deda7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is: FirstName SecondName \n",
      "\n",
      "---First line---\n",
      "==> UN.en-fr.en-filtered.en.subword.train <==\n",
      "▁ 3 . ▁States ▁Parties ▁shall ▁promote ▁training ▁and ▁technical ▁assistance ▁that ▁will ▁facilitate ▁extradition ▁and ▁mutual ▁legal ▁assistance . ▁S uch ▁training ▁and ▁technical ▁assistance ▁may ▁include ▁language ▁training , ▁second ments ▁and ▁exchanges ▁between ▁personnel ▁in ▁central ▁authorities ▁or ▁agencies ▁with ▁relevant ▁ responsibilities .\n",
      "\n",
      "==> UN.en-fr.fr-filtered.fr.subword.train <==\n",
      "▁ 3 . ▁Les ▁États ▁Parties ▁encouragent ▁les ▁activités ▁de ▁formation ▁et ▁d ' assistance ▁technique ▁de ▁nature ▁à ▁faciliter ▁l ' extradition ▁et ▁l ' entraide ▁judiciaire . ▁Ces ▁activités ▁de ▁formation ▁et ▁d ' assistance ▁technique ▁peuvent ▁inclure ▁une ▁formation ▁linguistique , ▁des ▁détachement s ▁et ▁des ▁échanges ▁entre ▁les ▁personnels ▁des ▁autorités ▁centrale s ▁ou ▁des ▁organismes ▁ayant ▁des ▁responsabilités ▁d ans ▁les ▁domaines ▁visés .\n",
      "\n",
      "==> UN.en-fr.en-filtered.en.subword.dev <==\n",
      "▁Noting ▁also ▁that ▁the ▁University ▁has ▁launched ▁a ▁broad ▁programme ▁for ▁building ▁a ▁culture ▁of ▁peace ▁worldwide ▁in ▁the ▁context ▁of ▁the ▁efforts ▁being ▁made ▁by ▁the ▁Unit ed ▁Nations ▁and ▁the ▁Unit ed ▁Nations ▁Education al , ▁Scientific ▁and ▁Cultur al ▁Organization ▁for ▁the ▁development ▁and ▁promotion ▁of ▁a ▁culture ▁of ▁peace ,\n",
      "\n",
      "==> UN.en-fr.fr-filtered.fr.subword.dev <==\n",
      "▁Notant ▁également ▁que ▁l ' Université ▁a ▁lancé ▁un ▁vaste ▁programme ▁pour ▁instaurer ▁une ▁culture ▁de ▁paix ▁partout ▁d ans ▁le ▁monde ▁d ans ▁le ▁cadre ▁de ▁l ' action ▁que ▁mènent ▁l ' Organisation ▁des ▁Nations ▁Unies ▁et ▁l ' Organisation ▁des ▁Nations ▁Unies ▁pour ▁l ' éducation , ▁la ▁science ▁et ▁la ▁culture ▁afin ▁de ▁faire ▁ naître ▁et ▁se ▁développer ▁une ▁culture ▁de ▁paix ,\n",
      "\n",
      "==> UN.en-fr.en-filtered.en.subword.test <==\n",
      "▁ 3 . ▁Decides ▁to ▁follow ▁close ly ▁the ▁public ▁consultations ▁on ▁the ▁future ▁political ▁status ▁of ▁Bermuda ▁under ▁way ▁in ▁the ▁Territory , ▁and ▁requests ▁the ▁relevant ▁Unit ed ▁Nations ▁organizations ▁to ▁provide ▁assistance ▁to ▁the ▁Territory , ▁if ▁requested , ▁in ▁the ▁context ▁of ▁its ▁public ▁education ▁programme ;\n",
      "\n",
      "==> UN.en-fr.fr-filtered.fr.subword.test <==\n",
      "▁ 3 . ▁Décide ▁de ▁suivre ▁de ▁près ▁les ▁consultations ▁publiques ▁sur ▁le ▁futur ▁statut ▁politique ▁des ▁Bermudes , ▁qui ▁se ▁déroule nt ▁actuellement ▁d ans ▁le ▁territoire , ▁et ▁prie ▁les ▁organismes ▁compétents ▁des ▁Nations ▁Unies ▁d ' aider ▁ce ▁territoire , ▁s ' il ▁en ▁fait ▁la ▁demande , ▁à ▁exécuter ▁son ▁programme ▁d ' éducation ▁du ▁public ▁;\n",
      "\n",
      "---Last line---\n",
      "==> UN.en-fr.en-filtered.en.subword.train <==\n",
      "▁Recalling ▁its ▁relevant ▁resolutions , ▁including ▁th ose ▁adopted ▁at ▁the ▁tenth ▁emergency ▁special ▁session ,\n",
      "\n",
      "==> UN.en-fr.fr-filtered.fr.subword.train <==\n",
      "▁Rappelant ▁ses ▁résolutions ▁sur ▁la ▁question , ▁notamment ▁celles ▁adoptées ▁à ▁sa ▁dixième ▁session ▁extraordinaire ▁d ' urgence ,\n",
      "\n",
      "==> UN.en-fr.en-filtered.en.subword.dev <==\n",
      "▁ 1 2 . ▁Invites ▁the ▁World ▁I ntellectual ▁Property ▁Organization ▁to ▁continue ▁further ▁its ▁development ▁activities ▁and ▁to ▁continue ▁to ▁cooperate ▁with ▁relevant ▁international ▁organizations ;\n",
      "\n",
      "==> UN.en-fr.fr-filtered.fr.subword.dev <==\n",
      "▁ 1 2 . ▁Invite ▁l ' Organisation ▁mondiale ▁de ▁la ▁propriété ▁intellectuelle ▁à ▁poursuivre ▁ses ▁activités ▁concernant ▁le ▁développement ▁et ▁à ▁continuer ▁de ▁coopérer ▁avec ▁les ▁organisations ▁internationales ▁pertinentes ▁;\n",
      "\n",
      "==> UN.en-fr.en-filtered.en.subword.test <==\n",
      "▁ 9 . ▁Encourages ▁the ▁Board ▁of ▁Trustees ▁to ▁continue ▁its ▁efforts ▁to ▁resolve ▁the ▁financial ▁situation ▁of ▁the ▁Institute , ▁in ▁particular ▁with ▁a ▁view ▁to ▁broaden ing ▁its ▁donor ▁base , ▁and ▁seek ing ▁more ▁predictable ▁and ▁adequate ▁support ▁from ▁Member ▁States ▁for ▁its ▁activities , ▁in ▁particular ▁its ▁core ▁training ▁activities ;\n",
      "\n",
      "==> UN.en-fr.fr-filtered.fr.subword.test <==\n",
      "▁ 9 . ▁Encourage ▁le ▁Conseil ▁d ' administration ▁à ▁poursuivre ▁ses ▁efforts ▁pour ▁remédier ▁à ▁la ▁situation ▁financière ▁de ▁l ' Institut , ▁en ▁particulier ▁pour ▁élargir ▁sa ▁base ▁de ▁donateurs ▁et ▁obtenir ▁des ▁États ▁Membres ▁un ▁soutien ▁plus ▁prévisible ▁et ▁plus ▁adéquat ▁à ▁ses ▁activités , ▁notamment ▁ses ▁activités ▁de ▁formation ▁de ▁base ▁;\n"
     ]
    }
   ],
   "source": [
    "# Check the first and last line from each dataset\n",
    "\n",
    "# -------------------------------------------\n",
    "# Change this cell to print your name\n",
    "!echo -e \"My name is: FirstName SecondName \\n\"\n",
    "# -------------------------------------------\n",
    "\n",
    "!echo \"---First line---\"\n",
    "!head -n 1 *.{train,dev,test}\n",
    "\n",
    "!echo -e \"\\n---Last line---\"\n",
    "!tail -n 1 *.{train,dev,test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ea26c12-6c4c-455b-a51d-0ff609bae23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting OpenNMT-py\n",
      "  Obtaining dependency information for OpenNMT-py from https://files.pythonhosted.org/packages/65/6f/c9eb54c967a722035c5ae136f087df5a4072bb81a98d61c00af79250b9ad/OpenNMT_py-3.3-py3-none-any.whl.metadata\n",
      "  Downloading OpenNMT_py-3.3-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: torch<2.1,>=1.13 in /opt/conda/lib/python3.9/site-packages (from OpenNMT-py) (1.13.1+cu117)\n",
      "Collecting configargparse (from OpenNMT-py)\n",
      "  Obtaining dependency information for configargparse from https://files.pythonhosted.org/packages/6f/b3/b4ac838711fd74a2b4e6f746703cf9dd2cf5462d17dac07e349234e21b97/ConfigArgParse-1.7-py3-none-any.whl.metadata\n",
      "  Downloading ConfigArgParse-1.7-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting ctranslate2<4,>=3.2 (from OpenNMT-py)\n",
      "  Obtaining dependency information for ctranslate2<4,>=3.2 from https://files.pythonhosted.org/packages/85/87/2961f66cd9aecf152ec18836699cd5e32b449f2a3ea30602198687c945b0/ctranslate2-3.18.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading ctranslate2-3.18.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting tensorboard>=2.3 (from OpenNMT-py)\n",
      "  Obtaining dependency information for tensorboard>=2.3 from https://files.pythonhosted.org/packages/bc/a2/ff5f4c299eb37c95299a76015da3f30211468e29d8d6f1d011683279baee/tensorboard-2.14.0-py3-none-any.whl.metadata\n",
      "  Downloading tensorboard-2.14.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting flask (from OpenNMT-py)\n",
      "  Obtaining dependency information for flask from https://files.pythonhosted.org/packages/fd/56/26f0be8adc2b4257df20c1c4260ddd0aa396cf8e75d90ab2f7ff99bc34f9/flask-2.3.3-py3-none-any.whl.metadata\n",
      "  Downloading flask-2.3.3-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting waitress (from OpenNMT-py)\n",
      "  Downloading waitress-2.1.2-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m17.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[?25hCollecting pyonmttok<2,>=1.35 (from OpenNMT-py)\n",
      "  Downloading pyonmttok-1.37.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m94.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:05\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (from OpenNMT-py) (6.0.1)\n",
      "Collecting sacrebleu (from OpenNMT-py)\n",
      "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m121.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting rapidfuzz (from OpenNMT-py)\n",
      "  Obtaining dependency information for rapidfuzz from https://files.pythonhosted.org/packages/b2/fd/36eb50a3a2e0d6df1ae1cdcd3a5c4a3e3cb68f3220499798e28be2bb0cfe/rapidfuzz-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading rapidfuzz-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting pyahocorasick (from OpenNMT-py)\n",
      "  Downloading pyahocorasick-2.0.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (103 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 kB\u001b[0m \u001b[31m81.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting fasttext-wheel (from OpenNMT-py)\n",
      "  Downloading fasttext_wheel-0.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m116.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from ctranslate2<4,>=3.2->OpenNMT-py) (1.25.2)\n",
      "Collecting absl-py>=0.4 (from tensorboard>=2.3->OpenNMT-py)\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m122.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.9/site-packages (from tensorboard>=2.3->OpenNMT-py) (1.56.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.9/site-packages (from tensorboard>=2.3->OpenNMT-py) (2.22.0)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard>=2.3->OpenNMT-py)\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard>=2.3->OpenNMT-py)\n",
      "  Obtaining dependency information for markdown>=2.6.8 from https://files.pythonhosted.org/packages/1a/b5/228c1cdcfe138f1a8e01ab1b54284c8b83735476cb22b6ba251656ed13ad/Markdown-3.4.4-py3-none-any.whl.metadata\n",
      "  Downloading Markdown-3.4.4-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in /opt/conda/lib/python3.9/site-packages (from tensorboard>=2.3->OpenNMT-py) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard>=2.3->OpenNMT-py) (2.31.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard>=2.3->OpenNMT-py) (68.0.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard>=2.3->OpenNMT-py)\n",
      "  Obtaining dependency information for tensorboard-data-server<0.8.0,>=0.7.0 from https://files.pythonhosted.org/packages/02/52/fb9e51fba47951aabd7a6b25e41d73eae94208ccf62d886168096941a781/tensorboard_data_server-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata\n",
      "  Downloading tensorboard_data_server-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard>=2.3->OpenNMT-py)\n",
      "  Obtaining dependency information for werkzeug>=1.0.1 from https://files.pythonhosted.org/packages/9b/59/a7c32e3d8d0e546a206e0552a2c04444544f15c1da4a01df8938d20c6ffc/werkzeug-2.3.7-py3-none-any.whl.metadata\n",
      "  Downloading werkzeug-2.3.7-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.9/site-packages (from tensorboard>=2.3->OpenNMT-py) (0.41.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch<2.1,>=1.13->OpenNMT-py) (4.7.1)\n",
      "Collecting pybind11>=2.2 (from fasttext-wheel->OpenNMT-py)\n",
      "  Obtaining dependency information for pybind11>=2.2 from https://files.pythonhosted.org/packages/06/55/9f73c32dda93fa4f539fafa268f9504e83c489f460c380371d94296126cd/pybind11-2.11.1-py3-none-any.whl.metadata\n",
      "  Downloading pybind11-2.11.1-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /opt/conda/lib/python3.9/site-packages (from flask->OpenNMT-py) (3.1.2)\n",
      "Collecting itsdangerous>=2.1.2 (from flask->OpenNMT-py)\n",
      "  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: click>=8.1.3 in /opt/conda/lib/python3.9/site-packages (from flask->OpenNMT-py) (8.1.6)\n",
      "Collecting blinker>=1.6.2 (from flask->OpenNMT-py)\n",
      "  Downloading blinker-1.6.2-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: importlib-metadata>=3.6.0 in /opt/conda/lib/python3.9/site-packages (from flask->OpenNMT-py) (6.8.0)\n",
      "Collecting portalocker (from sacrebleu->OpenNMT-py)\n",
      "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.9/site-packages (from sacrebleu->OpenNMT-py) (2023.6.3)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.9/site-packages (from sacrebleu->OpenNMT-py) (0.9.0)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.9/site-packages (from sacrebleu->OpenNMT-py) (0.4.6)\n",
      "Collecting lxml (from sacrebleu->OpenNMT-py)\n",
      "  Obtaining dependency information for lxml from https://files.pythonhosted.org/packages/c5/a2/7876f76606725340c989b1c73b5501fc41fb21e50a8597c9ecdb63a05b27/lxml-4.9.3-cp39-cp39-manylinux_2_28_x86_64.whl.metadata\n",
      "  Downloading lxml-4.9.3-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (4.9)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (1.16.0)\n",
      "Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.9/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.3->OpenNMT-py) (1.3.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata>=3.6.0->flask->OpenNMT-py) (3.16.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from Jinja2>=3.1.2->flask->OpenNMT-py) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (2023.7.22)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.3->OpenNMT-py) (3.2.2)\n",
      "Downloading OpenNMT_py-3.3-py3-none-any.whl (242 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.9/242.9 kB\u001b[0m \u001b[31m130.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ctranslate2-3.18.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hDownloading tensorboard-2.14.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hDownloading ConfigArgParse-1.7-py3-none-any.whl (25 kB)\n",
      "Downloading flask-2.3.3-py3-none-any.whl (96 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.1/96.1 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading rapidfuzz-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading Markdown-3.4.4-py3-none-any.whl (94 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.2/94.2 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.7/227.7 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.1-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-2.3.7-py3-none-any.whl (242 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.2/242.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading lxml-4.9.3-cp39-cp39-manylinux_2_28_x86_64.whl (8.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: werkzeug, waitress, tensorboard-data-server, rapidfuzz, pyonmttok, pybind11, pyahocorasick, portalocker, lxml, itsdangerous, ctranslate2, configargparse, blinker, absl-py, sacrebleu, markdown, flask, fasttext-wheel, google-auth-oauthlib, tensorboard, OpenNMT-py\n",
      "Successfully installed OpenNMT-py-3.3 absl-py-1.4.0 blinker-1.6.2 configargparse-1.7 ctranslate2-3.18.0 fasttext-wheel-0.9.2 flask-2.3.3 google-auth-oauthlib-1.0.0 itsdangerous-2.1.2 lxml-4.9.3 markdown-3.4.4 portalocker-2.7.0 pyahocorasick-2.0.0 pybind11-2.11.1 pyonmttok-1.37.1 rapidfuzz-3.2.0 sacrebleu-2.3.1 tensorboard-2.14.0 tensorboard-data-server-0.7.1 waitress-2.1.2 werkzeug-2.3.7\n"
     ]
    }
   ],
   "source": [
    "# Install OpenNMT-py 3.x\n",
    "!pip3 install OpenNMT-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20f760bf-a5e2-4f79-b818-48b9a0963204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en-fr.txt.zip\t\t\t UN.en-fr.en-filtered.en.subword.dev\n",
      "MT-Preparation\t\t\t UN.en-fr.en-filtered.en.subword.test\n",
      "README\t\t\t\t UN.en-fr.en-filtered.en.subword.train\n",
      "source.model\t\t\t UN.en-fr.fr\n",
      "source.vocab\t\t\t UN.en-fr.fr-filtered.fr\n",
      "target.model\t\t\t UN.en-fr.fr-filtered.fr.subword\n",
      "target.vocab\t\t\t UN.en-fr.fr-filtered.fr.subword.dev\n",
      "UN.en-fr.en\t\t\t UN.en-fr.fr-filtered.fr.subword.test\n",
      "UN.en-fr.en-filtered.en\t\t UN.en-fr.fr-filtered.fr.subword.train\n",
      "UN.en-fr.en-filtered.en.subword\n"
     ]
    }
   ],
   "source": [
    "# Open the folder where you saved your prepapred datasets from the first exercise\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45bbb1bf-7619-4920-8fc4-2807732b369f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/nmt'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcfcba1-a9d8-44e6-9afe-4047bf07c9f5",
   "metadata": {},
   "source": [
    "### Create the Training Configuration File\n",
    "\n",
    "The following config file matches most of the recommended values for the Transformer model [Vaswani et al., 2017](https://arxiv.org/abs/1706.03762). As the current dataset is small, we reduced the following values:\n",
    "\n",
    "    train_steps - for datasets with a few millions of sentences, consider using a value between 100000 and 200000, or more! Enabling the option early_stopping can help stop the training when there is no considerable improvement.\n",
    "    valid_steps - 10000 can be good if the value train_steps is big enough.\n",
    "    warmup_steps - obviously, its value must be less than train_steps. Try 4000 and 8000 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "740b39fe-14a6-42e3-bdae-e486810913f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the YAML configuration file\n",
    "# On a regular machine, you can create it manually or with nano\n",
    "# Note here we are using some smaller values because the dataset is small\n",
    "# For larger datasets, consider increasing: train_steps, valid_steps, warmup_steps, save_checkpoint_steps, keep_checkpoint\n",
    "\n",
    "config = '''# config.yaml\n",
    "\n",
    "\n",
    "## Where the samples will be written\n",
    "save_data: run\n",
    "\n",
    "# Training files\n",
    "data:\n",
    "    corpus_1:\n",
    "        path_src: UN.en-fr.fr-filtered.fr.subword.train\n",
    "        path_tgt: UN.en-fr.en-filtered.en.subword.train\n",
    "        transforms: [filtertoolong]\n",
    "    valid:\n",
    "        path_src: UN.en-fr.fr-filtered.fr.subword.dev\n",
    "        path_tgt: UN.en-fr.en-filtered.en.subword.dev\n",
    "        transforms: [filtertoolong]\n",
    "\n",
    "# Vocabulary files, generated by onmt_build_vocab\n",
    "src_vocab: run/source.vocab\n",
    "tgt_vocab: run/target.vocab\n",
    "\n",
    "# Vocabulary size - should be the same as in sentence piece\n",
    "src_vocab_size: 50000\n",
    "tgt_vocab_size: 50000\n",
    "\n",
    "# Filter out source/target longer than n if [filtertoolong] enabled\n",
    "src_seq_length: 150\n",
    "src_seq_length: 150\n",
    "\n",
    "# Tokenization options\n",
    "src_subword_model: source.model\n",
    "tgt_subword_model: target.model\n",
    "\n",
    "# Where to save the log file and the output models/checkpoints\n",
    "log_file: train.log\n",
    "save_model: models/model.fren\n",
    "\n",
    "# Stop training if it does not imporve after n validations\n",
    "early_stopping: 4\n",
    "\n",
    "# Default: 5000 - Save a model checkpoint for each n\n",
    "save_checkpoint_steps: 1000\n",
    "\n",
    "# To save space, limit checkpoints to last n\n",
    "# keep_checkpoint: 3\n",
    "\n",
    "seed: 3435\n",
    "\n",
    "# Default: 100000 - Train the model to max n steps \n",
    "# Increase to 200000 or more for large datasets\n",
    "# For fine-tuning, add up the required steps to the original steps\n",
    "train_steps: 3000\n",
    "\n",
    "# Default: 10000 - Run validation after n steps\n",
    "valid_steps: 1000\n",
    "\n",
    "# Default: 4000 - for large datasets, try up to 8000\n",
    "warmup_steps: 1000\n",
    "report_every: 100\n",
    "\n",
    "# Number of GPUs, and IDs of GPUs\n",
    "world_size: 1\n",
    "gpu_ranks: [0]\n",
    "\n",
    "# Batching\n",
    "bucket_size: 262144\n",
    "num_workers: 0  # Default: 2, set to 0 when RAM out of memory\n",
    "batch_type: \"tokens\"\n",
    "batch_size: 4096   # Tokens per batch, change when CUDA out of memory\n",
    "valid_batch_size: 2048\n",
    "max_generator_batches: 2\n",
    "accum_count: [4]\n",
    "accum_steps: [0]\n",
    "\n",
    "# Optimization\n",
    "model_dtype: \"fp16\"\n",
    "optim: \"adam\"\n",
    "learning_rate: 2\n",
    "# warmup_steps: 8000\n",
    "decay_method: \"noam\"\n",
    "adam_beta2: 0.998\n",
    "max_grad_norm: 0\n",
    "label_smoothing: 0.1\n",
    "param_init: 0\n",
    "param_init_glorot: true\n",
    "normalization: \"tokens\"\n",
    "\n",
    "# Model\n",
    "encoder_type: transformer\n",
    "decoder_type: transformer\n",
    "position_encoding: true\n",
    "enc_layers: 6\n",
    "dec_layers: 6\n",
    "heads: 8\n",
    "hidden_size: 512\n",
    "word_vec_size: 512\n",
    "transformer_ff: 2048\n",
    "dropout_steps: [0]\n",
    "dropout: [0.1]\n",
    "attention_dropout: [0.1]\n",
    "'''\n",
    "\n",
    "with open(\"config.yaml\", \"w+\") as config_yaml:\n",
    "  config_yaml.write(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "980c6a6b-1840-4b8f-9e02-97cd0595a206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# config.yaml\n",
      "\n",
      "\n",
      "## Where the samples will be written\n",
      "save_data: run\n",
      "\n",
      "# Training files\n",
      "data:\n",
      "    corpus_1:\n",
      "        path_src: UN.en-fr.fr-filtered.fr.subword.train\n",
      "        path_tgt: UN.en-fr.en-filtered.en.subword.train\n",
      "        transforms: [filtertoolong]\n",
      "    valid:\n",
      "        path_src: UN.en-fr.fr-filtered.fr.subword.dev\n",
      "        path_tgt: UN.en-fr.en-filtered.en.subword.dev\n",
      "        transforms: [filtertoolong]\n",
      "\n",
      "# Vocabulary files, generated by onmt_build_vocab\n",
      "src_vocab: run/source.vocab\n",
      "tgt_vocab: run/target.vocab\n",
      "\n",
      "# Vocabulary size - should be the same as in sentence piece\n",
      "src_vocab_size: 50000\n",
      "tgt_vocab_size: 50000\n",
      "\n",
      "# Filter out source/target longer than n if [filtertoolong] enabled\n",
      "src_seq_length: 150\n",
      "src_seq_length: 150\n",
      "\n",
      "# Tokenization options\n",
      "src_subword_model: source.model\n",
      "tgt_subword_model: target.model\n",
      "\n",
      "# Where to save the log file and the output models/checkpoints\n",
      "log_file: train.log\n",
      "save_model: models/model.fren\n",
      "\n",
      "# Stop training if it does not imporve after n validations\n",
      "early_stopping: 4\n",
      "\n",
      "# Default: 5000 - Save a model checkpoint for each n\n",
      "save_checkpoint_steps: 1000\n",
      "\n",
      "# To save space, limit checkpoints to last n\n",
      "# keep_checkpoint: 3\n",
      "\n",
      "seed: 3435\n",
      "\n",
      "# Default: 100000 - Train the model to max n steps \n",
      "# Increase to 200000 or more for large datasets\n",
      "# For fine-tuning, add up the required steps to the original steps\n",
      "train_steps: 3000\n",
      "\n",
      "# Default: 10000 - Run validation after n steps\n",
      "valid_steps: 1000\n",
      "\n",
      "# Default: 4000 - for large datasets, try up to 8000\n",
      "warmup_steps: 1000\n",
      "report_every: 100\n",
      "\n",
      "# Number of GPUs, and IDs of GPUs\n",
      "world_size: 1\n",
      "gpu_ranks: [0]\n",
      "\n",
      "# Batching\n",
      "bucket_size: 262144\n",
      "num_workers: 0  # Default: 2, set to 0 when RAM out of memory\n",
      "batch_type: \"tokens\"\n",
      "batch_size: 4096   # Tokens per batch, change when CUDA out of memory\n",
      "valid_batch_size: 2048\n",
      "max_generator_batches: 2\n",
      "accum_count: [4]\n",
      "accum_steps: [0]\n",
      "\n",
      "# Optimization\n",
      "model_dtype: \"fp16\"\n",
      "optim: \"adam\"\n",
      "learning_rate: 2\n",
      "# warmup_steps: 8000\n",
      "decay_method: \"noam\"\n",
      "adam_beta2: 0.998\n",
      "max_grad_norm: 0\n",
      "label_smoothing: 0.1\n",
      "param_init: 0\n",
      "param_init_glorot: true\n",
      "normalization: \"tokens\"\n",
      "\n",
      "# Model\n",
      "encoder_type: transformer\n",
      "decoder_type: transformer\n",
      "position_encoding: true\n",
      "enc_layers: 6\n",
      "dec_layers: 6\n",
      "heads: 8\n",
      "hidden_size: 512\n",
      "word_vec_size: 512\n",
      "transformer_ff: 2048\n",
      "dropout_steps: [0]\n",
      "dropout: [0.1]\n",
      "attention_dropout: [0.1]\n"
     ]
    }
   ],
   "source": [
    "# [Optional] Check the content of the configuration file\n",
    "!cat config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba801ade-8f81-464d-8b6d-8724a10f11be",
   "metadata": {},
   "source": [
    "### Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2162423-d91f-41d3-aed4-bc7cc8e5973f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "# Find the number of CPUs/cores on the machine\n",
    "!nproc --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fad62d9d-4769-46c2-8f9c-c48a761355b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
      "[2023-08-22 03:47:26,506 INFO] Counter vocab from -1 samples.\n",
      "[2023-08-22 03:47:26,506 INFO] n_sample=-1: Build vocab on full datasets.\n",
      "[2023-08-22 03:47:28,062 INFO] * Transform statistics for corpus_1(25.00%):\n",
      "\t\t\t* FilterTooLongStats(filtered=1053)\n",
      "\n",
      "[2023-08-22 03:47:28,063 INFO] * Transform statistics for corpus_1(25.00%):\n",
      "\t\t\t* FilterTooLongStats(filtered=1088)\n",
      "\n",
      "[2023-08-22 03:47:28,118 INFO] * Transform statistics for corpus_1(25.00%):\n",
      "\t\t\t* FilterTooLongStats(filtered=1031)\n",
      "\n",
      "[2023-08-22 03:47:28,130 INFO] * Transform statistics for corpus_1(25.00%):\n",
      "\t\t\t* FilterTooLongStats(filtered=1028)\n",
      "\n",
      "[2023-08-22 03:47:28,190 INFO] Counters src: 14714\n",
      "[2023-08-22 03:47:28,191 INFO] Counters tgt: 11885\n"
     ]
    }
   ],
   "source": [
    "# Build Vocabulary\n",
    "\n",
    "# -config: path to your config.yaml file\n",
    "# -n_sample: use -1 to build vocabulary on all the segment in the training dataset\n",
    "# -num_threads: change it to match the number of CPUs to run it faster\n",
    "\n",
    "!onmt_build_vocab -config config.yaml -n_sample -1 -num_threads 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5505ba4a-5e9c-44c7-b6b4-c7ee59fa7020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: GRID V100-16C (UUID: GPU-87e669c5-28e4-11b2-bca1-dacc96a729c6)\n"
     ]
    }
   ],
   "source": [
    "# Check if the GPU is active\n",
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e6aa9b8-49f3-4a47-96a3-932a91e9df46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "GRID V100-16C\n",
      "Free GPU memory: 14907.546875 out of: 16384.0\n"
     ]
    }
   ],
   "source": [
    "# Check if the GPU is visable to PyTorch\n",
    "\n",
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "gpu_memory = torch.cuda.mem_get_info(0)\n",
    "print(\"Free GPU memory:\", gpu_memory[0]/1024**2, \"out of:\", gpu_memory[1]/1024**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22090343-58ce-4603-9dba-8fdfcb140aae",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b8b6e74-587e-422d-81f7-a54bb0578ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be3e8638-7f8c-48e8-8c8e-1d48ec5caf84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-22 03:48:03,605 WARNING] Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
      "[2023-08-22 03:48:03,605 INFO] Parsed 2 corpora from -data.\n",
      "[2023-08-22 03:48:03,605 INFO] Get special vocabs from Transforms: {'src': [], 'tgt': []}.\n",
      "[2023-08-22 03:48:03,691 INFO] The first 10 tokens of the vocabs are:['<unk>', '<blank>', '<s>', '</s>', '▁de', ',', \"'\", '▁et', '▁', '▁la']\n",
      "[2023-08-22 03:48:03,691 INFO] The decoder start token is: <s>\n",
      "[2023-08-22 03:48:03,691 INFO] Building model...\n",
      "[2023-08-22 03:48:04,387 INFO] Switching model to float32 for amp/apex_amp\n",
      "[2023-08-22 03:48:04,388 INFO] Non quantized layer compute is fp16\n",
      "[2023-08-22 03:48:05,481 INFO] NMTModel(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(14720, 512, padding_idx=1)\n",
      "        )\n",
      "        (pe): PositionalEncoding()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (3): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (4): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (5): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(11896, 512, padding_idx=1)\n",
      "        )\n",
      "        (pe): PositionalEncoding()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "    (transformer_layers): ModuleList(\n",
      "      (0): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (1): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (2): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (3): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (4): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (5): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (generator): Linear(in_features=512, out_features=11896, bias=True)\n",
      ")\n",
      "[2023-08-22 03:48:05,484 INFO] encoder: 26424320\n",
      "[2023-08-22 03:48:05,484 INFO] decoder: 37378680\n",
      "[2023-08-22 03:48:05,484 INFO] * number of parameters: 63803000\n",
      "[2023-08-22 03:48:05,485 INFO] Trainable parameters = {'torch.float32': 63803000, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
      "[2023-08-22 03:48:05,485 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
      "[2023-08-22 03:48:05,485 INFO]  * src vocab size = 14720\n",
      "[2023-08-22 03:48:05,485 INFO]  * tgt vocab size = 11896\n",
      "[2023-08-22 03:48:05,488 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 1\n",
      "[2023-08-22 03:48:05,488 INFO] Starting training on GPU: [0]\n",
      "[2023-08-22 03:48:05,488 INFO] Start training loop and validate every 1000 steps...\n",
      "[2023-08-22 03:48:05,488 INFO] Scoring with: TransformPipe(FilterTooLongTransform(src_seq_length=150, tgt_seq_length=192))\n",
      "[2023-08-22 03:48:11,079 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 2\n",
      "[2023-08-22 03:48:17,871 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 3\n",
      "[2023-08-22 03:48:23,844 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 4\n",
      "[2023-08-22 03:48:30,148 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 5\n",
      "[2023-08-22 03:49:33,527 INFO] Step 100/ 3000; acc: 8.9; ppl: 1625.8; xent: 7.4; lr: 0.00028; sents:   27032; bsz: 4003/3521/68; 18187/15998 tok/s;     88 sec;\n",
      "[2023-08-22 03:50:11,150 INFO] Step 200/ 3000; acc: 29.9; ppl: 161.5; xent: 5.1; lr: 0.00056; sents:   24187; bsz: 4019/3522/60; 42731/37446 tok/s;    126 sec;\n",
      "[2023-08-22 03:50:48,737 INFO] Step 300/ 3000; acc: 41.0; ppl:  64.2; xent: 4.2; lr: 0.00084; sents:   25263; bsz: 4012/3525/63; 42701/37512 tok/s;    163 sec;\n",
      "[2023-08-22 03:51:26,452 INFO] Step 400/ 3000; acc: 48.0; ppl:  38.3; xent: 3.6; lr: 0.00112; sents:   25744; bsz: 4015/3535/64; 42587/37494 tok/s;    201 sec;\n",
      "[2023-08-22 03:52:04,152 INFO] Step 500/ 3000; acc: 56.1; ppl:  24.8; xent: 3.2; lr: 0.00140; sents:   26988; bsz: 4007/3525/67; 42513/37402 tok/s;    239 sec;\n",
      "[2023-08-22 03:52:41,930 INFO] Step 600/ 3000; acc: 63.3; ppl:  17.6; xent: 2.9; lr: 0.00168; sents:   26546; bsz: 4007/3524/66; 42429/37311 tok/s;    276 sec;\n",
      "[2023-08-22 03:53:21,350 INFO] Step 700/ 3000; acc: 67.9; ppl:  14.1; xent: 2.6; lr: 0.00196; sents:   29508; bsz: 3995/3531/74; 40535/35834 tok/s;    316 sec;\n",
      "[2023-08-22 03:54:02,484 INFO] Step 800/ 3000; acc: 70.5; ppl:  12.4; xent: 2.5; lr: 0.00224; sents:   23961; bsz: 4017/3526/60; 39070/34292 tok/s;    357 sec;\n",
      "[2023-08-22 03:54:42,261 INFO] Step 900/ 3000; acc: 72.0; ppl:  11.5; xent: 2.4; lr: 0.00252; sents:   26184; bsz: 4015/3527/65; 40373/35470 tok/s;    397 sec;\n",
      "[2023-08-22 03:54:45,306 INFO] * Transform statistics for corpus_1(100.00%):\n",
      "\t\t\t* FilterTooLongStats(filtered=19772)\n",
      "\n",
      "[2023-08-22 03:54:45,307 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 6\n",
      "[2023-08-22 03:54:55,645 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 7\n",
      "[2023-08-22 03:55:00,388 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 8\n",
      "[2023-08-22 03:55:11,810 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 9\n",
      "[2023-08-22 03:55:16,888 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 10\n",
      "[2023-08-22 03:56:24,222 INFO] Step 1000/ 3000; acc: 72.7; ppl:  11.0; xent: 2.4; lr: 0.00279; sents:   25646; bsz: 4012/3527/64; 15740/13836 tok/s;    499 sec;\n",
      "[2023-08-22 03:56:27,683 INFO] valid stats calculation and sentences rebuilding\n",
      "                           took: 3.4584364891052246 s.\n",
      "[2023-08-22 03:56:27,686 INFO] Train perplexity: 37.9192\n",
      "[2023-08-22 03:56:27,686 INFO] Train accuracy: 53.0478\n",
      "[2023-08-22 03:56:27,686 INFO] Sentences processed: 261059\n",
      "[2023-08-22 03:56:27,686 INFO] Average bsz: 4010/3526/65\n",
      "[2023-08-22 03:56:27,686 INFO] Validation perplexity: 12.5087\n",
      "[2023-08-22 03:56:27,686 INFO] Validation accuracy: 71.6938\n",
      "[2023-08-22 03:56:27,686 INFO] Model is improving ppl: inf --> 12.5087.\n",
      "[2023-08-22 03:56:27,686 INFO] Model is improving acc: -inf --> 71.6938.\n",
      "[2023-08-22 03:56:27,692 INFO] Saving checkpoint models/model.fren_step_1000.pt\n",
      "[2023-08-22 03:57:07,683 INFO] Step 1100/ 3000; acc: 73.9; ppl:  10.4; xent: 2.3; lr: 0.00266; sents:   24717; bsz: 4015/3520/62; 36954/32395 tok/s;    542 sec;\n",
      "[2023-08-22 03:57:46,504 INFO] Step 1200/ 3000; acc: 76.2; ppl:   9.5; xent: 2.2; lr: 0.00255; sents:   28098; bsz: 4004/3530/70; 41258/36373 tok/s;    581 sec;\n",
      "[2023-08-22 03:58:25,240 INFO] Step 1300/ 3000; acc: 79.5; ppl:   8.2; xent: 2.1; lr: 0.00245; sents:   26524; bsz: 4008/3528/66; 41384/36436 tok/s;    620 sec;\n",
      "[2023-08-22 03:59:03,942 INFO] Step 1400/ 3000; acc: 80.8; ppl:   7.8; xent: 2.0; lr: 0.00236; sents:   25065; bsz: 4017/3528/63; 41519/36469 tok/s;    658 sec;\n",
      "[2023-08-22 03:59:42,650 INFO] Step 1500/ 3000; acc: 83.2; ppl:   7.0; xent: 2.0; lr: 0.00228; sents:   24877; bsz: 4016/3525/62; 41500/36430 tok/s;    697 sec;\n",
      "[2023-08-22 04:00:21,428 INFO] Step 1600/ 3000; acc: 84.3; ppl:   6.7; xent: 1.9; lr: 0.00221; sents:   27381; bsz: 4007/3529/68; 41332/36404 tok/s;    736 sec;\n",
      "[2023-08-22 04:01:00,280 INFO] Step 1700/ 3000; acc: 85.7; ppl:   6.3; xent: 1.8; lr: 0.00214; sents:   26250; bsz: 4007/3525/66; 41255/36292 tok/s;    775 sec;\n",
      "[2023-08-22 04:01:39,040 INFO] Step 1800/ 3000; acc: 86.8; ppl:   6.1; xent: 1.8; lr: 0.00208; sents:   26722; bsz: 4009/3525/67; 41371/36377 tok/s;    814 sec;\n",
      "[2023-08-22 04:01:43,879 INFO] * Transform statistics for corpus_1(100.00%):\n",
      "\t\t\t* FilterTooLongStats(filtered=19736)\n",
      "\n",
      "[2023-08-22 04:01:43,879 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 11\n",
      "[2023-08-22 04:01:48,532 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 12\n",
      "[2023-08-22 04:01:57,084 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 13\n",
      "[2023-08-22 04:02:01,632 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 14\n",
      "[2023-08-22 04:02:11,334 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 15\n",
      "[2023-08-22 04:03:11,257 INFO] Step 1900/ 3000; acc: 88.9; ppl:   5.6; xent: 1.7; lr: 0.00203; sents:   27069; bsz: 4009/3532/68; 17389/15321 tok/s;    906 sec;\n",
      "[2023-08-22 04:03:50,321 INFO] Step 2000/ 3000; acc: 89.3; ppl:   5.5; xent: 1.7; lr: 0.00198; sents:   27439; bsz: 4007/3532/69; 41031/36169 tok/s;    945 sec;\n",
      "[2023-08-22 04:03:54,464 INFO] * Transform statistics for valid(100.00%):\n",
      "\t\t\t* FilterTooLongStats(filtered=134)\n",
      "\n",
      "[2023-08-22 04:03:57,876 INFO] valid stats calculation and sentences rebuilding\n",
      "                           took: 7.55215048789978 s.\n",
      "[2023-08-22 04:03:57,879 INFO] Train perplexity: 16.4743\n",
      "[2023-08-22 04:03:57,879 INFO] Train accuracy: 67.9575\n",
      "[2023-08-22 04:03:57,879 INFO] Sentences processed: 525201\n",
      "[2023-08-22 04:03:57,879 INFO] Average bsz: 4010/3527/66\n",
      "[2023-08-22 04:03:57,879 INFO] Validation perplexity: 7.36079\n",
      "[2023-08-22 04:03:57,879 INFO] Validation accuracy: 84.8289\n",
      "[2023-08-22 04:03:57,879 INFO] Model is improving ppl: 12.5087 --> 7.36079.\n",
      "[2023-08-22 04:03:57,879 INFO] Model is improving acc: 71.6938 --> 84.8289.\n",
      "[2023-08-22 04:03:57,885 INFO] Saving checkpoint models/model.fren_step_2000.pt\n",
      "[2023-08-22 04:04:38,208 INFO] Step 2100/ 3000; acc: 89.6; ppl:   5.4; xent: 1.7; lr: 0.00193; sents:   25496; bsz: 4013/3528/64; 33523/29468 tok/s;    993 sec;\n",
      "[2023-08-22 04:05:17,157 INFO] Step 2200/ 3000; acc: 90.1; ppl:   5.3; xent: 1.7; lr: 0.00188; sents:   24815; bsz: 4015/3524/62; 41232/36192 tok/s;   1032 sec;\n",
      "[2023-08-22 04:05:55,876 INFO] Step 2300/ 3000; acc: 90.7; ppl:   5.2; xent: 1.7; lr: 0.00184; sents:   25604; bsz: 4009/3527/64; 41416/36435 tok/s;   1070 sec;\n",
      "[2023-08-22 04:06:34,713 INFO] Step 2400/ 3000; acc: 91.3; ppl:   5.1; xent: 1.6; lr: 0.00180; sents:   25364; bsz: 4011/3517/63; 41314/36224 tok/s;   1109 sec;\n",
      "[2023-08-22 04:07:13,329 INFO] Step 2500/ 3000; acc: 91.8; ppl:   5.0; xent: 1.6; lr: 0.00177; sents:   26392; bsz: 4013/3530/66; 41567/36563 tok/s;   1148 sec;\n",
      "[2023-08-22 04:07:52,235 INFO] Step 2600/ 3000; acc: 92.2; ppl:   4.9; xent: 1.6; lr: 0.00173; sents:   27660; bsz: 4004/3529/69; 41169/36283 tok/s;   1187 sec;\n",
      "[2023-08-22 04:08:31,014 INFO] Step 2700/ 3000; acc: 92.6; ppl:   4.9; xent: 1.6; lr: 0.00170; sents:   25626; bsz: 4012/3523/64; 41380/36345 tok/s;   1226 sec;\n",
      "[2023-08-22 04:08:38,509 INFO] * Transform statistics for corpus_1(100.00%):\n",
      "\t\t\t* FilterTooLongStats(filtered=19763)\n",
      "\n",
      "[2023-08-22 04:08:38,509 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 16\n",
      "[2023-08-22 04:08:47,433 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 17\n",
      "[2023-08-22 04:08:52,051 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 18\n",
      "[2023-08-22 04:09:01,880 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 19\n",
      "[2023-08-22 04:10:10,075 INFO] Step 2800/ 3000; acc: 93.6; ppl:   4.7; xent: 1.5; lr: 0.00167; sents:   26115; bsz: 4011/3523/65; 16198/14227 tok/s;   1325 sec;\n",
      "[2023-08-22 04:10:49,058 INFO] Step 2900/ 3000; acc: 93.6; ppl:   4.7; xent: 1.5; lr: 0.00164; sents:   25758; bsz: 4012/3524/64; 41166/36163 tok/s;   1364 sec;\n",
      "[2023-08-22 04:11:27,970 INFO] Step 3000/ 3000; acc: 93.9; ppl:   4.6; xent: 1.5; lr: 0.00161; sents:   25357; bsz: 4015/3520/63; 41275/36188 tok/s;   1402 sec;\n",
      "[2023-08-22 04:11:28,154 INFO] * Transform statistics for valid(100.00%):\n",
      "\t\t\t* FilterTooLongStats(filtered=134)\n",
      "\n",
      "[2023-08-22 04:11:31,507 INFO] valid stats calculation and sentences rebuilding\n",
      "                           took: 3.535004138946533 s.\n",
      "[2023-08-22 04:11:31,510 INFO] Train perplexity: 11.0637\n",
      "[2023-08-22 04:11:31,510 INFO] Train accuracy: 75.9542\n",
      "[2023-08-22 04:11:31,510 INFO] Sentences processed: 783388\n",
      "[2023-08-22 04:11:31,510 INFO] Average bsz: 4010/3526/65\n",
      "[2023-08-22 04:11:31,510 INFO] Validation perplexity: 6.8022\n",
      "[2023-08-22 04:11:31,510 INFO] Validation accuracy: 87.2777\n",
      "[2023-08-22 04:11:31,510 INFO] Model is improving ppl: 7.36079 --> 6.8022.\n",
      "[2023-08-22 04:11:31,510 INFO] Model is improving acc: 84.8289 --> 87.2777.\n",
      "[2023-08-22 04:11:31,517 INFO] Saving checkpoint models/model.fren_step_3000.pt\n"
     ]
    }
   ],
   "source": [
    "# Train the NMT model\n",
    "!onmt_train -config config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4a78b0-77fc-4303-9104-a5ff1bc8c2f4",
   "metadata": {},
   "source": [
    "### Translation\n",
    "\n",
    "Translation Options:\n",
    "\n",
    "    -model - specify the last model checkpoint name; try testing the quality of multiple checkpoints\n",
    "    -src - the subworded test dataset, source file\n",
    "    -output - give any file name to the new translation output file\n",
    "    -gpu - GPU ID, usually 0 if you have one GPU. Otherwise, it will translate on CPU, which would be slower.\n",
    "    -min_length - [optional] to avoid empty translations\n",
    "    -verbose - [optional] if you want to print translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1287e464-daf3-4e51-8563-2eb7460272f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-22 04:19:10,172 INFO] Loading checkpoint from models/model.fren_step_3000.pt\n",
      "[2023-08-22 04:19:10,960 INFO] Loading data into the model\n",
      "[2023-08-22 04:21:33,443 INFO] PRED SCORE: -0.1977, PRED PPL: 1.22 NB SENTENCES: 2000\n"
     ]
    }
   ],
   "source": [
    "# Translate the \"subworded\" source file of the test dataset\n",
    "# Change the model name, if needed.\n",
    "!onmt_translate -model models/model.fren_step_3000.pt -src UN.en-fr.fr-filtered.fr.subword.test -output UN.en.translated -gpu 0 -min_length 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fba64783-e20f-4b8c-9e5a-d6615499f450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁ 3 . ▁Decides ▁to ▁follow ▁close ly ▁the ▁public ▁consultations ▁on ▁the ▁future ▁political ▁status ▁of ▁Bermuda ▁under ▁way ▁in ▁the ▁Territory , ▁and ▁requests ▁the ▁relevant ▁Unit ed ▁Nations ▁organizations ▁to ▁provide ▁assistance ▁to ▁the ▁Territory , ▁if ▁requested , ▁in ▁the ▁context ▁of ▁its ▁public ▁education ▁programme ;\n",
      "▁ 6 . ▁Stresses ▁the ▁importance ▁of ▁contributions ▁to ▁the ▁Trust ▁Fund ▁for ▁the ▁Unit ed ▁Nations ▁Disarmament ▁Information ▁Programme ▁with ▁a ▁view ▁to ▁supporting ▁an ▁effective ▁outreach ▁programme , ▁and ▁invites ▁all ▁Member ▁States ▁to ▁contribute ▁to ▁the ▁Fund ;\n",
      "▁ 5 3 . ▁We ▁recognize ▁that ▁the ▁global ▁nature ▁of ▁climate ▁change ▁calls ▁for ▁cooperation ▁and ▁the ▁wide st ▁possible ▁participation ▁in ▁international ▁action , ▁in ▁accord ance ▁with ▁the ▁principles ▁of ▁the ▁Framework ▁Convention . ▁We ▁are ▁committed ▁to ▁advanc ing ▁the ▁long - term ▁nature ▁of ▁global ▁cooperation ▁to ▁address ▁climate ▁change , ▁in ▁accord ance ▁with ▁the ▁principles ▁of ▁the ▁eleventh ▁session . ▁We ▁emphasize ▁the ▁importance ▁of ▁the ▁eleventh ▁session ▁of ▁the ▁Conference ▁of ▁the ▁Parties ▁to ▁be ▁held ▁in ▁Montreal , ▁Canada , ▁from ▁ 2 0 0 5 .\n",
      "▁ 5 . ▁Urges ▁all ▁Governments ▁and ▁the ▁Unit ed ▁Nations ▁system ▁to ▁intensify ▁efforts , ▁on ▁the ▁basis ▁of ▁the ▁bilateral ▁and ▁private ▁donor ▁agencies , ▁development ▁and ▁private ▁donors , ▁to ▁implement ▁the ▁goals ▁of ▁the ▁World ▁Education ▁Forum , See ▁Unit ed ▁Nations ▁Education al , ▁Scientific ▁and ▁Cultur al ▁Organization , ▁Fin al ▁Report ▁of ▁the ▁World ▁Education ▁Forum , ▁Dakar , ▁Senegal , ▁ 2 6 - 2 8 ▁April ▁ 2 0 0 0 , ▁ 2 0 0 . ▁that ▁have ▁not ▁been ▁fully ▁implemented , ▁in ▁particular ▁by ▁ 2 0 0 5 ;\n",
      "▁ 2 0 . ▁Further ▁requests ▁the ▁Secretary - General , ▁in ▁order ▁to ▁reduce ▁the ▁cost ▁of ▁employ ing ▁General ▁Service ▁staff , ▁to ▁continue ▁efforts ▁to ▁recruit ▁local ▁staff ▁for ▁the ▁Mission ▁against ▁General ▁Service ▁posts , ▁commensurate ▁with ▁the ▁requirements ▁of ▁the ▁Mission ;\n"
     ]
    }
   ],
   "source": [
    "# Check the first 5 lines of the translation file\n",
    "!head -n 5 UN.en.translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f85ba01-2f25-4d3b-b749-45fe4b2477c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done desubwording! Output: UN.en.translated.desubword\n"
     ]
    }
   ],
   "source": [
    "# If needed install/update sentencepiece\n",
    "!pip3 install --upgrade -q sentencepiece\n",
    "\n",
    "# Desubword the translation file\n",
    "!python3 MT-Preparation/subwording/3-desubword.py target.model UN.en.translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc2d521d-5d8a-433e-be6c-8b3672c22b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Decides to follow closely the public consultations on the future political status of Bermuda under way in the Territory, and requests the relevant United Nations organizations to provide assistance to the Territory, if requested, in the context of its public education programme;\n",
      "6. Stresses the importance of contributions to the Trust Fund for the United Nations Disarmament Information Programme with a view to supporting an effective outreach programme, and invites all Member States to contribute to the Fund;\n",
      "53. We recognize that the global nature of climate change calls for cooperation and the widest possible participation in international action, in accordance with the principles of the Framework Convention. We are committed to advancing the long-term nature of global cooperation to address climate change, in accordance with the principles of the eleventh session. We emphasize the importance of the eleventh session of the Conference of the Parties to be held in Montreal, Canada, from 2005.\n",
      "5. Urges all Governments and the United Nations system to intensify efforts, on the basis of the bilateral and private donor agencies, development and private donors, to implement the goals of the World Education Forum,See United Nations Educational, Scientific and Cultural Organization, Final Report of the World Education Forum, Dakar, Senegal, 26-28 April 2000, 200. that have not been fully implemented, in particular by 2005;\n",
      "20. Further requests the Secretary-General, in order to reduce the cost of employing General Service staff, to continue efforts to recruit local staff for the Mission against General Service posts, commensurate with the requirements of the Mission;\n"
     ]
    }
   ],
   "source": [
    "# Check the first 5 lines of the desubworded translation file\n",
    "!head -n 5 UN.en.translated.desubword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "704cd1ac-daf8-489f-a490-b8c5c8867a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done desubwording! Output: UN.en-fr.en-filtered.en.subword.test.desubword\n"
     ]
    }
   ],
   "source": [
    "# Desubword the target file (reference) of the test dataset\n",
    "# Note: You might as well have split files *before* subwording during dataset preperation, \n",
    "# but sometimes datasets have tokeniztion issues, so this way you are sure the file is really untokenized.\n",
    "!python3 MT-Preparation/subwording/3-desubword.py target.model UN.en-fr.en-filtered.en.subword.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58b76947-2627-4acb-bbb1-8f867bd6c4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Decides to follow closely the public consultations on the future political status of Bermuda under way in the Territory, and requests the relevant United Nations organizations to provide assistance to the Territory, if requested, in the context of its public education programme;\n",
      "6. Emphasizes the importance of contributions to the Voluntary Trust Fund for the United Nations Disarmament Information Programme to sustain a strong outreach programme, and invites all Member States to make contributions to the Fund;\n",
      "53. We acknowledge that the global nature of climate change calls for the widest possible cooperation and participation in an effective and appropriate international response, in accordance with the principles of the Convention. We are committed to moving forward the global discussion on long-term cooperative action to address climate change, in accordance with these principles. We stress the importance of the eleventh session of the Conference of the Parties to the Convention, to be held in Montreal in November 2005.\n",
      "5. Urges all Governments and the United Nations system to strengthen efforts bilaterally and with international organizations and private sector donors in order to achieve the goals of the World Education Forum,See United Nations Educational, Scientific and Cultural Organization, Final Report of the World Education Forum, Dakar, Senegal, 26-28 April 2000 (Paris, 2000). in particular that of eliminating gender disparities in primary and secondary education by 2005, which have not been fully met, and to implement the United Nations Girls' Education Initiative as a means of reaching this goal, and calls for the implementation of and reaffirms the commitments contained in the United Nations Millennium Declaration,See resolution 55/2. particularly those related to education;\n",
      "20. Further requests the Secretary-General, in order to reduce the cost of employing General Service staff, to continue efforts to recruit local staff for the Mission against General Service posts, commensurate with the requirements of the Mission;\n"
     ]
    }
   ],
   "source": [
    "# Check the first 5 lines of the desubworded reference\n",
    "!head -n 5 UN.en-fr.en-filtered.en.subword.test.desubword"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276ca89a-c33d-4dd2-a4ee-f42e6c68f107",
   "metadata": {},
   "source": [
    "### MT Evaluation\n",
    "\n",
    "There are several MT Evaluation metrics such as BLEU, TER, METEOR, COMET, BERTScore, among others.\n",
    "\n",
    "Here we are using BLEU. Files must be detokenized/desubworded beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "37091436-517a-40bc-ac96-a9b969192958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-08-22 05:13:12--  https://raw.githubusercontent.com/ymoslem/MT-Evaluation/main/BLEU/compute-bleu.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 957 [text/plain]\n",
      "Saving to: ‘compute-bleu.py’\n",
      "\n",
      "compute-bleu.py     100%[===================>]     957  --.-KB/s    in 0s      \n",
      "\n",
      "2023-08-22 05:13:13 (16.8 MB/s) - ‘compute-bleu.py’ saved [957/957]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download the BLEU script\n",
    "!wget https://raw.githubusercontent.com/ymoslem/MT-Evaluation/main/BLEU/compute-bleu.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24eb2a8e-add1-4595-999b-0b6e9b9928f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sacrebleu in /opt/conda/lib/python3.9/site-packages (2.3.1)\n",
      "Requirement already satisfied: portalocker in /opt/conda/lib/python3.9/site-packages (from sacrebleu) (2.7.0)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.9/site-packages (from sacrebleu) (2023.6.3)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.9/site-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from sacrebleu) (1.25.2)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.9/site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.9/site-packages (from sacrebleu) (4.9.3)\n"
     ]
    }
   ],
   "source": [
    "# Install sacrebleu\n",
    "!pip3 install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4409798d-4994-42e8-b8ad-fe56a3a94e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference 1st sentence: 3. Decides to follow closely the public consultations on the future political status of Bermuda under way in the Territory, and requests the relevant United Nations organizations to provide assistance to the Territory, if requested, in the context of its public education programme;\n",
      "MTed 1st sentence: 3. Decides to follow closely the public consultations on the future political status of Bermuda under way in the Territory, and requests the relevant United Nations organizations to provide assistance to the Territory, if requested, in the context of its public education programme;\n",
      "BLEU:  66.31832136740302\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the translation (without subwording)\n",
    "!python3 compute-bleu.py UN.en-fr.en-filtered.en.subword.test.desubword UN.en.translated.desubword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a205218d-63a4-48d7-a0a7-2d88e0129794",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
